Search.setIndex({"alltitles":{"(Optional) Quark UINT4 Quantization with Different Group Sizes per Layer":[[131,"optional-quark-uint4-quantization-with-different-group-sizes-per-layer"]],"1. AWQ Overview":[[82,"awq-overview"]],"1. Auto-SmoothQuant Overview":[[133,"auto-smoothquant-overview"]],"1. Install AMD Quark":[[80,"install-amd-quark"],[119,"install-amd-quark"]],"1. Load the original floating-point model":[[83,"load-the-original-floating-point-model"]],"1. PPL in LM-Evaluation-Harness vs PPL Feature in Table":[[90,"ppl-in-lm-evaluation-harness-vs-ppl-feature-in-table"]],"1. Prepare the original float model":[[28,"prepare-the-original-float-model"],[130,"prepare-the-original-float-model"]],"1. Quantizing to Other Precision Levels":[[79,"quantizing-to-other-precision-levels"]],"1. Retrieve dataset from LM-Evaluation-Harness":[[92,"retrieve-dataset-from-lm-evaluation-harness"]],"1. Using Built-in Templates":[[123,"using-built-in-templates"]],"1.1 Quantizing Float32 Models to Int16 or Int32":[[79,"quantizing-float32-models-to-int16-or-int32"]],"1.2 Quantizing Float32 Models to Float16 or BFloat16":[[79,"quantizing-float32-models-to-float16-or-bfloat16"]],"1.3 Quantizing Float32 Models to BFP16":[[79,"quantizing-float32-models-to-bfp16"]],"1.4 Quantizing Float32 Models to MXINT8":[[79,"quantizing-float32-models-to-mxint8"]],"1.5 Quantizing Float32 Models to Mixed Data Formats":[[79,"quantizing-float32-models-to-mixed-data-formats"]],"1.Prepare data and model":[[116,"prepare-data-and-model"]],"2. (Optional) Define the data loader for calibration":[[83,"optional-define-the-data-loader-for-calibration"]],"2. Creating Configurations with Advanced Options":[[123,"creating-configurations-with-advanced-options"]],"2. Export Pretrained Model-Of-Interest to ONNX":[[92,"export-pretrained-model-of-interest-to-onnx"]],"2. ONNX Exported Models":[[90,"onnx-exported-models"]],"2. Prepare calibration data":[[28,"prepare-calibration-data"],[130,"prepare-calibration-data"]],"2. Quantizing Float16 Models":[[79,"quantizing-float16-models"]],"2. Quark AWQ Workflow":[[82,"quark-awq-workflow"]],"2. Quark Auto-SmoothQuant Workflow":[[133,"quark-auto-smoothquant-workflow"]],"2. Set the model":[[80,"set-the-model"]],"2. Set the model:":[[119,"set-the-model"]],"2.1. Quantization without Calibration Data":[[130,"quantization-without-calibration-data"]],"2.2. Quantization with Calibration Data":[[130,"quantization-with-calibration-data"]],"2.Set quantization Config and Quantizer":[[116,"set-quantization-config-and-quantizer"]],"3. Creating New Templates":[[123,"creating-new-templates"]],"3. Quark AWQ Config":[[82,"quark-awq-config"]],"3. Quark Auto-SmoothQuant Config":[[133,"quark-auto-smoothquant-config"]],"3. Retrieve OGA references for pre-trained ONNX Model":[[92,"retrieve-oga-references-for-pre-trained-onnx-model"]],"3. Set the quantization configuration":[[28,"set-the-quantization-configuration"],[80,"set-the-quantization-configuration"],[83,"set-the-quantization-configuration"],[130,"set-the-quantization-configuration"]],"3. Set the quantization configuration:":[[119,"set-the-quantization-configuration"]],"3. Support for VLMs":[[90,"support-for-vlms"]],"3.1. General Configuration (All Models)":[[83,"general-configuration-all-models"]],"3.2. LLM Template Configuration (Large Language Models)":[[83,"llm-template-configuration-large-language-models"]],"3.Calibration (PTQ) / Training (QAT) (Optional)":[[116,"calibration-ptq-training-qat-optional"]],"4. AWQ Code Call Example":[[82,"awq-code-call-example"]],"4. Auto Smoothquant end-to-end example":[[133,"auto-smoothquant-end-to-end-example"]],"4. Do quantization":[[119,"do-quantization"]],"4. Get Baseline Evaluation Scores on Pretrained ONNX Model":[[92,"get-baseline-evaluation-scores-on-pretrained-onnx-model"]],"4. LLM_Eval_Harness vs LLM_Eval_Haness_Offline":[[90,"llm-eval-harness-vs-llm-eval-haness-offline"]],"4. Quantize the model":[[28,"quantize-the-model"],[83,"quantize-the-model"],[130,"quantize-the-model"]],"4. Registering Custom Schemes":[[123,"registering-custom-schemes"]],"4. Set up the calibration data (this is required for weight only and dynamic quantization as well)":[[80,"set-up-the-calibration-data-this-is-required-for-weight-only-and-dynamic-quantization-as-well"]],"4.1 Quantize the model with Advanced Features":[[130,"quantize-the-model-with-advanced-features"]],"4.Exported to Onnx (prepare for NPU compile)":[[116,"exported-to-onnx-prepare-for-npu-compile"]],"5. (Optional) Export the quantized model to other formats for deployment":[[83,"optional-export-the-quantized-model-to-other-formats-for-deployment"]],"5. Apply the quantization":[[80,"apply-the-quantization"]],"5. Evaluate an optimized ONNX Model":[[92,"evaluate-an-optimized-onnx-model"]],"5. Evaluation":[[130,"evaluation"]],"5. Export Evaluation Results":[[90,"export-evaluation-results"]],"5. Next Steps":[[82,"next-steps"]],"5.Preparation before export":[[116,"preparation-before-export"]],"6. Results":[[130,"results"]],"6. Verify Offline Mode Setup":[[92,"verify-offline-mode-setup"]],"6.Export to ONNX model":[[116,"export-to-onnx-model"]],"7.Visualization ONNX model (Optional)":[[116,"visualization-onnx-model-optional"]],"8.Compile and deploy on AMD NPU device":[[116,"compile-and-deploy-on-amd-npu-device"]],"A config example for Llama3":[[133,"a-config-example-for-llama3"]],"AMD Quark APIs for ONNX":[[0,null]],"AMD Quark Tutorial: PyTorch Quickstart":[[140,null]],"AMD Quark for ONNX":[[28,null],[69,"amd-quark-for-onnx"]],"AMD Quark for ONNX: Streamlined Quantization for ONNX models":[[17,"amd-quark-for-onnx-streamlined-quantization-for-onnx-models"]],"AMD Quark for PyTorch":[[83,null]],"AMD Quark for PyTorch: Flexible and Efficient Quantization for PyTorch Models":[[17,"amd-quark-for-pytorch-flexible-and-efficient-quantization-for-pytorch-models"]],"AMD Quark for Pytorch":[[110,"amd-quark-for-pytorch"]],"AMD Quark release history":[[141,null]],"API Usage":[[107,"api-usage"]],"AWQ end-to-end example":[[136,null]],"Accelerate with GPUs":[[64,null]],"Accessing ONNX Examples":[[68,null]],"Accessing PyTorch Examples":[[109,null]],"Accuracy Improvement Algorithms":[[26,null]],"Activation/weight smoothing (SmoothQuant)":[[118,null]],"AdaQuant":[[22,"adaquant"],[22,"id2"]],"AdaRound":[[22,"adaround"],[22,"id1"]],"Adding Calibration Datasets":[[29,null],[84,null]],"Advanced Installation":[[18,"advanced"]],"Advantage about the fx graph":[[99,"advantage-about-the-fx-graph"]],"An example on ResNet50":[[47,"an-example-on-resnet50"]],"Apply Quantization Algorithms":[[115,"apply-quantization-algorithms"]],"Arguments":[[22,"arguments"],[23,"arguments"],[24,"arguments"],[25,"arguments"]],"Assign Shapes for All Tensors in A Given Model":[[71,"assign-shapes-for-all-tensors-in-a-given-model"]],"Attributes":[[35,"attributes"],[36,"attributes"],[37,"attributes"],[38,"attributes"],[39,"attributes"],[40,"attributes"]],"Auto Encoder (AE)":[[135,"auto-encoder-ae"]],"Auto Search Premium Features":[[77,"auto-search-premium-features"]],"Auto search for AMD Ryzen AI quantization":[[63,"auto-search-for-amd-ryzen-ai-quantization"]],"Auto-Search for General Yolov8 ONNX Quantization":[[45,null]],"Auto-Search for Ryzen AI ONNX Model Quantization":[[56,null]],"Auto-Search for Ryzen AI Resnet50 ONNX Model Quantization":[[63,null]],"Auto-Search for Ryzen AI Yolo-NAS ONNX Model Quantization":[[57,null]],"Auto-Search for Ryzen AI Yolov3 ONNX Model Quantization with Custom Evaluator":[[58,null]],"Automatic Mixed Precision based on Sensitivity Analysis":[[76,"automatic-mixed-precision-based-on-sensitivity-analysis"]],"Automatic Search for Model Quantization":[[77,null]],"BF16 quantization in AMD Quark for ONNX":[[72,"bf16-quantization-in-amd-quark-for-onnx"]],"BFP16 (Block floating point) Quantization":[[73,null],[119,null]],"BFP16 Quantization":[[41,"bfp16-quantization"]],"BFP16 Quantization with ADAQUANT":[[41,"bfp16-quantization-with-adaquant"]],"BFPQuantizeDequantize":[[35,null]],"BFPQuantizeDequantize - 1":[[35,"bfpquantizedequantize-1"]],"Backward Denoising Processs":[[135,"backward-denoising-processs"]],"Basic Example":[[28,"basic-example"],[83,"basic-example"]],"Benchmark":[[89,"benchmark"]],"Benefits of AdaRound and AdaQuant":[[22,"benefits-of-adaround-and-adaquant"]],"Benefits of BFP16 Quantization":[[73,"benefits-of-bfp16-quantization"]],"Benefits of Mixed Precision Quantization":[[76,"benefits-of-mixed-precision-quantization"]],"Best Practice for Ryzen AI in AMD Quark ONNX":[[127,null]],"Best Practice for Ryzen AI in Quark ONNX":[[66,null],[67,null]],"Best Practices for Post-Training Quantization (PTQ)":[[115,null]],"Block Floating Point (BFP) Example":[[41,null]],"Brevitas Integration":[[88,null],[88,"id1"]],"Bridge from Quark to llama.cpp":[[100,null]],"Brief using instruction":[[99,"brief-using-instruction"]],"Bug Fixes and Enhancements":[[124,"bug-fixes-and-enhancements"],[124,"id3"]],"C++ Compilation Issues":[[110,"c-compilation-issues"]],"CLI Scripts":[[139,"cli-scripts"]],"Calibration":[[64,"calibration"]],"Calibration Data Path for AMD Quark Quantizer":[[29,"calibration-data-path-for-amd-quark-quantizer"]],"Calibration Methods":[[30,null],[85,null]],"Calibration and Export":[[89,"calibration-and-export"]],"Call the Auto Search Process":[[56,"call-the-auto-search-process"],[57,"call-the-auto-search-process"],[58,"call-the-auto-search-process"]],"Check Our Hand-Drawn Images":[[140,"check-our-hand-drawn-images"]],"Chunking & Tokenization":[[139,"chunking-tokenization"]],"Class DataReader for AMD Quark Quantizer":[[29,"class-datareader-for-amd-quark-quantizer"]],"Comparing Quark\u2019s ONNX and PyTorch capabilities":[[16,"comparing-quark-s-onnx-and-pytorch-capabilities"]],"Compile Custom Operators Library (Optional)":[[18,"compile-custom-operators-library-optional"]],"Compile Fast Quantization Kernels (Optional)":[[18,"compile-fast-quantization-kernels-optional"]],"Components":[[77,"components"]],"Conclusion":[[77,"conclusion"],[80,"conclusion"],[88,"conclusion"]],"Config schema":[[133,"config-schema"]],"Configuring ONNX Quantization":[[78,null]],"Configuring PyTorch Quantization":[[122,null]],"Configuring PyTorch Quantization for Large Language Models":[[123,null]],"Considerations for Quantization":[[19,"considerations-for-quantization"]],"Context: Uniform Integer Quantization":[[81,"context-uniform-integer-quantization"]],"Contribution Principles":[[20,"contribution-principles"]],"Convert Quark extended custom ops to deprecated Vitis custom ops":[[71,"convert-quark-extended-custom-ops-to-deprecated-vitis-custom-ops"]],"Convert a A8W8 NPU Model to a A8W8 CPU Model":[[71,"convert-a-a8w8-npu-model-to-a-a8w8-cpu-model"]],"Convert a Float16 Model to a BFP16 Model":[[71,"convert-a-float16-model-to-a-bfp16-model"]],"Convert a Float16 Model to a BFloat16 Model":[[71,"convert-a-float16-model-to-a-bfloat16-model"]],"Convert a Float16 Model to a Float32 Model":[[71,"convert-a-float16-model-to-a-float32-model"]],"Convert a Float32 Model to a BFP16 Model":[[71,"convert-a-float32-model-to-a-bfp16-model"]],"Convert a Float32 Model to a BFloat16 Model":[[71,"convert-a-float32-model-to-a-bfloat16-model"]],"Convert a NCHW input Model to a NHWC Model":[[71,"convert-a-nchw-input-model-to-a-nhwc-model"]],"Convert a U16U8 Quantized Model to a U8U8 Model":[[71,"convert-a-u16u8-quantized-model-to-a-u8u8-model"]],"Convert a float32 model to a float16 model":[[71,"convert-a-float32-model-to-a-float16-model"]],"Convert the Int32 Bias of the Quantized Model to Int16":[[71,"convert-the-int32-bias-of-the-quantized-model-to-int16"]],"Create a Calibration Data Set":[[140,"create-a-calibration-data-set"]],"Create a Quantization Configuration":[[140,"create-a-quantization-configuration"]],"Create the Quantized Model":[[140,"create-the-quantized-model"]],"Crypto Mode":[[68,null]],"Customized Configurations":[[78,"customized-configurations"]],"Dataloader with Dataset as torch.Tensor":[[84,"dataloader-with-dataset-as-torch-tensor"]],"Dataloader with Dict[str, torch.Tensor]":[[84,"dataloader-with-dict-str-torch-tensor"]],"Dataloader with List[Dict[str, torch.Tensor]] or List[torch.Tensor]":[[84,"dataloader-with-list-dict-str-torch-tensor-or-list-torch-tensor"]],"Dataset Files":[[89,"dataset-files"]],"Debugging quantization degradation in AMD Quark":[[86,null]],"Define Directory to Reuse Data":[[140,"define-directory-to-reuse-data"]],"Depth-Wise Prune:":[[107,"depth-wise-prune"]],"Depth-Wise Pruning":[[134,"depth-wise-pruning"]],"Detailed Code":[[34,"detailed-code"]],"Detailed Experiments script":[[99,"detailed-experiments-script"]],"Development Flow Steps":[[126,"development-flow-steps"]],"Diffusion Model":[[135,"diffusion-model"]],"Diffusion Model Fundamentals":[[135,"diffusion-model-fundamentals"]],"Diffusion Model Quantization using Quark":[[89,null]],"Documenting Your Contribution":[[20,"documenting-your-contribution"]],"Downloading the Model":[[139,"downloading-the-model"]],"Dumping the Simulation Results":[[70,"dumping-the-simulation-results"]],"Dynamic Quantization":[[68,null]],"Dynamic Quantization for Llama-2-7b":[[48,null]],"Dynamic Quantization for OPT-125M":[[49,null]],"End to end tutorials":[[96,"end-to-end-tutorials"]],"Entropy Calibration Method":[[30,"entropy-calibration-method"]],"Environment Issues":[[110,"environment-issues"]],"Environment Setup":[[64,"environment-setup"]],"Environments prepare":[[134,"environments-prepare"]],"Evaluate accuracy between baseline and quantized results folders":[[71,"evaluate-accuracy-between-baseline-and-quantized-results-folders"]],"Evaluate the Metric & Save Pruned Model":[[107,"evaluate-the-metric-save-pruned-model"]],"Evaluating the Quantized Model":[[70,"evaluating-the-quantized-model"]],"Evaluation":[[41,"evaluation"],[42,"evaluation"],[43,"evaluation"],[44,"evaluation"],[46,"evaluation"],[47,"evaluation"],[48,"evaluation"],[49,"evaluation"],[50,"evaluation"],[51,"evaluation"],[52,"evaluation"],[53,"evaluation"],[54,"evaluation"],[55,"evaluation"],[59,"evaluation"],[60,"evaluation"],[61,"evaluation"]],"Example":[[23,"example"],[24,"example"],[25,"example"],[73,"example"],[75,"example"]],"Example 1":[[98,"example-1"]],"Example 2":[[98,"example-2"]],"Example 3":[[98,"example-3"]],"Example Code":[[107,"example-code"]],"Example Code:":[[29,"example-code"],[29,"id1"]],"Example of GGUF Exporting (for already quantized model)":[[102,"example-of-gguf-exporting-for-already-quantized-model"]],"Example of Loading in Eager Mode":[[114,"example-of-loading-in-eager-mode"]],"Example of Loading in FX-graph Mode":[[114,"example-of-loading-in-fx-graph-mode"]],"Example of Onnx Exporting":[[104,"example-of-onnx-exporting"]],"Example of Quark Format Exporting":[[105,"example-of-quark-format-exporting"]],"Example of Quark Format Importing":[[105,"example-of-quark-format-importing"]],"Example of Saving in Eager Mode":[[114,"example-of-saving-in-eager-mode"]],"Example of Saving in FX-graph Mode":[[114,"example-of-saving-in-fx-graph-mode"]],"Examples":[[22,"examples"],[74,"examples"]],"Exclude Outlier Layers":[[115,"exclude-outlier-layers"]],"Expanding with more models":[[121,"expanding-with-more-models"]],"Experiment Results":[[87,"experiment-results"]],"Experiment results":[[100,"id4"]],"Experiments":[[100,"experiments"]],"Experiments results (Partly)":[[134,"experiments-results-partly"]],"Experiments:":[[99,"experiments"]],"Exporting PyTorch Models to ONNX":[[70,"exporting-pytorch-models-to-onnx"]],"Exporting Quantized Models":[[101,null]],"Exporting Using ONNX Runtime Gen AI Model Builder":[[131,"exporting-using-onnx-runtime-gen-ai-model-builder"]],"Exporting to Hugging Face format (safetensors format)":[[103,"exporting-to-hugging-face-format-safetensors-format"]],"Exporting with ONNX":[[135,"exporting-with-onnx"]],"ExtendedDequantizeLinear":[[36,null]],"ExtendedDequantizeLinear - 1":[[36,"extendeddequantizelinear-1"]],"ExtendedInstanceNormalization":[[37,null]],"ExtendedInstanceNormalization - 1":[[37,"extendedinstancenormalization-1"]],"ExtendedLSTM":[[38,null]],"ExtendedLSTM - 1":[[38,"extendedlstm-1"]],"ExtendedQuantizeLinear":[[39,null]],"ExtendedQuantizeLinear - 1":[[39,"extendedquantizelinear-1"]],"Extension Feature Design":[[88,"extension-feature-design"]],"Extensions for PyTorch":[[106,null]],"FAQ":[[77,"faq"]],"FP32/FP16 to BF16 Model Conversion":[[129,null]],"FP4 Quantization for LLM models":[[137,null]],"FP8 Quantization for LLM models":[[138,null]],"Fake Quantization":[[19,"fake-quantization"]],"Fast Finetune":[[22,"fast-finetune"],[64,"fast-finetune"]],"Field Descriptions":[[82,"field-descriptions"]],"Float Scales (A8W8 and A16W8) Quantization":[[128,null]],"Flow Diagram":[[77,"flow-diagram"]],"For Contributors: How to Contribute":[[20,"for-contributors-how-to-contribute"]],"For Multi-Input Models":[[34,"for-multi-input-models"]],"For Multi-Input Models:":[[29,"for-multi-input-models"]],"For Single-Input Models":[[34,"for-single-input-models"]],"For Single-Input Models:":[[29,"for-single-input-models"]],"For Users: Understanding the contrib Area":[[20,"for-users-understanding-the-contrib-area"]],"For example (AWQ config for Llama3)":[[82,"for-example-awq-config-for-llama3"]],"Forward Noising Process":[[135,"forward-noising-process"]],"Frequently Asked Questions (FAQ)":[[69,null],[110,null]],"Full List of Quantization Configuration Features":[[27,null]],"Further Reading":[[135,"further-reading"],[139,"further-reading"],[140,"further-reading"]],"Further reading":[[28,"further-reading"],[83,"further-reading"]],"GGUF Exporting":[[102,null]],"Getting Started":[[90,"getting-started"]],"Getting started with AMD Quark":[[16,null]],"Guidelines":[[55,"guidelines"]],"Hardware Mapping":[[81,"hardware-mapping"]],"Highlight Overview":[[116,"highlight-overview"],[117,"highlight-overview"]],"Highlight points about the FX mode quantization":[[87,"highlight-points-about-the-fx-mode-quantization"]],"How BFP16 works in AMD Quark":[[119,"how-bfp16-works-in-amd-quark"]],"How Does It Work":[[100,"how-does-it-work"]],"How Does Quark Do Quantization":[[100,"how-does-quark-do-quantization"]],"How are These Two-Level Scales Obtained?":[[81,"how-are-these-two-level-scales-obtained"]],"How are the scales calculated?":[[80,"how-are-the-scales-calculated"]],"How are the scales used?":[[80,"how-are-the-scales-used"]],"How does SmoothQuant work?":[[118,"how-does-smoothquant-work"]],"How is the tensor turned into blocks?":[[80,"how-is-the-tensor-turned-into-blocks"]],"How to Contribute":[[20,"how-to-contribute"]],"How to Convert FP16 to BF16":[[129,"how-to-convert-fp16-to-bf16"]],"How to Convert FP32 to BF16":[[129,"how-to-convert-fp32-to-bf16"]],"How to Enable MX Quantization in AMD Quark for ONNX?":[[75,"how-to-enable-mx-quantization-in-amd-quark-for-onnx"]],"How to Enable Mixed Precision in AMD Quark for ONNX?":[[76,"how-to-enable-mixed-precision-in-amd-quark-for-onnx"]],"How to Further Improve the Accuracy for BF16 Quantization?":[[72,"how-to-further-improve-the-accuracy-for-bf16-quantization"]],"How to Further Improve the Accuracy of a MX Quantized Model?":[[75,"how-to-further-improve-the-accuracy-of-a-mx-quantized-model"]],"How to Further Improve the Accuracy of a MX9 Quantized Model?":[[74,"how-to-further-improve-the-accuracy-of-a-mx9-quantized-model"]],"How to Improve BF16 Accuracy":[[129,"how-to-improve-bf16-accuracy"]],"How to Improve Quantization Accuracy":[[128,"how-to-improve-quantization-accuracy"],[132,"how-to-improve-quantization-accuracy"]],"How to Measure Accuracy (Compare Differences between FP32 and A8W8/A16W8)":[[128,"how-to-measure-accuracy-compare-differences-between-fp32-and-a8w8-a16w8"]],"How to Measure Accuracy (Compare Differences between FP32 and XINT8)":[[132,"how-to-measure-accuracy-compare-differences-between-fp32-and-xint8"]],"How to Measure Accuracy (Compare Differences between FP32/FP16 and BF16)":[[129,"how-to-measure-accuracy-compare-differences-between-fp32-fp16-and-bf16"]],"How to Quantize a Float Model with A8W8/A16W8 Config":[[128,"how-to-quantize-a-float-model-with-a8w8-a16w8-config"]],"How to Quantize a Float Model with XINT8 Config":[[132,"how-to-quantize-a-float-model-with-xint8-config"]],"How to Use GGUF Export in Quark":[[100,"how-to-use-gguf-export-in-quark"]],"How to Write Your Own AWQ Config":[[82,"how-to-write-your-own-awq-config"]],"How to Write Your Own Auto-SmoothQuant Config":[[133,"how-to-write-your-own-auto-smoothquant-config"]],"How to enable BFP16 quantization in AMD Quark for ONNX?":[[73,"how-to-enable-bfp16-quantization-in-amd-quark-for-onnx"]],"How to enable MX9 quantization in AMD Quark for ONNX?":[[74,"how-to-enable-mx9-quantization-in-amd-quark-for-onnx"]],"How to further improve the accuracy of a BFP16 quantized model in AMD Quark for ONNX?":[[73,"how-to-further-improve-the-accuracy-of-a-bfp16-quantized-model-in-amd-quark-for-onnx"]],"How to use BFP16 in AMD Quark":[[119,"how-to-use-bfp16-in-amd-quark"]],"How to use OCP MX in AMD Quark":[[80,"how-to-use-ocp-mx-in-amd-quark"]],"Hugging Face TIMM Models":[[68,null]],"Hugging Face TIMM Quantization":[[65,null]],"Hugging Face format (safetensors format)":[[103,null]],"Image Classification":[[68,null]],"Image Classification Models FX Graph Quantization":[[87,null]],"Image Classification Task":[[99,"image-classification-task"]],"Import the necessary packages":[[134,"import-the-necessary-packages"]],"Important Details":[[90,"important-details"]],"Important Information":[[117,"important-information"]],"Improving Model Accuracy":[[68,null]],"Infer the Float Model (Optional)":[[62,"infer-the-float-model-optional"],[65,"infer-the-float-model-optional"]],"Inference":[[64,"inference"],[67,"inference"]],"Init Prune Config & Calibration/Test Dataset":[[107,"init-prune-config-calibration-test-dataset"]],"Init Pruner & Perform Pruning":[[107,"init-pruner-perform-pruning"]],"Init the LLM":[[134,"init-the-llm"]],"Init the LLM model and dataset for evaluation":[[134,"init-the-llm-model-and-dataset-for-evaluation"]],"Init the prune config":[[134,"init-the-prune-config"],[134,"id1"]],"Init the prune config and the pruner instance.":[[134,"init-the-prune-config-and-the-pruner-instance"]],"Init the pruner instance":[[134,"init-the-pruner-instance"]],"Init the testdata":[[134,"init-the-testdata"]],"Inputs":[[35,"inputs"],[36,"inputs"],[37,"inputs"],[38,"inputs"],[39,"inputs"],[40,"inputs"]],"Install CMake":[[18,"install-cmake"]],"Install PyTorch with GPU Support":[[18,"install-pytorch-with-gpu-support"]],"Install Python":[[18,"install-python"]],"Install Quark":[[18,"install-quark"]],"Install Quark + Quark Examples from Download":[[18,"install-quark-quark-examples-from-download"]],"Install Quark from PyPI with pip":[[18,"install-quark-from-pypi-with-pip"]],"Install a C++ Compiler":[[18,"install-a-c-compiler"]],"Installation":[[96,"installation"],[131,"installation"]],"Installation Guide":[[18,null]],"Installation Verification (Optional)":[[18,"installation-verification-optional"]],"Installation and Set-Up":[[135,"installation-and-set-up"],[140,"installation-and-set-up"]],"Installation and Setup":[[139,"installation-and-setup"]],"Integer Quantization":[[19,"integer-quantization"]],"Integration with AMD Pytorch-light (APL)":[[98,null]],"Introduction":[[55,"introduction"],[72,null],[74,null],[80,"introduction"],[98,"introduction"],[100,"introduction"],[119,"introduction"],[121,"introduction"],[128,"introduction"],[129,"introduction"],[132,"introduction"]],"Introduction to AWQ Algorithm":[[82,null]],"Introduction to Auto-SmoothQuant Algorithm":[[133,null]],"Jupyter Notebook":[[140,"jupyter-notebook"]],"Kernel errors mentioning path to \u201ccl\u201d not found":[[140,"kernel-errors-mentioning-path-to-cl-not-found"]],"Key Concepts":[[73,"key-concepts"]],"Key Feature":[[99,"key-feature"]],"Key Feature & Brief Usage instruction.":[[99,"key-feature-brief-usage-instruction"]],"Key Features":[[17,"key-features"],[17,"id1"]],"LLM Model Depth-Wise Pruning (beta)":[[134,null]],"LLM Pruning":[[107,null],[134,"llm-pruning"]],"LM-Evaluation-Harness (Offline)":[[92,null]],"LM-Evaluation-Harness Evaluations":[[91,null]],"LM-Evaluation-Harness on ONNX Models":[[91,"lm-evaluation-harness-on-onnx-models"]],"LM-Evaluation-Harness on Torch Models":[[91,"lm-evaluation-harness-on-torch-models"]],"Language Model Evaluations in Quark":[[90,null]],"Language Model Optimization":[[108,null]],"Language Model Post Training Quantization (PTQ) Using Quark":[[96,null]],"Language Model QAT Using Quark and Trainer":[[97,null]],"Language Models":[[68,null]],"Large Language Model Fundamentals":[[139,"large-language-model-fundamentals"]],"Latent Space":[[139,"latent-space"]],"License":[[45,"license"],[52,"license"],[55,"license"]],"Linux":[[18,"linux"],[18,"id4"]],"Load SafeTensor and Run with a prompt":[[89,"load-safetensor-and-run-with-a-prompt"]],"Load SafeTensor and Test":[[89,"load-safetensor-and-test"]],"Load and Run":[[89,"load-and-run"]],"Load and Test":[[89,"load-and-test"]],"Loading":[[114,"loading"]],"Loading quantized models saved in Hugging Face format (safetensors format)":[[103,"loading-quantized-models-saved-in-hugging-face-format-safetensors-format"]],"MSE Calibration Method":[[30,"mse-calibration-method"]],"MXQuantizeDequantize":[[40,null]],"MXQuantizeDequantize - 1":[[40,"mxquantizedequantize-1"]],"Main API Declaration":[[87,"main-api-declaration"]],"Mainstream Methods Overview":[[107,"mainstream-methods-overview"]],"Microscaling (MX)":[[75,null]],"Microscaling (MX) Example":[[42,null]],"MinMax Calibration Method":[[30,"minmax-calibration-method"]],"Mixed Precision":[[76,null]],"Mixed Precision Quantization in AMD Quark for ONNX":[[76,"mixed-precision-quantization-in-amd-quark-for-onnx"]],"Model Architecture":[[139,"model-architecture"]],"Model Components":[[135,"model-components"]],"Model Evaluation: Post-Quantization":[[139,"model-evaluation-post-quantization"]],"Model Evaluation: Pre-Quantization":[[139,"model-evaluation-pre-quantization"]],"Model Implementation & Code":[[135,"model-implementation-code"]],"Model Issues":[[69,"model-issues"]],"Model Preparation":[[131,"model-preparation"]],"Model Quantization":[[19,"model-quantization"],[47,"model-quantization"],[51,"model-quantization"]],"Model Quantization Preparation":[[56,"model-quantization-preparation"],[58,"model-quantization-preparation"]],"ModelQuantizer":[[88,"modelquantizer"]],"More Quantization Default Configurations":[[78,"more-quantization-default-configurations"]],"More examples":[[96,null]],"New Features":[[124,"new-features"],[124,"id2"]],"Next Steps":[[135,"next-steps"],[140,"next-steps"]],"Next steps":[[16,"next-steps"]],"NonOverflow Calibration Method":[[30,"nonoverflow-calibration-method"]],"Notes":[[81,"notes"]],"ONNX Examples in AMD Quark for This Release":[[68,"onnx-examples-in-amd-quark-for-this-release"]],"ONNX Exporting":[[104,null]],"ONNX model calibration":[[2,null]],"ONNX model optimization":[[4,null]],"ONNX model quantization":[[7,null]],"ONNX quantization configuration":[[8,null]],"ONNX quantization utilities":[[6,null]],"ONNX quantizer":[[3,null]],"OSSCAR:":[[107,"osscar"]],"Object Detection Task":[[99,"object-detection-task"]],"Optional Utilities":[[70,null]],"Other Arguments":[[91,"other-arguments"],[93,"other-arguments"],[94,"other-arguments"]],"Other:":[[107,"other"]],"Others":[[134,"others"]],"Outputs":[[35,"outputs"],[36,"outputs"],[37,"outputs"],[38,"outputs"],[39,"outputs"],[40,"outputs"]],"Overall summary":[[116,"overall-summary"]],"Overview":[[27,"overview"],[77,"overview"],[88,"overview"]],"Overview of LLM Pruning":[[107,"overview-of-llm-pruning"]],"PPL on Torch Models":[[93,"ppl-on-torch-models"]],"Papers":[[135,"papers"],[139,"papers"]],"Param explanations:":[[134,"param-explanations"]],"Percentile Calibration Method":[[30,"percentile-calibration-method"]],"Perform Depth-Wise":[[134,"perform-depth-wise"]],"Perform PTQ & QAT for YOLO-NAS":[[116,"perform-ptq-qat-for-yolo-nas"]],"Perform the Pruning Process":[[134,"perform-the-pruning-process"]],"Perplexity Evaluations":[[93,null]],"Perplexity on ONNX Models":[[93,"perplexity-on-onnx-models"]],"Pip Requirements":[[44,"pip-requirements"],[46,"pip-requirements"],[50,"pip-requirements"],[53,"pip-requirements"],[59,"pip-requirements"],[62,"pip-requirements"],[63,"pip-requirements"],[65,"pip-requirements"],[66,"pip-requirements"],[67,"pip-requirements"],[127,"pip-requirements"]],"Pip requirements":[[41,"pip-requirements"],[42,"pip-requirements"],[43,"pip-requirements"],[45,"pip-requirements"],[47,"pip-requirements"],[48,"pip-requirements"],[49,"pip-requirements"],[51,"pip-requirements"],[52,"pip-requirements"],[54,"pip-requirements"],[55,"pip-requirements"],[57,"pip-requirements"],[60,"pip-requirements"],[61,"pip-requirements"]],"Power-of-Two Scales (Xint8) Quantization":[[132,null]],"Pre-processing on the Float Model":[[70,"pre-processing-on-the-float-model"]],"Preparation":[[95,"preparation"],[96,"preparation"],[97,"preparation"],[116,"preparation"],[131,"preparation"]],"Preparation & Workflow":[[117,"preparation-workflow"]],"Prepare Calibration Data":[[63,"prepare-calibration-data"],[66,"prepare-calibration-data"],[67,"prepare-calibration-data"],[127,"prepare-calibration-data"]],"Prepare Data":[[44,"prepare-data"],[46,"prepare-data"],[53,"prepare-data"],[62,"prepare-data"],[65,"prepare-data"]],"Prepare LLM & Tokenizer":[[107,"prepare-llm-tokenizer"]],"Prepare Model":[[44,"prepare-model"],[46,"prepare-model"],[50,"prepare-model"],[53,"prepare-model"],[59,"prepare-model"]],"Prepare data":[[41,"prepare-data"],[42,"prepare-data"],[43,"prepare-data"],[45,"prepare-data"],[54,"prepare-data"]],"Prepare data and model":[[47,"prepare-data-and-model"],[51,"prepare-data-and-model"]],"Prepare model":[[41,"prepare-model"],[42,"prepare-model"],[43,"prepare-model"],[45,"prepare-model"],[48,"prepare-model"],[49,"prepare-model"],[52,"prepare-model"],[54,"prepare-model"],[55,"prepare-model"],[57,"prepare-model"],[60,"prepare-model"],[61,"prepare-model"],[63,"prepare-model"],[66,"prepare-model"],[67,"prepare-model"],[127,"prepare-model"]],"Prepare model from Torch to ONNX (Optional)":[[67,"prepare-model-from-torch-to-onnx-optional"]],"Prepare the Prune config":[[134,"prepare-the-prune-config"]],"Prerequisite & Some Facts":[[134,"prerequisite-some-facts"]],"Prerequisites information/knowledge":[[116,"prerequisites-information-knowledge"]],"Previous Versions of AMD Quark":[[18,"previous-versions-of-amd-quark"]],"Print Names and Quantity of A16W8 and A8W8 Conv for Mixed-Precision Models":[[71,"print-names-and-quantity-of-a16w8-and-a8w8-conv-for-mixed-precision-models"]],"Provide Custom Calibration Data and Evaluation Data (Optional)":[[65,"provide-custom-calibration-data-and-evaluation-data-optional"]],"Prune Results":[[107,"prune-results"]],"Pruning":[[11,null],[95,null]],"Pruning Scripts":[[95,"pruning-scripts"]],"Pruning configuration":[[12,null]],"PyTorch Examples in Quark for This Release":[[109,null]],"PyTorch FX-Graph model":[[116,"pytorch-fx-graph-model"]],"PyTorch Fx Graph & Quark Quantization Tool":[[99,"pytorch-fx-graph-quark-quantization-tool"]],"PyTorch model export and reloading":[[9,null]],"PyTorch model export configuration":[[10,null]],"PyTorch quantization":[[13,null]],"QAT Scripts":[[97,"qat-scripts"]],"QDQ quantizer":[[5,null]],"QuaRot":[[24,null]],"Quantization":[[48,"quantization"],[49,"quantization"],[52,"quantization"],[60,"quantization"],[61,"quantization"],[62,"quantization"],[65,"quantization"],[66,"quantization"],[67,"quantization"],[127,"quantization"],[135,"quantization"],[139,"quantization"]],"Quantization & Export Scripts":[[89,"quantization-export-scripts"]],"Quantization & Export Scripts & Import Scripts":[[96,"quantization-export-scripts-import-scripts"]],"Quantization Config Issues":[[69,"quantization-config-issues"]],"Quantization Configuration":[[27,"quantization-configuration"]],"Quantization Issues":[[69,"quantization-issues"]],"Quantization LLM Template":[[15,null]],"Quantization Preparation":[[57,"quantization-preparation"]],"Quantization Result":[[116,"quantization-result"]],"Quantization Results":[[41,"quantization-results"],[117,"quantization-results"]],"Quantization Schemes":[[31,null],[111,null]],"Quantization Strategies":[[32,null],[112,null]],"Quantization Symmetry":[[33,null],[113,null]],"Quantization Using AdaQuant and AdaRound":[[22,null]],"Quantization With CLE":[[46,"quantization-with-cle"]],"Quantization With GPTQ":[[50,"quantization-with-gptq"]],"Quantization With LayerWisePercentile":[[53,"quantization-with-layerwisepercentile"]],"Quantization With MinMax and Percentile":[[53,"quantization-with-minmax-and-percentile"]],"Quantization With Mixed Precision":[[54,"quantization-with-mixed-precision"]],"Quantization With Smooth Quant":[[59,"quantization-with-smooth-quant"]],"Quantization Without CLE":[[46,"quantization-without-cle"]],"Quantization Without GPTQ":[[50,"quantization-without-gptq"]],"Quantization Without Mixed Precision":[[54,"quantization-without-mixed-precision"]],"Quantization Without Smooth Quant":[[59,"quantization-without-smooth-quant"]],"Quantization Work Flow":[[99,"quantization-work-flow"]],"Quantization configuration":[[14,null]],"Quantization using Mixed Precision":[[54,null]],"Quantization using SmoothQuant":[[59,null]],"Quantization with ADAQUANT":[[43,"quantization-with-adaquant"]],"Quantization with ADAROUND":[[44,"quantization-with-adaround"]],"Quantization with AMD Quark":[[19,null]],"Quantization with HQQ":[[60,"quantization-with-hqq"]],"Quantization with MX Formats":[[42,"quantization-with-mx-formats"]],"Quantization with QuaRot":[[55,"quantization-with-quarot"]],"Quantization with QuaRot and SmoothQuant":[[55,"quantization-with-quarot-and-smoothquant"]],"Quantization with auto_search":[[45,"quantization-with-auto-search"]],"Quantization without ADAQUANT":[[43,"quantization-without-adaquant"]],"Quantization without ADAROUND":[[44,"quantization-without-adaround"]],"Quantization without QuaRot":[[55,"quantization-without-quarot"]],"QuantizationConfig":[[88,"quantizationconfig"]],"Quantize Controlnet and Export SafeTensors (unet-only)":[[89,"quantize-controlnet-and-export-safetensors-unet-only"]],"Quantize Diffusion and Export ONNX (entire pipeline)":[[89,"quantize-diffusion-and-export-onnx-entire-pipeline"]],"Quantize a Float Model with Random Data":[[71,"quantize-a-float-model-with-random-data"]],"Quantize the Model":[[140,"quantize-the-model"]],"Quantizing LLMs for ONNX Runtime GenAI":[[131,null]],"Quantizing Llama-2-7b model using MatMulNBits quantizer":[[60,null]],"Quantizing Using CrossLayerEqualization (CLE)":[[23,null]],"Quantizing a Diffusion Model using Quark":[[135,null]],"Quantizing a Large Language Model with Quark":[[139,null]],"Quantizing a ResNet50-v1-12 Model":[[51,null]],"Quantizing a ResNet50-v1-12 Model in crypto mode":[[47,null]],"Quantizing a model with GPTQ":[[50,null]],"Quantizing an OPT-125M Model":[[52,null]],"Quantizing with Rotation and SmoothQuant":[[121,null]],"Quark APIs for PyTorch":[[1,null]],"Quark Format":[[105,null]],"Quark Format Exporting":[[105,"quark-format-exporting"]],"Quark Format Importing":[[105,"quark-format-importing"]],"Quark Fx quantization tool":[[99,"quark-fx-quantization-tool"]],"Quark ONNX Example for CrossLayerEqualization (CLE)":[[46,null]],"Quark ONNX Example for LayerWisePercentile":[[53,null]],"Quark ONNX Quantization Example":[[43,null],[44,null],[55,null],[61,null]],"Quark Pruning Tool Feature":[[107,"quark-pruning-tool-feature"]],"Quark UINT4 Quantization with AWQ":[[131,"quark-uint4-quantization-with-awq"]],"Quark and Dependencies":[[140,"quark-and-dependencies"]],"Quark for AMD Instinct Accelerators":[[125,null]],"Quark for Ryzen AI NPU":[[126,null]],"Quark license":[[21,null]],"Quark\u2019s contrib Area":[[20,null]],"Quick Start":[[117,"quick-start"]],"Quick Start for Ryzen AI":[[130,null]],"Quick start":[[116,"quick-start"]],"Recap - MNIST Fashion":[[140,"recap-mnist-fashion"]],"Recipe 1: Evaluation of Llama Float16 Model without Quantization":[[96,"recipe-1-evaluation-of-llama-float16-model-without-quantization"]],"Recipe 1: Evaluation of Llama2 Float16 Model without Pruning":[[95,"recipe-1-evaluation-of-llama2-float16-model-without-pruning"]],"Recipe 1: QAT Finetuning ChatGLM and Export to Safetensors using FSDP (The configuration variable ONLY_TRAIN_SCALING_FACTOR determines whether to only make scaling factor trainable, while keeping other parameters frozen)":[[97,"recipe-1-qat-finetuning-chatglm-and-export-to-safetensors-using-fsdp-the-configuration-variable-only-train-scaling-factor-determines-whether-to-only-make-scaling-factor-trainable-while-keeping-other-parameters-frozen"]],"Recipe 2: FP8 (OCP fp8_e4m3) Quantization & Json_SafeTensors_Export with KV Cache":[[96,"recipe-2-fp8-ocp-fp8-e4m3-quantization-json-safetensors-export-with-kv-cache"]],"Recipe 2: Pruning Model and Saved to Safetensors":[[95,"recipe-2-pruning-model-and-saved-to-safetensors"]],"Recipe 2: Reload and Evaluate QAT Finetuned Model":[[97,"recipe-2-reload-and-evaluate-qat-finetuned-model"]],"Recipe 3: Evaluate Original Non-Quantized Model":[[97,"recipe-3-evaluate-original-non-quantized-model"]],"Recipe 3: INT Weight-Only Quantization & Json_SafeTensors_Export with AWQ":[[96,"recipe-3-int-weight-only-quantization-json-safetensors-export-with-awq"]],"Recipe 4: INT Static Quantization & Json_SafeTensors_Export (on CPU)":[[96,"recipe-4-int-static-quantization-json-safetensors-export-on-cpu"]],"Recipe 5: Quantization & GGUF_Export with AWQ (W_uint4 A_float16 per_group asymmetric)":[[96,"recipe-5-quantization-gguf-export-with-awq-w-uint4-a-float16-per-group-asymmetric"]],"Recipe 6: OCP MX Quantization":[[96,"recipe-6-ocp-mx-quantization"]],"Recipe 7: BFP16 Quantization":[[96,"recipe-7-bfp16-quantization"]],"Recipe 8: MX6 Quantization":[[96,"recipe-8-mx6-quantization"]],"Recipe 9: Import Quantized Model & Evaluation":[[96,"recipe-9-import-quantized-model-evaluation"]],"Recipes":[[91,"recipes"],[93,"recipes"],[94,"recipes"]],"Recommended First Time User Installation":[[18,"recommended-first-time-user-installation"]],"Release 0.1.0":[[124,"release-0-1-0"]],"Release 0.10":[[124,"release-0-10"]],"Release 0.2.0":[[124,"release-0-2-0"]],"Release 0.5.0":[[124,"release-0-5-0"]],"Release 0.5.1":[[124,"release-0-5-1"]],"Release 0.6":[[124,"release-0-6"]],"Release 0.7":[[124,"release-0-7"]],"Release 0.8":[[124,"release-0-8"]],"Release 0.8.1":[[124,"release-0-8-1"]],"Release 0.8.2":[[124,"release-0-8-2"]],"Release 0.9":[[124,"release-0-9"]],"Release Notes":[[124,null]],"Replace inf and -inf Values in ONNX Model Weights":[[71,"replace-inf-and-inf-values-in-onnx-model-weights"]],"Resources":[[125,null],[126,null]],"Results":[[62,"results"],[65,"results"],[121,"results"]],"Results on ChatGLM3-6B":[[97,"results-on-chatglm3-6b"]],"Results on Phi-3-mini-4k-instruct":[[97,"results-on-phi-3-mini-4k-instruct"]],"Rotation-based quantization with QuaRot":[[120,null]],"Rouge & Meteor Evaluations":[[94,null]],"Rouge/Meteor on ONNX Models":[[94,"rouge-meteor-on-onnx-models"]],"Rouge/Meteor on Torch Models":[[94,"rouge-meteor-on-torch-models"]],"Run Diffusion Model Without Quantization":[[89,"run-diffusion-model-without-quantization"]],"Ryzen AI Quantization":[[68,null]],"Save & Load Quantized Models":[[114,null]],"Save the pruned model to the specified path":[[134,"save-the-pruned-model-to-the-specified-path"]],"Saving":[[114,"saving"]],"Search Config Settings":[[56,"search-config-settings"],[57,"search-config-settings"],[58,"search-config-settings"]],"Simulated Quantization":[[140,"simulated-quantization"]],"SmoothQuant (SQ)":[[25,null]],"Some Key Tech Feature":[[99,"some-key-tech-feature"]],"Some of GGUF dtypes and their corresponding quant schemes":[[100,"id3"]],"Step 1: Configuring QuantizationSpec for torch.Tensors":[[122,"step-1-configuring-quantizationspec-for-torch-tensors"]],"Step 1: Quantize Your Model":[[100,"step-1-quantize-your-model"]],"Step 2: Establishing QuantizationConfig for nn.Module":[[122,"step-2-establishing-quantizationconfig-for-nn-module"]],"Step 2: Export to GGUF":[[100,"step-2-export-to-gguf"]],"Step 3: Run with llama.cpp":[[100,"step-3-run-with-llama-cpp"]],"Step 3: [Optional] Setting AlgoConfig for the model":[[122,"step-3-optional-setting-algoconfig-for-the-model"]],"Step 4: Setting up the overall Config for the model.":[[122,"step-4-setting-up-the-overall-config-for-the-model"]],"Step-by-Step Integration":[[88,"step-by-step-integration"]],"Step-by-Step Process":[[92,"step-by-step-process"]],"Summary":[[35,"summary"],[36,"summary"],[37,"summary"],[38,"summary"],[39,"summary"],[40,"summary"]],"Summary Table":[[79,"summary-table"],[79,"quark-onnx-supported-ops"]],"Supported Data Types":[[79,"supported-data-types"]],"Supported Data and Op Types":[[79,null]],"Supported Methods Overview":[[107,"supported-methods-overview"]],"Supported Models":[[95,"supported-models"],[96,"supported-models"],[96,"id1"],[97,"supported-models"]],"Supported Op Type":[[79,"supported-op-type"]],"Supported Quantization Schemes":[[123,"supported-quantization-schemes"]],"Supported Tasks":[[92,"supported-tasks"]],"Test the Quantized Model Accuracy":[[140,"test-the-quantized-model-accuracy"]],"Testing Your Contribution":[[20,"testing-your-contribution"]],"Text Encoder":[[135,"text-encoder"]],"Text Encoding":[[139,"text-encoding"]],"Third-party Dependencies":[[89,"third-party-dependencies"]],"Tips:":[[70,"tips"]],"Tools":[[71,null]],"Transformers & Attention":[[139,"transformers-attention"]],"Troubleshooting":[[140,"troubleshooting"]],"Try Different Quantization Schemes":[[115,"try-different-quantization-schemes"]],"Try QAT":[[115,"try-qat"]],"Tutorial: Generating AWQ Configuration Automatically (Experimental)":[[96,"tutorial-generating-awq-configuration-automatically-experimental"]],"Tutorial: Running a Model Not on the Supported List":[[96,"tutorial-running-a-model-not-on-the-supported-list"]],"Tutorials":[[17,null],[135,"tutorials"]],"Tutorials/Articles":[[139,"tutorials-articles"]],"Two Level Quantization Formats (MX4, MX6, MX9: shared Microexponents)":[[81,null]],"Two-level Quantization: MX6 and MX9 Data Types":[[81,"two-level-quantization-mx6-and-mx9-data-types"]],"Type Constraints":[[35,"type-constraints"],[36,"type-constraints"],[37,"type-constraints"],[38,"type-constraints"],[39,"type-constraints"],[40,"type-constraints"]],"U-Net Model":[[135,"u-net-model"]],"Understanding the Network structure":[[116,"understanding-the-network-structure"]],"Understanding the network output":[[116,"understanding-the-network-output"]],"Upgrades of AdaRound / AdaQuant in AMD Quark for ONNX":[[22,"upgrades-of-adaround-adaquant-in-amd-quark-for-onnx"]],"Usage":[[77,"usage"],[96,"usage"]],"User Guide":[[90,"user-guide"]],"Using LLMTemplate for Quantization Configuration":[[123,"using-llmtemplate-for-quantization-configuration"]],"Using OCP MX (Microscaling)":[[80,null]],"Using ONNX Model Inference and Saving Input Data in NPY Format":[[34,null]],"Using Random Data for AMD Quark Quantizer":[[29,"using-random-data-for-amd-quark-quantizer"]],"Using SmoothQuant in quark.torch":[[118,"using-smoothquant-in-quark-torch"]],"Version":[[35,"version"],[36,"version"],[37,"version"],[38,"version"],[39,"version"],[40,"version"]],"Vision Model Quantization Using Quark FX Graph Mode":[[99,null]],"Weights-Only Quantization":[[68,null]],"Welcome to AMD Quark Documentation!":[[17,null]],"What Does This Mean?":[[19,"what-does-this-mean"]],"What Happens Internally in Quark When We Quantize Something?":[[19,"what-happens-internally-in-quark-when-we-quantize-something"]],"What Is GGUF":[[100,"what-is-gguf"]],"What Is Quantization?":[[19,"what-is-quantization"]],"What You Will Learn":[[135,"what-you-will-learn"],[139,"what-you-will-learn"],[140,"what-you-will-learn"]],"What content on this page:":[[87,"what-content-on-this-page"]],"What is MX Quantization?":[[75,"what-is-mx-quantization"]],"What is Microexponents Quantization?":[[74,"what-is-microexponents-quantization"]],"What is Mixed Precision Quantization?":[[76,"what-is-mixed-precision-quantization"]],"What is crypto mode":[[47,"what-is-crypto-mode"]],"When Are Values Actually Converted into Their Quantized Data Types?":[[19,"when-are-values-actually-converted-into-their-quantized-data-types"]],"Windows":[[18,"windows"],[18,"id3"]],"Working in crypto mode":[[47,"working-in-crypto-mode"]],"YOLO-NAS FX graph Quantization":[[116,null]],"YOLO-X Tiny FX Graph Quantization":[[117,null]],"Yolo_nas and Yolox Models":[[68,null]],"Yolo_nas and Yolox Quantization":[[62,null]],"inp":[[82,"inp"]],"layers":[[82,"layers"]],"model_decoder_layers":[[82,"model-decoder-layers"]],"module2inspect":[[82,"module2inspect"]],"prev_op":[[82,"prev-op"]],"scaling_layers":[[82,"scaling-layers"]]},"docnames":["autoapi/onnx_apis","autoapi/pytorch_apis","autoapi/quark/onnx/calibrate/index","autoapi/quark/onnx/onnx_quantizer/index","autoapi/quark/onnx/optimize/index","autoapi/quark/onnx/qdq_quantizer/index","autoapi/quark/onnx/quant_utils/index","autoapi/quark/onnx/quantization/api/index","autoapi/quark/onnx/quantization/config/config/index","autoapi/quark/torch/export/api/index","autoapi/quark/torch/export/config/config/index","autoapi/quark/torch/pruning/api/index","autoapi/quark/torch/pruning/config/index","autoapi/quark/torch/quantization/api/index","autoapi/quark/torch/quantization/config/config/index","autoapi/quark/torch/quantization/config/template/index","basic_usage","index","install","intro","intro_contrib","license","onnx/accuracy_algorithms/ada","onnx/accuracy_algorithms/cle","onnx/accuracy_algorithms/quarot","onnx/accuracy_algorithms/sq","onnx/accuracy_improvement_algorithms","onnx/appendix_full_quant_config_features","onnx/basic_usage_onnx","onnx/config/calibration_datasets","onnx/config/calibration_methods","onnx/config/quantization_schemes","onnx/config/quantization_strategies","onnx/config/quantization_symmetry","onnx/config/user_guide_onnx_model_inference_save_input_npy","onnx/custom_operators/BFPQuantizeDequantize","onnx/custom_operators/ExtendedDequantizeLinear","onnx/custom_operators/ExtendedInstanceNormalization","onnx/custom_operators/ExtendedLSTM","onnx/custom_operators/ExtendedQuantizeLinear","onnx/custom_operators/MXQuantizeDequantize","onnx/example_quark_onnx_BFP","onnx/example_quark_onnx_MX","onnx/example_quark_onnx_adaquant","onnx/example_quark_onnx_adaround","onnx/example_quark_onnx_auto_search","onnx/example_quark_onnx_cle","onnx/example_quark_onnx_crypto_mode","onnx/example_quark_onnx_dynamic_quantization_llama2","onnx/example_quark_onnx_dynamic_quantization_opt","onnx/example_quark_onnx_gptq","onnx/example_quark_onnx_image_classification","onnx/example_quark_onnx_language_models","onnx/example_quark_onnx_layerwise_percentile","onnx/example_quark_onnx_mixed_precision","onnx/example_quark_onnx_quarot","onnx/example_quark_onnx_ryzenai","onnx/example_quark_onnx_ryzenai_yolonas","onnx/example_quark_onnx_ryzenai_yolov3_custom_evaluator","onnx/example_quark_onnx_smoothquant","onnx/example_quark_onnx_weights_only_quant_int4_matmul_nbits_llama2","onnx/example_quark_onnx_weights_only_quant_int8_qdq_llama2","onnx/example_quark_onnx_yolo_quantization","onnx/example_ryzenai_autosearch_resnet50","onnx/gpu_usage_guide","onnx/hugging_face_timm_quantization","onnx/image_classification_example_quark_onnx_ryzen_ai_best_practice","onnx/object_detection_example_quark_onnx_ryzen_ai_best_practice","onnx/onnx_examples","onnx/onnx_faq","onnx/optional_utilities","onnx/tools","onnx/tutorial_bf16_quantization","onnx/tutorial_bfp16_quantization","onnx/tutorial_microexponents_quantization","onnx/tutorial_microscaling_quantization","onnx/tutorial_mix_precision","onnx/user_guide_auto_search","onnx/user_guide_config_description","onnx/user_guide_supported_optype_datatype","pytorch/adv_mx","pytorch/adv_two_level","pytorch/awq_document","pytorch/basic_usage_pytorch","pytorch/calibration_datasets","pytorch/calibration_methods","pytorch/debug","pytorch/example_quark_fx_image_classification","pytorch/example_quark_torch_brevitas","pytorch/example_quark_torch_diffusers","pytorch/example_quark_torch_llm_eval","pytorch/example_quark_torch_llm_eval_harness","pytorch/example_quark_torch_llm_eval_harness_offline","pytorch/example_quark_torch_llm_eval_perplexity","pytorch/example_quark_torch_llm_eval_rouge_meteor","pytorch/example_quark_torch_llm_pruning","pytorch/example_quark_torch_llm_ptq","pytorch/example_quark_torch_llm_qat","pytorch/example_quark_torch_pytorch_light","pytorch/example_quark_torch_vision","pytorch/export/gguf_llamacpp","pytorch/export/quark_export","pytorch/export/quark_export_gguf","pytorch/export/quark_export_hf","pytorch/export/quark_export_onnx","pytorch/export/quark_export_quark","pytorch/extensions","pytorch/feature_pruning_overall","pytorch/llm_quark","pytorch/pytorch_examples","pytorch/pytorch_faq","pytorch/quantization_schemes","pytorch/quantization_strategies","pytorch/quantization_symmetry","pytorch/quark_save_load","pytorch/quark_torch_best_practices","pytorch/sample_yolo_nas_quant","pytorch/sample_yolo_x_tiny_quant","pytorch/smoothquant","pytorch/tutorial_bfp16","pytorch/tutorial_quarot","pytorch/tutorial_rotation","pytorch/user_guide_config_description","pytorch/user_guide_config_for_llm","release_note","supported_accelerators/mi_gpus/index","supported_accelerators/ryzenai/index","supported_accelerators/ryzenai/ryzen_ai_best_practice","supported_accelerators/ryzenai/tutorial_a8w8_and_a16w8_quantize","supported_accelerators/ryzenai/tutorial_convert_fp32_or_fp16_to_bf16","supported_accelerators/ryzenai/tutorial_quick_start_for_ryzenai","supported_accelerators/ryzenai/tutorial_uint4_oga","supported_accelerators/ryzenai/tutorial_xint8_quantize","tutorials/torch/auto_smoothquant_document_and_example","tutorials/torch/depth_wise_pruning/llm_depth_pruning","tutorials/torch/diffusion_tutorial/diffusion_tutorial","tutorials/torch/example_awq","tutorials/torch/example_fp4","tutorials/torch/example_fp8","tutorials/torch/llm_tutorial/llm_tutorial","tutorials/torch/quickstart_tutorial/quickstart_tutorial","versions"],"envversion":{"sphinx":65,"sphinx.domains.c":3,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":9,"sphinx.domains.index":1,"sphinx.domains.javascript":3,"sphinx.domains.math":2,"sphinx.domains.python":4,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,"sphinx.ext.todo":2,"sphinx.ext.viewcode":1},"filenames":["autoapi/onnx_apis.rst","autoapi/pytorch_apis.rst","autoapi/quark/onnx/calibrate/index.rst","autoapi/quark/onnx/onnx_quantizer/index.rst","autoapi/quark/onnx/optimize/index.rst","autoapi/quark/onnx/qdq_quantizer/index.rst","autoapi/quark/onnx/quant_utils/index.rst","autoapi/quark/onnx/quantization/api/index.rst","autoapi/quark/onnx/quantization/config/config/index.rst","autoapi/quark/torch/export/api/index.rst","autoapi/quark/torch/export/config/config/index.rst","autoapi/quark/torch/pruning/api/index.rst","autoapi/quark/torch/pruning/config/index.rst","autoapi/quark/torch/quantization/api/index.rst","autoapi/quark/torch/quantization/config/config/index.rst","autoapi/quark/torch/quantization/config/template/index.rst","basic_usage.rst","index.rst","install.rst","intro.rst","intro_contrib.rst","license.md","onnx/accuracy_algorithms/ada.rst","onnx/accuracy_algorithms/cle.rst","onnx/accuracy_algorithms/quarot.rst","onnx/accuracy_algorithms/sq.rst","onnx/accuracy_improvement_algorithms.rst","onnx/appendix_full_quant_config_features.rst","onnx/basic_usage_onnx.rst","onnx/config/calibration_datasets.rst","onnx/config/calibration_methods.rst","onnx/config/quantization_schemes.rst","onnx/config/quantization_strategies.rst","onnx/config/quantization_symmetry.rst","onnx/config/user_guide_onnx_model_inference_save_input_npy.rst","onnx/custom_operators/BFPQuantizeDequantize.rst","onnx/custom_operators/ExtendedDequantizeLinear.rst","onnx/custom_operators/ExtendedInstanceNormalization.rst","onnx/custom_operators/ExtendedLSTM.rst","onnx/custom_operators/ExtendedQuantizeLinear.rst","onnx/custom_operators/MXQuantizeDequantize.rst","onnx/example_quark_onnx_BFP.rst","onnx/example_quark_onnx_MX.rst","onnx/example_quark_onnx_adaquant.rst","onnx/example_quark_onnx_adaround.rst","onnx/example_quark_onnx_auto_search.rst","onnx/example_quark_onnx_cle.rst","onnx/example_quark_onnx_crypto_mode.rst","onnx/example_quark_onnx_dynamic_quantization_llama2.rst","onnx/example_quark_onnx_dynamic_quantization_opt.rst","onnx/example_quark_onnx_gptq.rst","onnx/example_quark_onnx_image_classification.rst","onnx/example_quark_onnx_language_models.rst","onnx/example_quark_onnx_layerwise_percentile.rst","onnx/example_quark_onnx_mixed_precision.rst","onnx/example_quark_onnx_quarot.rst","onnx/example_quark_onnx_ryzenai.rst","onnx/example_quark_onnx_ryzenai_yolonas.rst","onnx/example_quark_onnx_ryzenai_yolov3_custom_evaluator.rst","onnx/example_quark_onnx_smoothquant.rst","onnx/example_quark_onnx_weights_only_quant_int4_matmul_nbits_llama2.rst","onnx/example_quark_onnx_weights_only_quant_int8_qdq_llama2.rst","onnx/example_quark_onnx_yolo_quantization.rst","onnx/example_ryzenai_autosearch_resnet50.rst","onnx/gpu_usage_guide.rst","onnx/hugging_face_timm_quantization.rst","onnx/image_classification_example_quark_onnx_ryzen_ai_best_practice.rst","onnx/object_detection_example_quark_onnx_ryzen_ai_best_practice.rst","onnx/onnx_examples.rst","onnx/onnx_faq.rst","onnx/optional_utilities.rst","onnx/tools.rst","onnx/tutorial_bf16_quantization.rst","onnx/tutorial_bfp16_quantization.rst","onnx/tutorial_microexponents_quantization.rst","onnx/tutorial_microscaling_quantization.rst","onnx/tutorial_mix_precision.rst","onnx/user_guide_auto_search.rst","onnx/user_guide_config_description.rst","onnx/user_guide_supported_optype_datatype.rst","pytorch/adv_mx.rst","pytorch/adv_two_level.rst","pytorch/awq_document.rst","pytorch/basic_usage_pytorch.rst","pytorch/calibration_datasets.rst","pytorch/calibration_methods.rst","pytorch/debug.rst","pytorch/example_quark_fx_image_classification.rst","pytorch/example_quark_torch_brevitas.rst","pytorch/example_quark_torch_diffusers.rst","pytorch/example_quark_torch_llm_eval.rst","pytorch/example_quark_torch_llm_eval_harness.rst","pytorch/example_quark_torch_llm_eval_harness_offline.rst","pytorch/example_quark_torch_llm_eval_perplexity.rst","pytorch/example_quark_torch_llm_eval_rouge_meteor.rst","pytorch/example_quark_torch_llm_pruning.rst","pytorch/example_quark_torch_llm_ptq.rst","pytorch/example_quark_torch_llm_qat.rst","pytorch/example_quark_torch_pytorch_light.rst","pytorch/example_quark_torch_vision.rst","pytorch/export/gguf_llamacpp.rst","pytorch/export/quark_export.rst","pytorch/export/quark_export_gguf.rst","pytorch/export/quark_export_hf.rst","pytorch/export/quark_export_onnx.rst","pytorch/export/quark_export_quark.rst","pytorch/extensions.rst","pytorch/feature_pruning_overall.rst","pytorch/llm_quark.rst","pytorch/pytorch_examples.rst","pytorch/pytorch_faq.rst","pytorch/quantization_schemes.rst","pytorch/quantization_strategies.rst","pytorch/quantization_symmetry.rst","pytorch/quark_save_load.rst","pytorch/quark_torch_best_practices.rst","pytorch/sample_yolo_nas_quant.rst","pytorch/sample_yolo_x_tiny_quant.rst","pytorch/smoothquant.rst","pytorch/tutorial_bfp16.rst","pytorch/tutorial_quarot.rst","pytorch/tutorial_rotation.rst","pytorch/user_guide_config_description.rst","pytorch/user_guide_config_for_llm.rst","release_note.rst","supported_accelerators/mi_gpus/index.rst","supported_accelerators/ryzenai/index.rst","supported_accelerators/ryzenai/ryzen_ai_best_practice.rst","supported_accelerators/ryzenai/tutorial_a8w8_and_a16w8_quantize.rst","supported_accelerators/ryzenai/tutorial_convert_fp32_or_fp16_to_bf16.rst","supported_accelerators/ryzenai/tutorial_quick_start_for_ryzenai.rst","supported_accelerators/ryzenai/tutorial_uint4_oga.rst","supported_accelerators/ryzenai/tutorial_xint8_quantize.rst","tutorials/torch/auto_smoothquant_document_and_example.rst","tutorials/torch/depth_wise_pruning/llm_depth_pruning.rst","tutorials/torch/diffusion_tutorial/diffusion_tutorial.rst","tutorials/torch/example_awq.rst","tutorials/torch/example_fp4.rst","tutorials/torch/example_fp8.rst","tutorials/torch/llm_tutorial/llm_tutorial.rst","tutorials/torch/quickstart_tutorial/quickstart_tutorial.rst","versions.md"],"indexentries":{"algoconfig (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.AlgoConfig",false]],"algoconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.AlgoConfig",false]],"algoconfigbase (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.AlgoConfigBase",false]],"algoconfigbase (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.AlgoConfigBase",false]],"autosmoothquantconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.AutoSmoothQuantConfig",false]],"awqconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.AWQConfig",false]],"bfloat16spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Bfloat16Spec",false]],"bfp16scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.BFP16Scheme",false]],"bfp16spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.BFP16Spec",false]],"blockwisetuningconfig (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.BlockwiseTuningConfig",false]],"cache_onnx_model_and_infer_shapes() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.cache_onnx_model_and_infer_shapes",false]],"calculate_quantization_params() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.calculate_quantization_params",false]],"check_hard_sigmoid_condition() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.check_hard_sigmoid_condition",false]],"check_model_quantizable() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.check_model_quantizable",false]],"check_onnx_model() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.check_onnx_model",false]],"check_reduce_mean_condition() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.check_reduce_mean_condition",false]],"check_relu_like_node() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.check_relu_like_node",false]],"compute_scale_zp() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.compute_scale_zp",false]],"compute_scale_zp_fp() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.compute_scale_zp_fp",false]],"config (class in quark.onnx.quantization.config.config)":[[8,"quark.onnx.quantization.config.config.Config",false]],"config (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.Config",false]],"config (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Config",false]],"configbase (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.ConfigBase",false]],"configbase (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.ConfigBase",false]],"convert_bn_to_conv() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.convert_bn_to_conv",false]],"convert_clip_to_relu() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.convert_clip_to_relu",false]],"convert_reduce_mean_to_global_avg_pool() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.convert_reduce_mean_to_global_avg_pool",false]],"convert_split_to_slice() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.convert_split_to_slice",false]],"create_infer_session_for_onnx_model() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.create_infer_session_for_onnx_model",false]],"customqdq_to_contribqdq() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.customqdq_to_contribqdq",false]],"datatypespec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.DataTypeSpec",false]],"decrypt_data() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.decrypt_data",false]],"dequantize_data() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.dequantize_data",false]],"dpu_leaky_relu_alpha() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.dpu_leaky_relu_alpha",false]],"encrypt_data() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.encrypt_data",false]],"export_gguf() (in module quark.torch.export.api)":[[9,"quark.torch.export.api.export_gguf",false]],"export_gguf_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.export_gguf_model",false]],"export_onnx() (in module quark.torch.export.api)":[[9,"quark.torch.export.api.export_onnx",false]],"export_onnx_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.export_onnx_model",false]],"export_quark_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.export_quark_model",false]],"export_safetensors() (in module quark.torch.export.api)":[[9,"quark.torch.export.api.export_safetensors",false]],"export_safetensors_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.export_safetensors_model",false]],"exporterconfig (class in quark.torch.export.config.config)":[[10,"quark.torch.export.config.config.ExporterConfig",false]],"extendedquantformat (class in quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.ExtendedQuantFormat",false]],"extendedquanttype (class in quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.ExtendedQuantType",false]],"fake_calibration() (in module quark.onnx.calibration.interface)":[[2,"quark.onnx.calibration.interface.fake_calibration",false]],"find_int16_scale() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.find_int16_scale",false]],"find_quant_scale_zp() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.find_quant_scale_zp",false]],"find_quantized_value() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.find_quantized_value",false]],"float16spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Float16Spec",false]],"fold_batch_norm() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.fold_batch_norm",false]],"fold_batch_norm_after_concat() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.fold_batch_norm_after_concat",false]],"fp4pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP4PerGroupSpec",false]],"fp6e2m3pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP6E2M3PerGroupSpec",false]],"fp6e3m2pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP6E3M2PerGroupSpec",false]],"fp8e4m3perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E4M3PerChannelSpec",false]],"fp8e4m3pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E4M3PerGroupSpec",false]],"fp8e4m3pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E4M3PerTensorSpec",false]],"fp8e5m2perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E5M2PerChannelSpec",false]],"fp8e5m2pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E5M2PerGroupSpec",false]],"fp8e5m2pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.FP8E5M2PerTensorSpec",false]],"fp8scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.FP8Scheme",false]],"freeze() (quark.torch.quantization.api.modelquantizer static method)":[[13,"quark.torch.quantization.api.ModelQuantizer.freeze",false]],"fuse_instance_norm() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.fuse_instance_norm",false]],"fuse_l2_norm() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.fuse_l2_norm",false]],"get() (quark.torch.quantization.config.template.llmtemplate class method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.get",false]],"get_annotate_tensors() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_annotate_tensors",false]],"get_clip_min_max() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_clip_min_max",false]],"get_config() (quark.torch.quantization.config.template.llmtemplate method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.get_config",false]],"get_datatype_shape() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_datatype_shape",false]],"get_default_config() (quark.onnx.quantization.config.config.qconfig static method)":[[8,"quark.onnx.quantization.config.config.QConfig.get_default_config",false]],"get_exclude_nodes() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_exclude_nodes",false]],"get_export_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.get_export_model",false]],"get_qdq_to_remove() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_qdq_to_remove",false]],"get_qmin_qmax_for_qtype() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_qmin_qmax_for_qType",false]],"get_qrange_for_qtype() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.get_qrange_for_qType",false]],"get_scheme() (quark.torch.quantization.config.template.quantizationschemecollection method)":[[15,"quark.torch.quantization.config.template.QuantizationSchemeCollection.get_scheme",false]],"get_supported_schemes() (quark.torch.quantization.config.template.quantizationschemecollection method)":[[15,"quark.torch.quantization.config.template.QuantizationSchemeCollection.get_supported_schemes",false]],"gptqconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.GPTQConfig",false]],"import_model_from_safetensors() (in module quark.torch.export.api)":[[9,"quark.torch.export.api.import_model_from_safetensors",false]],"import_model_info() (quark.torch.export.api.modelimporter method)":[[9,"quark.torch.export.api.ModelImporter.import_model_info",false]],"infer_shape() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.infer_shape",false]],"int2pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int2PerGroupSpec",false]],"int3perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int3PerChannelSpec",false]],"int3pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int3PerGroupSpec",false]],"int4perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int4PerChannelSpec",false]],"int4pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int4PerGroupSpec",false]],"int4pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int4PerTensorSpec",false]],"int4weightonlyscheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.Int4WeightOnlyScheme",false]],"int8perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int8PerChannelSpec",false]],"int8pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int8PerGroupSpec",false]],"int8pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Int8PerTensorSpec",false]],"int8scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.Int8Scheme",false]],"is_approximately_equal() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.is_approximately_equal",false]],"is_clip_with_min_max() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.is_clip_with_min_max",false]],"is_leaky_relu_with_alpha() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.is_leaky_relu_with_alpha",false]],"is_node_needs_annotated() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.is_node_needs_annotated",false]],"is_version_below() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.is_version_below",false]],"jsonexporterconfig (class in quark.torch.export.config.config)":[[10,"quark.torch.export.config.config.JsonExporterConfig",false]],"layerimportancepruneconfig (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.LayerImportancePruneConfig",false]],"list_available() (quark.torch.quantization.config.template.llmtemplate class method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.list_available",false]],"llmtemplate (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.LLMTemplate",false]],"load_params() (in module quark.torch.quantization.api)":[[13,"quark.torch.quantization.api.load_params",false]],"load_pre_optimization_config_from_file() (in module quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.load_pre_optimization_config_from_file",false]],"load_quant_algo_config_from_file() (in module quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.load_quant_algo_config_from_file",false]],"modelexporter (class in quark.torch.export.api)":[[9,"quark.torch.export.api.ModelExporter",false]],"modelimporter (class in quark.torch.export.api)":[[9,"quark.torch.export.api.ModelImporter",false]],"modelpruner (class in quark.torch.pruning.api)":[[11,"quark.torch.pruning.api.ModelPruner",false]],"modelquantizer (class in quark.onnx.quantization.api)":[[7,"quark.onnx.quantization.api.ModelQuantizer",false]],"modelquantizer (class in quark.torch.quantization.api)":[[13,"quark.torch.quantization.api.ModelQuantizer",false]],"modified_annotate_input() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.modified_annotate_input",false]],"module":[[2,"module-quark.onnx.calibration.interface",false],[3,"module-quark.onnx.onnx_quantizer",false],[4,"module-quark.onnx.optimize",false],[5,"module-quark.onnx.qdq_quantizer",false],[6,"module-quark.onnx.quant_utils",false],[7,"module-quark.onnx.quantization.api",false],[8,"module-quark.onnx.quantization.config.config",false],[9,"module-quark.torch.export.api",false],[10,"module-quark.torch.export.config.config",false],[11,"module-quark.torch.pruning.api",false],[12,"module-quark.torch.pruning.config",false],[13,"module-quark.torch.quantization.api",false],[14,"module-quark.torch.quantization.config.config",false],[15,"module-quark.torch.quantization.config.template",false]],"mx6scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.MX6Scheme",false]],"mx6spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.MX6Spec",false]],"mx9spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.MX9Spec",false]],"mxfp4scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.MXFP4Scheme",false]],"mxfp6e2m3scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.MXFP6E2M3Scheme",false]],"mxfp6e3m2scheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.MXFP6E3M2Scheme",false]],"ocp_mxfp4diffsspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP4DiffsSpec",false]],"ocp_mxfp4spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP4Spec",false]],"ocp_mxfp6e2m3spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP6E2M3Spec",false]],"ocp_mxfp6e3m2spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP6E3M2Spec",false]],"ocp_mxfp8e4m3spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP8E4M3Spec",false]],"ocp_mxfp8e5m2spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXFP8E5M2Spec",false]],"ocp_mxint8spec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXINT8Spec",false]],"ocp_mxspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.OCP_MXSpec",false]],"onnx_load_model_with_decryption() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.onnx_load_model_with_decryption",false]],"onnx_save_model_with_encryption() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.onnx_save_model_with_encryption",false]],"onnxexporterconfig (class in quark.torch.export.config.config)":[[10,"quark.torch.export.config.config.OnnxExporterConfig",false]],"onnxquantizer (class in quark.onnx.onnx_quantizer)":[[3,"quark.onnx.onnx_quantizer.ONNXQuantizer",false]],"optimize (class in quark.onnx.optimize)":[[4,"quark.onnx.optimize.Optimize",false]],"optimize() (in module quark.onnx.optimize)":[[4,"quark.onnx.optimize.optimize",false]],"osscarconfig (class in quark.torch.pruning.config)":[[12,"quark.torch.pruning.config.OSSCARConfig",false]],"pos2scale() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.pos2scale",false]],"prequantoptconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.PreQuantOptConfig",false]],"print_quantize_dynamic_info() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.print_quantize_dynamic_info",false]],"print_quantize_info() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.print_quantize_info",false]],"progressivespec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.ProgressiveSpec",false]],"pruning_model() (quark.torch.pruning.api.modelpruner method)":[[11,"quark.torch.pruning.api.ModelPruner.pruning_model",false]],"qatspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.QATSpec",false]],"qconfig (class in quark.onnx.quantization.config.config)":[[8,"quark.onnx.quantization.config.config.QConfig",false]],"qdqnputransformerquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.QDQNPUTransformerQuantizer",false]],"qdqquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.QDQQuantizer",false]],"qronosconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.QronosConfig",false]],"quantizationconfig (class in quark.onnx.quantization.config.config)":[[8,"quark.onnx.quantization.config.config.QuantizationConfig",false]],"quantizationconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.QuantizationConfig",false]],"quantizationscheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.QuantizationScheme",false]],"quantizationschemecollection (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.QuantizationSchemeCollection",false]],"quantizationspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.QuantizationSpec",false]],"quantize_bias_static() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.quantize_bias_static",false]],"quantize_bias_tensor() (quark.onnx.qdq_quantizer.qdqnputransformerquantizer method)":[[5,"quark.onnx.qdq_quantizer.QDQNPUTransformerQuantizer.quantize_bias_tensor",false]],"quantize_bias_tensor() (quark.onnx.qdq_quantizer.qdqquantizer method)":[[5,"quark.onnx.qdq_quantizer.QDQQuantizer.quantize_bias_tensor",false]],"quantize_data() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.quantize_data",false]],"quantize_initializer() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.quantize_initializer",false]],"quantize_model() (quark.onnx.quantization.api.modelquantizer method)":[[7,"quark.onnx.quantization.api.ModelQuantizer.quantize_model",false]],"quantize_model() (quark.torch.quantization.api.modelquantizer method)":[[13,"quark.torch.quantization.api.ModelQuantizer.quantize_model",false]],"quantize_weight() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.quantize_weight",false]],"quantize_weight_per_channel() (quark.onnx.onnx_quantizer.vitisonnxquantizer method)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer.quantize_weight_per_channel",false]],"quark.onnx.calibration.interface":[[2,"module-quark.onnx.calibration.interface",false]],"quark.onnx.onnx_quantizer":[[3,"module-quark.onnx.onnx_quantizer",false]],"quark.onnx.optimize":[[4,"module-quark.onnx.optimize",false]],"quark.onnx.qdq_quantizer":[[5,"module-quark.onnx.qdq_quantizer",false]],"quark.onnx.quant_utils":[[6,"module-quark.onnx.quant_utils",false]],"quark.onnx.quantization.api":[[7,"module-quark.onnx.quantization.api",false]],"quark.onnx.quantization.config.config":[[8,"module-quark.onnx.quantization.config.config",false]],"quark.torch.export.api":[[9,"module-quark.torch.export.api",false]],"quark.torch.export.config.config":[[10,"module-quark.torch.export.config.config",false]],"quark.torch.pruning.api":[[11,"module-quark.torch.pruning.api",false]],"quark.torch.pruning.config":[[12,"module-quark.torch.pruning.config",false]],"quark.torch.quantization.api":[[13,"module-quark.torch.quantization.api",false]],"quark.torch.quantization.config.config":[[14,"module-quark.torch.quantization.config.config",false]],"quark.torch.quantization.config.template":[[15,"module-quark.torch.quantization.config.template",false]],"quarotconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.QuaRotConfig",false]],"register_scheme() (quark.torch.quantization.config.template.llmtemplate class method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.register_scheme",false]],"register_scheme() (quark.torch.quantization.config.template.quantizationschemecollection method)":[[15,"quark.torch.quantization.config.template.QuantizationSchemeCollection.register_scheme",false]],"register_template() (quark.torch.quantization.config.template.llmtemplate class method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.register_template",false]],"remove_initializers() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.remove_initializers",false]],"remove_nodes() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.remove_nodes",false]],"reset_model() (quark.torch.export.api.modelexporter method)":[[9,"quark.torch.export.api.ModelExporter.reset_model",false]],"rotationconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.RotationConfig",false]],"run_calibration() (in module quark.onnx.calibration.interface)":[[2,"quark.onnx.calibration.interface.run_calibration",false]],"run_onnx_model() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.run_onnx_model",false]],"save_onnx_model_with_external_data() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.save_onnx_model_with_external_data",false]],"save_params() (in module quark.torch.export.api)":[[9,"quark.torch.export.api.save_params",false]],"scale2pos() (in module quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.scale2pos",false]],"scalequantspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.ScaleQuantSpec",false]],"smoothquantconfig (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.SmoothQuantConfig",false]],"split_large_kernel_pool() (quark.onnx.optimize.optimize method)":[[4,"quark.onnx.optimize.Optimize.split_large_kernel_pool",false]],"tqtspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.TQTSpec",false]],"twostagespec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.TwoStageSpec",false]],"uint4perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint4PerChannelSpec",false]],"uint4pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint4PerGroupSpec",false]],"uint4pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint4PerTensorSpec",false]],"uint4weightonlyscheme (class in quark.torch.quantization.config.template)":[[15,"quark.torch.quantization.config.template.Uint4WeightOnlyScheme",false]],"uint8perchannelspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint8PerChannelSpec",false]],"uint8pergroupspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint8PerGroupSpec",false]],"uint8pertensorspec (class in quark.torch.quantization.config.config)":[[14,"quark.torch.quantization.config.config.Uint8PerTensorSpec",false]],"unregister_scheme() (quark.torch.quantization.config.template.llmtemplate class method)":[[15,"quark.torch.quantization.config.template.LLMTemplate.unregister_scheme",false]],"unregister_scheme() (quark.torch.quantization.config.template.quantizationschemecollection method)":[[15,"quark.torch.quantization.config.template.QuantizationSchemeCollection.unregister_scheme",false]],"vitisbfpquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.VitisBFPQuantizer",false]],"vitisextendedquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.VitisExtendedQuantizer",false]],"vitisonnxquantizer (class in quark.onnx.onnx_quantizer)":[[3,"quark.onnx.onnx_quantizer.VitisONNXQuantizer",false]],"vitisqdqnpucnnquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.VitisQDQNPUCNNQuantizer",false]],"vitisqdqquantizer (class in quark.onnx.qdq_quantizer)":[[5,"quark.onnx.qdq_quantizer.VitisQDQQuantizer",false]],"vitisquantformat (class in quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.VitisQuantFormat",false]],"vitisquanttype (class in quark.onnx.quant_utils)":[[6,"quark.onnx.quant_utils.VitisQuantType",false]]},"objects":{"quark.onnx":[[3,0,0,"-","onnx_quantizer"],[4,0,0,"-","optimize"],[5,0,0,"-","qdq_quantizer"],[6,0,0,"-","quant_utils"]],"quark.onnx.calibration":[[2,0,0,"-","interface"]],"quark.onnx.calibration.interface":[[2,1,1,"","fake_calibration"],[2,1,1,"","run_calibration"]],"quark.onnx.onnx_quantizer":[[3,2,1,"","ONNXQuantizer"],[3,2,1,"","VitisONNXQuantizer"]],"quark.onnx.onnx_quantizer.VitisONNXQuantizer":[[3,3,1,"","calculate_quantization_params"],[3,3,1,"","find_quant_scale_zp"],[3,3,1,"","find_quantized_value"],[3,3,1,"","quantize_bias_static"],[3,3,1,"","quantize_initializer"],[3,3,1,"","quantize_weight"],[3,3,1,"","quantize_weight_per_channel"]],"quark.onnx.optimize":[[4,2,1,"","Optimize"],[4,1,1,"","optimize"]],"quark.onnx.optimize.Optimize":[[4,3,1,"","convert_bn_to_conv"],[4,3,1,"","convert_clip_to_relu"],[4,3,1,"","convert_reduce_mean_to_global_avg_pool"],[4,3,1,"","convert_split_to_slice"],[4,3,1,"","fold_batch_norm"],[4,3,1,"","fold_batch_norm_after_concat"],[4,3,1,"","fuse_instance_norm"],[4,3,1,"","fuse_l2_norm"],[4,3,1,"","split_large_kernel_pool"]],"quark.onnx.qdq_quantizer":[[5,2,1,"","QDQNPUTransformerQuantizer"],[5,2,1,"","QDQQuantizer"],[5,2,1,"","VitisBFPQuantizer"],[5,2,1,"","VitisExtendedQuantizer"],[5,2,1,"","VitisQDQNPUCNNQuantizer"],[5,2,1,"","VitisQDQQuantizer"]],"quark.onnx.qdq_quantizer.QDQNPUTransformerQuantizer":[[5,3,1,"","quantize_bias_tensor"]],"quark.onnx.qdq_quantizer.QDQQuantizer":[[5,3,1,"","quantize_bias_tensor"]],"quark.onnx.quant_utils":[[6,2,1,"","ExtendedQuantFormat"],[6,2,1,"","ExtendedQuantType"],[6,2,1,"","VitisQuantFormat"],[6,2,1,"","VitisQuantType"],[6,1,1,"","cache_onnx_model_and_infer_shapes"],[6,1,1,"","check_hard_sigmoid_condition"],[6,1,1,"","check_model_quantizable"],[6,1,1,"","check_onnx_model"],[6,1,1,"","check_reduce_mean_condition"],[6,1,1,"","check_relu_like_node"],[6,1,1,"","compute_scale_zp"],[6,1,1,"","compute_scale_zp_fp"],[6,1,1,"","create_infer_session_for_onnx_model"],[6,1,1,"","customqdq_to_contribqdq"],[6,1,1,"","decrypt_data"],[6,1,1,"","dequantize_data"],[6,1,1,"","dpu_leaky_relu_alpha"],[6,1,1,"","encrypt_data"],[6,1,1,"","find_int16_scale"],[6,1,1,"","get_annotate_tensors"],[6,1,1,"","get_clip_min_max"],[6,1,1,"","get_datatype_shape"],[6,1,1,"","get_exclude_nodes"],[6,1,1,"","get_qdq_to_remove"],[6,1,1,"","get_qmin_qmax_for_qType"],[6,1,1,"","get_qrange_for_qType"],[6,1,1,"","infer_shape"],[6,1,1,"","is_approximately_equal"],[6,1,1,"","is_clip_with_min_max"],[6,1,1,"","is_leaky_relu_with_alpha"],[6,1,1,"","is_node_needs_annotated"],[6,1,1,"","is_version_below"],[6,1,1,"","modified_annotate_input"],[6,1,1,"","onnx_load_model_with_decryption"],[6,1,1,"","onnx_save_model_with_encryption"],[6,1,1,"","pos2scale"],[6,1,1,"","print_quantize_dynamic_info"],[6,1,1,"","print_quantize_info"],[6,1,1,"","quantize_data"],[6,1,1,"","remove_initializers"],[6,1,1,"","remove_nodes"],[6,1,1,"","run_onnx_model"],[6,1,1,"","save_onnx_model_with_external_data"],[6,1,1,"","scale2pos"]],"quark.onnx.quantization":[[7,0,0,"-","api"]],"quark.onnx.quantization.api":[[7,2,1,"","ModelQuantizer"]],"quark.onnx.quantization.api.ModelQuantizer":[[7,3,1,"","quantize_model"]],"quark.onnx.quantization.config":[[8,0,0,"-","config"]],"quark.onnx.quantization.config.config":[[8,2,1,"","Config"],[8,2,1,"","QConfig"],[8,2,1,"","QuantizationConfig"]],"quark.onnx.quantization.config.config.QConfig":[[8,3,1,"","get_default_config"]],"quark.torch.export":[[9,0,0,"-","api"]],"quark.torch.export.api":[[9,2,1,"","ModelExporter"],[9,2,1,"","ModelImporter"],[9,1,1,"","export_gguf"],[9,1,1,"","export_onnx"],[9,1,1,"","export_safetensors"],[9,1,1,"","import_model_from_safetensors"],[9,1,1,"","save_params"]],"quark.torch.export.api.ModelExporter":[[9,3,1,"","export_gguf_model"],[9,3,1,"","export_onnx_model"],[9,3,1,"","export_quark_model"],[9,3,1,"","export_safetensors_model"],[9,3,1,"","get_export_model"],[9,3,1,"","reset_model"]],"quark.torch.export.api.ModelImporter":[[9,3,1,"","import_model_info"]],"quark.torch.export.config":[[10,0,0,"-","config"]],"quark.torch.export.config.config":[[10,2,1,"","ExporterConfig"],[10,2,1,"","JsonExporterConfig"],[10,2,1,"","OnnxExporterConfig"]],"quark.torch.pruning":[[11,0,0,"-","api"],[12,0,0,"-","config"]],"quark.torch.pruning.api":[[11,2,1,"","ModelPruner"]],"quark.torch.pruning.api.ModelPruner":[[11,3,1,"","pruning_model"]],"quark.torch.pruning.config":[[12,2,1,"","AlgoConfig"],[12,2,1,"","AlgoConfigBase"],[12,2,1,"","BlockwiseTuningConfig"],[12,2,1,"","Config"],[12,2,1,"","ConfigBase"],[12,2,1,"","LayerImportancePruneConfig"],[12,2,1,"","OSSCARConfig"]],"quark.torch.quantization":[[13,0,0,"-","api"]],"quark.torch.quantization.api":[[13,2,1,"","ModelQuantizer"],[13,1,1,"","load_params"]],"quark.torch.quantization.api.ModelQuantizer":[[13,3,1,"","freeze"],[13,3,1,"","quantize_model"]],"quark.torch.quantization.config":[[14,0,0,"-","config"],[15,0,0,"-","template"]],"quark.torch.quantization.config.config":[[14,2,1,"","AWQConfig"],[14,2,1,"","AlgoConfig"],[14,2,1,"","AlgoConfigBase"],[14,2,1,"","AutoSmoothQuantConfig"],[14,2,1,"","BFP16Spec"],[14,2,1,"","Bfloat16Spec"],[14,2,1,"","Config"],[14,2,1,"","ConfigBase"],[14,2,1,"","DataTypeSpec"],[14,2,1,"","FP4PerGroupSpec"],[14,2,1,"","FP6E2M3PerGroupSpec"],[14,2,1,"","FP6E3M2PerGroupSpec"],[14,2,1,"","FP8E4M3PerChannelSpec"],[14,2,1,"","FP8E4M3PerGroupSpec"],[14,2,1,"","FP8E4M3PerTensorSpec"],[14,2,1,"","FP8E5M2PerChannelSpec"],[14,2,1,"","FP8E5M2PerGroupSpec"],[14,2,1,"","FP8E5M2PerTensorSpec"],[14,2,1,"","Float16Spec"],[14,2,1,"","GPTQConfig"],[14,2,1,"","Int2PerGroupSpec"],[14,2,1,"","Int3PerChannelSpec"],[14,2,1,"","Int3PerGroupSpec"],[14,2,1,"","Int4PerChannelSpec"],[14,2,1,"","Int4PerGroupSpec"],[14,2,1,"","Int4PerTensorSpec"],[14,2,1,"","Int8PerChannelSpec"],[14,2,1,"","Int8PerGroupSpec"],[14,2,1,"","Int8PerTensorSpec"],[14,2,1,"","MX6Spec"],[14,2,1,"","MX9Spec"],[14,2,1,"","OCP_MXFP4DiffsSpec"],[14,2,1,"","OCP_MXFP4Spec"],[14,2,1,"","OCP_MXFP6E2M3Spec"],[14,2,1,"","OCP_MXFP6E3M2Spec"],[14,2,1,"","OCP_MXFP8E4M3Spec"],[14,2,1,"","OCP_MXFP8E5M2Spec"],[14,2,1,"","OCP_MXINT8Spec"],[14,2,1,"","OCP_MXSpec"],[14,2,1,"","PreQuantOptConfig"],[14,2,1,"","ProgressiveSpec"],[14,2,1,"","QATSpec"],[14,2,1,"","QronosConfig"],[14,2,1,"","QuaRotConfig"],[14,2,1,"","QuantizationConfig"],[14,2,1,"","QuantizationSpec"],[14,2,1,"","RotationConfig"],[14,2,1,"","ScaleQuantSpec"],[14,2,1,"","SmoothQuantConfig"],[14,2,1,"","TQTSpec"],[14,2,1,"","TwoStageSpec"],[14,2,1,"","Uint4PerChannelSpec"],[14,2,1,"","Uint4PerGroupSpec"],[14,2,1,"","Uint4PerTensorSpec"],[14,2,1,"","Uint8PerChannelSpec"],[14,2,1,"","Uint8PerGroupSpec"],[14,2,1,"","Uint8PerTensorSpec"],[14,1,1,"","load_pre_optimization_config_from_file"],[14,1,1,"","load_quant_algo_config_from_file"]],"quark.torch.quantization.config.template":[[15,2,1,"","BFP16Scheme"],[15,2,1,"","FP8Scheme"],[15,2,1,"","Int4WeightOnlyScheme"],[15,2,1,"","Int8Scheme"],[15,2,1,"","LLMTemplate"],[15,2,1,"","MX6Scheme"],[15,2,1,"","MXFP4Scheme"],[15,2,1,"","MXFP6E2M3Scheme"],[15,2,1,"","MXFP6E3M2Scheme"],[15,2,1,"","QuantizationScheme"],[15,2,1,"","QuantizationSchemeCollection"],[15,2,1,"","Uint4WeightOnlyScheme"]],"quark.torch.quantization.config.template.LLMTemplate":[[15,3,1,"","get"],[15,3,1,"","get_config"],[15,3,1,"","list_available"],[15,3,1,"","register_scheme"],[15,3,1,"","register_template"],[15,3,1,"","unregister_scheme"]],"quark.torch.quantization.config.template.QuantizationSchemeCollection":[[15,3,1,"","get_scheme"],[15,3,1,"","get_supported_schemes"],[15,3,1,"","register_scheme"],[15,3,1,"","unregister_scheme"]]},"objnames":{"0":["py","module","Python module"],"1":["py","function","Python function"],"2":["py","class","Python class"],"3":["py","method","Python method"]},"objtypes":{"0":"py:module","1":"py:function","2":"py:class","3":"py:method"},"terms":{"":[3,5,6,8,9,15,18,19,22,27,28,29,30,34,35,36,39,42,47,56,57,58,64,69,70,71,73,74,75,76,77,79,81,82,87,88,92,96,97,98,99,100,107,114,115,116,118,120,122,123,124,128,129,130,133,134,135,139,140],"0":[2,3,5,6,8,9,10,12,14,15,18,19,22,25,27,28,34,35,36,38,39,40,42,48,55,56,57,58,60,61,62,63,64,65,66,67,70,71,73,74,75,76,77,78,79,80,81,86,87,89,92,96,97,98,99,100,107,112,115,116,117,118,119,120,121,122,123,127,128,129,130,132,133,134,135,136,137,138,139,140,141],"000":[41,42,43,44,45,46,47,51,53,54,65],"000000000001":[62,116],"00001":[66,67,74,75,127],"0001":[12,77],"001":[14,77,116,122],"0010":[95,107],"004":44,"00456":55,"0055":92,"01":[12,14,27,56,57,58,77,87,99,107,122,134],"02":55,"028":53,"0284":[95,107],"03":116,"0317":[49,50,52,59],"03236":100,"03302":100,"03372":100,"0338":[107,134],"04":18,"05":[37,107],"052":[42,87],"054":42,"06":6,"068":42,"0681":[107,134],"06d":34,"07":133,"0737":92,"0755":[95,107],"076":42,"08":[87,95,96,99,107,121,124],"08007":[14,35],"08066":[14,99],"08153":99,"09":[55,87,99,121],"090":42,"0b":[95,107],"1":[2,3,5,6,8,9,12,13,14,15,18,19,20,22,23,27,29,31,34,41,42,43,44,46,47,48,49,50,51,52,53,54,56,57,58,59,60,61,62,63,64,65,66,67,69,70,74,75,76,77,78,81,86,87,89,91,93,94,99,107,111,112,115,117,118,120,121,127,128,129,132,134,135,136,137,138,139,140,141],"10":[14,18,34,45,54,55,70,77,81,95,97,99,107,120,134,140,141],"100":[27,73,74,75,77,92,117,135,140],"1000":[22,27,41,42,43,44,46,47,51,53,54,63,64,65,72,74,75,77,78,119,124,128,129,130],"10000":[14,66,67,71,127],"1024":[19,70,98,107,135],"108":120,"11":[18,19,35,55,62,74,78,95,97,107,124,134,140],"1110":19,"111063552":134,"1111":19,"114":[42,47,51],"11695":14,"1195":[95,107],"11b":[90,91],"12":[18,28,42,62,63,66,68,107,118,120,127,130,134,135,139],"120":49,"120b":124,"122":65,"123":[120,140],"125239296":134,"125m":[13,25,50,59,68,83,96,98,103,112,119,123,124,134,140],"126":[107,134],"127":[27,39,81,87,117,140],"128":[13,14,27,39,81,84,87,95,96,97,115,117,118,122,123,124,131,133,136,137,138,139,140],"128256":107,"12_quantiz":[28,42,47,51,66,127,130],"12_random_quant":130,"13":[18,35,70,74,95,107,124,134],"135":[120,141],"1370":[95,107],"1378":[107,134],"1382":[95,107],"139":[107,134],"13908052444458":120,"13b":[9,102],"14":[95,107,133,134,139,141],"140":120,"142":53,"148":120,"14b":[95,107,134],"15":[65,121,130],"156":120,"16":[3,6,14,19,35,55,66,67,72,73,74,76,78,79,81,96,99,107,121,127,129,134,135],"1600":116,"16406":55,"16b":[96,107,124,134],"17":[54,79,141],"1705472343":[74,75,124],"172":120,"175":139,"18":[27,42,62,87,99,107,124,134],"181324005126953":120,"182":42,"18944":120,"19":[79,97,121,124],"1902":99,"1903":[14,99],"194":46,"1959":[95,107],"1b":139,"1e":[6,14,37,72,73,77,107,118,122,128,129,140],"1e4":[14,122],"1f":140,"1k":[41,42,43,44,46,47,51,53,54,65],"1st":81,"2":[3,6,8,12,14,18,19,22,24,27,29,34,35,36,39,40,42,43,44,47,51,54,55,57,58,61,63,67,68,69,70,74,75,76,77,78,81,86,87,89,91,93,94,99,102,107,112,117,120,129,134,135,136,137,138,139,140,141],"20":[12,92,94,120,121,124,135,140],"200":[63,77],"2012":[41,42,43,44,46,47,51,53,54,65],"2014":89,"2017":[45,116,117],"2022":[18,79],"2023":21,"2024":[21,45,52,55,95,96,107,124,141],"2025":141,"2048":[48,49,50,52,55,59,60,61,96,133,134,136,137,138],"206":53,"20b":124,"21":[27,42,70,71,89,97,107,124,134],"2147483647":39,"2147483648":39,"2155":121,"216":54,"22":[67,107,121,124,134,139],"220":41,"224":[27,28,29,34,41,69,70,87,99,130],"225":130,"229":130,"23":[19,53,89,119,121],"2302":[14,35],"232":46,"24":[18,97,107,134,139],"2404":55,"2405":55,"244":69,"2462":[95,107],"248":42,"24969482421875":120,"25":[47,51,62,116,117,130,140,141],"2505":14,"252":53,"253":120,"255":[19,27,28,39],"256":[6,27,42,47,116],"26":[48,55,60,61,87,107,121,130,134,141],"26559":89,"2681332":140,"2687718":140,"269912719726":120,"27":[49,50,52,59,107,121,134],"27d67f1b5f57dc0953326b2601d68371d40ea8da":139,"28":[49,50,52,59,107,121,134,140,141],"280":42,"284":43,"28672":107,"28x28":140,"29":[62,87,89,95,97,99,107,121,141],"2907":92,"294":42,"2b":[95,107],"2d":120,"2e":97,"2gb":[6,27,47,69,70,71,124],"2mb":140,"2nd":81,"3":[3,8,12,14,18,27,29,34,36,38,39,41,42,43,44,57,58,60,63,69,70,76,77,86,87,91,95,99,107,112,115,117,118,120,121,124,134,135,139,140],"30":[50,62,97,107,117,121,130,134],"3000":[66,67,127],"31":[19,70,86,89],"314":42,"32":[6,9,14,19,35,40,75,76,79,80,81,95,96,97,100,102,107,112,117,118,123,124,131,134,140],"3244":[99,116],"32767":39,"32768":39,"33":54,"332":140,"3415":116,"3416":[99,116],"342":53,"34745":89,"34854":89,"35":[62,97,107,121,134],"3593":[107,134],"36":[62,95,97,107,120],"3600":77,"3604":50,"3640":120,"37":121,"3794":[95,107],"38":121,"384":[50,52,59],"385":59,"3892":118,"39":44,"3b":[95,107],"3ex":81,"4":[3,8,12,14,18,19,27,34,38,41,43,44,48,50,55,56,57,58,63,65,77,84,95,97,99,100,107,112,117,118,120,134,135,136,137,138,139,140],"40":[62,120,121],"400":116,"4025":[95,107],"405b":[107,134],"406":[50,130],"4096":[24,55,98,107],"41":[42,89],"416":117,"42":[77,89,95,97,107,121,133,136,137,138],"420":[47,51],"424":[41,43,44],"4294967295":39,"43":[117,130],"4315":59,"4321":[107,134],"43882751464844":120,"44":[53,96],"440":54,"446":42,"44639":89,"45":[89,97,120],"452":42,"456":[46,87,130],"46":[42,62,95,107,121],"47":42,"4721":[95,107],"4759":[99,116],"48":[6,107,117,134,139],"480":[49,50,52,59],"4838":[95,107],"485":130,"486":65,"49":[87,97,99],"490":42,"4b":27,"4bit":60,"4e38":39,"4f":[133,136,137,138],"4k":124,"5":[3,6,12,18,19,25,27,41,43,44,45,46,47,48,51,53,54,55,57,58,60,61,62,63,65,73,77,87,89,95,97,98,99,100,107,117,118,121,122,133,134,135,136,137,138,139,140,141],"50":[41,42,43,44,46,47,51,53,54,65,97,99,116,117,130,135],"500":[77,89],"5000":89,"5081":[95,107],"51":[62,97,121,139],"510":19,"512":[42,96,97,131,133,136,137,138,139,140],"5139":116,"52":[120,133,136,137,138],"5210":118,"528":139,"5305":[107,134],"53238":89,"53386":89,"5408":116,"56":[43,87],"562":[47,51,65],"5651":[95,107],"56758":89,"57":139,"5734":50,"58":121,"580":46,"584":41,"586":65,"59":[46,62,97],"5994":[95,107],"5b":[95,96,107,133,136,137,138],"5b_tinygsm8k_limit":92,"5d":140,"5e":118,"6":[3,6,14,18,27,48,55,57,58,60,61,63,69,72,73,77,81,95,97,98,99,100,107,117,120,128,129,134,135,139,140,141],"60":[41,62,120],"6006":49,"602":54,"61":[53,87],"610":46,"614":65,"61475":89,"62":[47,51,87,97,99],"622321128845215":120,"6267":[48,60,61],"628":42,"63":[44,55,63,66,67,127],"64":[42,55,118,119,123,124,135,140],"640":[65,116],"6400":116,"642":[42,54],"6421":92,"6460":[107,134],"6466":116,"65":[41,43,44,87,97,99],"65504":39,"65535":[38,39],"658":[41,42],"66":[42,65],"662":42,"67":[42,53],"68":[42,87,97,116],"681":140,"684":42,"6846":[50,52,59],"69":[87,99],"690":[43,44],"6984167098999":120,"6986":[95,107],"6b":[95,96,107,115,124],"7":[3,18,27,35,41,54,55,61,72,77,81,95,99,107,120,121,131,134,135,139,140,141],"70":[42,46,53,65,87,107],"700":[42,65],"7010":[107,134],"708":[43,44],"70b":[9,102,107,134],"71":[42,87,99,140],"712":42,"716":[42,47,51],"72":[42,65],"722":42,"7224":[95,107],"73":[42,47,51,97],"74":[42,47,51,53,87,97,99],"742":42,"74845":89,"75":[54,117],"754":19,"7590":[95,107],"76":[54,87,99,107,134,139],"764":42,"766":42,"768":[54,135],"77":135,"77445":89,"7782":120,"78":[87,117,130],"786":42,"788":[41,43,44],"789085":140,"79":[43,46,107],"790":44,"7964":100,"7b":[9,24,55,61,68,80,91,93,94,95,96,98,100,102,103,107,120,122,124,134,139],"7f":140,"8":[3,18,19,27,35,38,41,43,44,48,50,55,56,57,58,76,78,79,81,95,107,119,120,121,123,134,135,140,141],"80":[107,116,134,135],"8074":[95,107],"8080":135,"8192":107,"82":[41,42,47,51],"8255":61,"83":[46,53,87],"838":[41,42],"83954":89,"84":97,"8400":116,"842":53,"8429":[107,134],"85":[41,43,44,121,133],"85444":89,"85624":[107,134],"86":[87,99,117],"8602":[95,107],"8605":[107,134],"87":[42,65,87,99,121],"870":42,"878":42,"87ba8cb8a6a4f6525f26255fa513d902b17ab060":89,"88":[42,46,53,87,99],"883856773376465":120,"8859":48,"89":[42,53,65,87,99],"890":65,"891325950622559":120,"894":46,"8945":[95,107],"8952":100,"8958":[95,107],"8b":[9,86,95,102,107,115,120,121,124],"8bit":[22,23,24,25,61],"8f":140,"8map":117,"8x7b":[95,96,107,124,134],"9":[18,19,62,95,97,107,116,117,118,121,130,134,140,141],"90":[42,65,87,99],"90b":[90,91],"91":[42,47,51],"912":42,"92":[53,54,62,117],"920":42,"9210":60,"922":42,"9228":60,"9274":[95,107],"93":[54,97],"932":54,"936":43,"94":[46,56,58],"9419":[107,134],"94327":[107,134],"948962688446045":120,"95":[56,58,62,99,116,117,121],"952":42,"9560":[95,107],"96":[27,46,117],"97":[42,47,51,62,97],"972":53,"988":53,"99":[27,62,77,130],"996":[42,65],"999":[27,77],"9994":100,"9999":27,"9b":[95,107],"A":[2,3,4,5,8,10,12,14,15,16,19,21,22,27,34,35,38,56,57,58,70,77,81,82,88,89,91,92,107,119,120,122,124,135,139,140],"AND":21,"AS":21,"And":[17,63,76,99,135,140],"As":[20,27,45,47,56,57,58,62,65,76,81,82,86,87,88,99,100,107,116,117,118,125,128,129,130,131,132,133,134,135,139,140],"At":[76,116,140],"BE":21,"BUT":21,"Be":[81,140],"But":[96,105,107,115,116,140],"By":[14,19,20,22,27,64,73,74,76,77,79,80,82,103,105,107,126,130,133,135,139],"FOR":21,"For":[3,4,9,14,17,18,19,22,23,24,25,27,28,31,32,36,37,39,40,41,42,48,52,55,56,57,58,60,61,63,64,66,67,69,70,71,76,79,80,81,83,84,87,88,89,90,95,96,97,98,100,103,104,105,107,111,112,114,115,116,117,118,120,121,122,123,126,127,128,129,130,131,132,133,134,135,136,139,140],"IF":21,"IN":21,"If":[3,4,6,8,9,14,18,20,22,24,27,34,36,38,39,41,42,43,44,46,47,51,53,54,56,58,62,63,64,65,70,71,73,74,75,76,77,80,81,82,84,86,87,92,96,97,100,115,116,118,120,122,124,128,129,131,132,133,135,136,139,140],"In":[3,6,9,13,14,17,18,19,22,27,35,36,39,40,47,56,57,58,63,64,72,73,74,75,76,79,80,81,82,86,87,96,98,99,100,103,104,105,107,110,112,114,115,116,117,118,119,120,121,122,123,124,128,129,130,132,133,134,135,136,139,140],"It":[3,7,9,11,13,14,15,18,20,22,24,25,27,29,35,36,38,39,40,42,47,50,55,56,57,58,59,63,64,65,66,67,70,71,73,77,78,82,107,115,118,121,123,124,127,128,129,130,131,132,133,135,139,140],"Its":[22,27],"NO":21,"NOT":21,"No":[20,29,47,70],"OF":21,"OR":21,"Of":17,"On":[18,47,95,107,125,139,140],"One":[18,77,81,100,107,118],"Or":[116,140],"SUCH":21,"Such":81,"THAT":21,"THE":[21,68,109],"TO":21,"That":[18,140],"The":[2,3,4,5,6,8,9,10,11,13,14,15,17,18,19,20,21,22,23,24,25,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,64,65,66,67,68,70,71,72,73,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,96,99,100,102,107,109,111,112,115,116,117,118,119,120,121,122,123,124,127,128,129,130,131,132,133,134,135,136,139,140],"Their":129,"Then":[14,18,41,42,43,44,46,47,51,53,54,62,65,87,100,116,119,135,140],"There":[19,39,42,57,58,63,72,77,92,100,118,122,135,140],"These":[10,19,22,42,75,77,79,86,107,116,140],"To":[6,15,18,19,20,28,29,32,41,42,43,44,45,46,47,51,53,54,62,65,72,74,77,79,81,89,90,95,96,97,100,107,112,119,120,126,130,131,133,134,139],"WILL":21,"WITH":21,"Will":[17,79,107,116],"With":[81,139,140],"_":[20,34,70,86,97,99,104,117],"_2":81,"__":140,"__getitem__":34,"__init__":[28,29,34,99,116,118,128,130,132,140],"__len__":34,"__main__":[133,136,137,138],"__name__":[96,133,136,137,138],"__quantize_input":3,"_adaqu":42,"_avgpool_globalaveragepool_output_0_float":70,"_c":9,"_conv1_conv_output_0_dequantizelinear_output":70,"_do_calibr":124,"_export":116,"_finetun":97,"_float":70,"_generate_anchor":116,"_load_calibration_data":[128,130,132],"_non_quantized_eval_result":97,"_onnx":9,"_output":130,"_preprocess_imag":[28,29],"_quant":100,"_quantized_eval_result":97,"_test_bf16":97,"_test_finetun":97,"_val":100,"a16w8":[27,28,62,65,66,67,69,78,87,124,126,127,130],"a16w8_adaround":[62,65],"a16w8_quantized_model":128,"a18w8":71,"a1h_in1k":46,"a2":[96,124],"a8w8":[22,23,24,25,27,28,62,65,66,67,69,78,86,87,124,126,127,130],"a8w8_adaqu":130,"a8w8_adaround":[62,65,130],"a8w8_config":124,"a8w8_quantized_model":128,"ab":[6,14,35,55,99,116,118],"abbrevi":[35,42,94],"abil":[90,107,116,139],"abl":[13,18,135,139],"about":[19,20,32,69,83,100,112,116,117,122,124,130,135,139,140],"abov":[3,14,21,27,28,80,87,90,96,99,100,102,107,115,116,119,130,133,134,135,139,140],"absmax":6,"absolut":[27,30,47,80,85,86,140],"abstract":[15,135],"acc":[87,99],"acceler":[2,9,16,17,22,27,36,39,41,62,65,69,72,73,74,75,77,79,87,97,99,107,116,120,121,124,126,132,133,134,135,136,137,138,139,140],"accept":[27,36,39,56,57,58,63,84],"access":[22,23,24,25,41,42,43,44,46,47,48,51,52,53,54,55,60,61,65,80,88,95,96,97,98,107,120,131,135,139,140],"access_repo":139,"accommod":19,"accompani":[76,107],"accord":[6,9,39,45,63,74,80,100,134],"accordingli":[11,13,27,88,119],"account":[77,81,135,139],"accumul":116,"accur":[14,17,22,32,74,112,118,133,139,140],"accuraci":[14,17,19,22,23,24,25,27,28,30,35,36,39,40,41,42,43,44,46,47,51,53,54,56,57,58,62,63,64,65,66,67,76,77,78,79,80,82,85,87,99,100,107,115,116,120,124,127,130,131,133,134,135,139],"accuracy_improv":[22,23,24,25,41,42],"accuracylevel":27,"achiev":[17,19,22,32,42,55,62,65,67,70,73,76,77,78,79,81,82,87,88,112,120,130,133,140],"across":[8,10,12,14,16,19,22,27,66,67,115,119,124,126,127,135],"act":[67,133],"act_fn":107,"action":[21,124,133],"activ":[2,3,5,6,8,14,15,18,19,22,23,24,25,27,29,32,47,55,56,57,58,64,66,67,69,70,71,72,73,75,76,78,79,82,83,86,88,89,100,112,115,116,117,120,121,122,124,125,127,128,129,130,131,132,133,139],"activaiton":27,"activation_lay":98,"activation_qtyp":[3,5],"activation_spec":[29,47,72,128,129],"activation_tensor_nam":76,"activation_tensor_name1":76,"activation_tensor_name2":76,"activation_typ":[2,6,8,56,57,58,63,74,75,76,77,79,124],"activationbitwidth":27,"activationsc":[27,72],"activationsymmetr":[56,57,58,63,77,79,128],"acttargetquanttyp":76,"actual":[2,9,30,32,85,100,107,112,128,132,134,135,139,140],"ad":[18,27,36,39,45,77,79,83,88,99,103,118,120,124,135,139,140],"adapt":[11,13,22,23,66,67,73,76,77,87,99,127,134],"adaqu":[16,17,27,28,42,62,65,66,67,68,71,72,73,74,75,77,78,124,127,128,129,130,132],"adaquantconfig":[72,73,128,129],"adaround":[7,8,16,17,27,28,62,63,64,65,66,67,68,71,72,73,77,78,124,127,128,130,132],"adaround_algo":[78,124,130],"adaround_config":22,"adaroundconfig":[22,27,64,78,124,128,130],"add":[5,6,9,18,20,27,71,77,79,95,96,116,124,131,135,139,140],"add_export_info_for_hf":9,"addit":[2,3,5,6,8,18,21,27,35,36,39,40,48,55,60,61,70,79,87,89,90,95,96,99,103,116,117,121,126,129,131,139,140],"addition":[10,19,73,74,75,135],"addqdqpairtoweight":27,"address":[20,72,74,115,124,130,133,135],"adeptli":19,"adequ":34,"adher":19,"adjust":[3,14,19,22,27,30,35,40,42,56,57,58,64,71,74,75,77,82,85,87,89,99,123],"adjustbiasscal":27,"adjusthardsigmoid":27,"adjustshiftbia":27,"adjustshiftcut":27,"adjustshiftread":27,"adjustshiftswish":27,"adjustshiftwrit":27,"administr":18,"adopt":[116,117,124,134],"advanc":[8,14,17,19,21,22,28,45,52,55,74,75,77,78,82,83,88,98,100,116,122,124,126,131,133,136,139,140],"advanced_fastft_param":77,"advanced_fastft_search":77,"advantag":[19,56,57,58,69],"adversari":135,"advis":21,"ae":[6,27,47],"affect":[19,71,135],"affili":134,"afford":81,"after":[4,12,14,19,22,24,26,27,28,29,55,56,57,58,64,68,70,71,73,74,75,76,77,86,95,96,100,102,103,105,107,109,115,116,117,118,120,124,128,129,132,133,134,135,139,140],"again":[110,139,140],"against":[6,27,140],"aggress":[14,73,76,82,139],"agnost":100,"agre":[20,135],"ahead":[32,112,118],"ai":[3,9,16,28,75,76,96,116,119,124,128,132,135,140],"aid":14,"aim":[9,22,66,67,73,74,75,77,81,88,100,122,127,133,135],"aka":20,"akanametov":67,"algo_conf":[29,64,72,73,128,129],"algo_config":[8,12,14,22,23,24,25,27,29,64,72,73,78,107,122,124,128,129,130,134],"algo_config_fil":[107,134],"algo_config_info":134,"algoconfig":[7,8,12,14,27],"algoconfigbas":[12,14],"algorithm":[6,7,8,12,14,15,16,17,19,22,23,24,25,27,29,30,42,45,50,55,56,57,58,59,60,64,66,67,72,73,77,78,83,96,98,99,100,120,122,123,124,127,128,129,130,131,136,139],"algorithm_config":122,"align":[27,72,99,100,116,124],"alignconcat":[27,128],"aligneltwisequanttyp":[27,128],"alignpad":27,"alignpool":27,"alignreshap":27,"alignslic":[27,128],"aligntranspos":27,"all":[2,7,8,11,13,15,18,20,21,22,27,38,39,42,45,47,52,55,63,70,74,75,76,77,79,80,82,86,87,88,90,91,92,96,99,100,107,116,117,118,120,121,122,123,124,125,130,133,134,135,139,140],"all_config":[56,57,58,63],"all_tensors_to_one_fil":[60,61,70],"alloc":[19,77,81],"allow":[8,10,12,14,15,19,20,27,32,33,39,42,66,67,70,73,74,75,76,80,81,92,98,112,113,116,123,127,130,131,133,135,139,140],"almost":[80,140],"alon":118,"along":[36,38,39,80,82,89,100,133],"alpha":[6,14,25,115,118,121,122,124],"alpha_valu":6,"alreadi":[11,13,27,41,42,43,44,46,47,51,53,54,65,70,71,100,131,135,139,140],"also":[14,18,19,20,22,24,25,27,28,35,36,40,41,42,50,55,59,62,64,65,70,76,77,78,79,80,81,82,87,90,99,100,101,117,126,129,130,133,134,135,139,140],"altern":[18,19,27,70,91,93,94,135],"alwai":[19,27,75,80,118,119],"amazonaw":116,"amd":[20,21,23,24,25,26,27,30,31,32,34,35,36,37,38,39,40,56,58,64,70,71,78,81,84,85,87,99,106,109,111,112,114,115,117,118,120,121,122,123,124,126,128,129,130,132,133,134,135,136,137,138,139],"amd_quark":[18,68,109,131],"among":[4,62,65,116],"amount":[64,81,107,116,117],"amplifi":72,"an":[2,3,4,5,6,7,9,11,13,14,15,16,17,18,19,20,21,22,23,24,25,27,28,29,34,35,38,39,40,41,42,43,44,45,46,48,49,50,51,53,54,55,56,57,58,59,60,61,62,63,64,65,67,68,69,70,71,73,74,75,76,77,80,81,82,84,86,87,88,94,95,96,97,99,100,103,110,115,116,117,118,119,120,122,123,124,125,128,129,130,131,132,133,134,135,136,137,138,139,140],"anaconda":18,"analysi":[36,39],"analyz":[86,121],"anchor":116,"anchor_point":116,"andrej":139,"ani":[2,3,5,6,8,9,14,19,20,21,27,47,56,57,58,63,76,80,83,100,118,121,124,133,134,136,137,138,139,140],"ankl":140,"annot":[6,62,99,116],"annotate_tensor":6,"annotations_trainval2017":62,"anomali":130,"anoth":[25,35,81,83,88,100,135,139],"answer":140,"anton_shirt":140,"anton_sho":140,"anymor":[36,39],"ap":117,"apart":76,"api":[7,8,9,10,11,12,13,14,16,18,20,27,28,32,62,70,76,77,79,83,88,99,100,105,112,114,116,117,122,124,130,131,134,135,139],"apl":[17,106,109,124],"app":28,"appar":19,"appear":[19,21,135],"append":[28,118,130,133,134,136,137,138],"appli":[3,4,6,8,9,13,14,15,18,19,21,22,23,24,25,27,28,29,39,40,42,72,73,74,75,76,77,78,79,81,82,88,118,119,120,124,128,130,132,133],"appliabl":22,"applic":[19,22,40,56,57,58,71,76,77,82,83,88,96,116,130,133,140],"approach":[11,13,16,19,22,28,32,34,35,42,74,75,76,77,81,83,107,112,115,118,123,130,133,140],"appropri":[20,76,100,115,128,140],"approxim":[6,19,27,35,40,115],"apt":18,"ar":[2,3,6,9,11,13,14,15,18,20,21,22,23,24,25,27,28,32,35,37,39,40,41,42,45,47,52,55,57,58,60,63,64,65,68,69,70,71,72,74,75,76,77,78,79,82,83,86,87,88,90,91,92,93,94,95,96,97,98,99,100,103,104,105,109,111,112,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,133,134,135,139,140],"arbitrari":80,"arbitrarili":76,"architectur":[9,15,16,83,103,107,114,116,118,120,123,124,125],"area":[72,117],"arg":[5,6,8,9,57,58,63,87,91,94,99,104,105,107,114,116],"argmax":[34,79,140],"argument":[9,14,27,70,86,95,96,131],"aris":[20,21,69],"arithmet":19,"around":[14,27,77,89,133,139,140],"arrai":[28,35,74,75,82,133],"arrow":21,"art":[17,100],"articl":140,"artifact":[20,103],"artifici":[74,140],"artwork":140,"arxiv":[14,35,55,99,124],"aspect":[20,134],"assert":[133,135,136,137,138],"assess":[77,130],"assign":[9,15,35,40,57,58,63,73,75,76,77,123,134,139],"assist":[19,20],"associ":[3,6,21,22,122,139],"assum":[7,11,13,18,21,38,65,90,99,128,129,132],"astyp":[28,34],"asym":[91,93,94],"asymetr":9,"asymmetr":[3,16,17,19,27,31,33,78,100,102,111,113,115,123,124,131],"aten":[99,116],"attach":[82,133],"attempt":119,"attent":[14,15,82,107,120,123,124,133,134],"attention_schem":[15,123],"attn_implement":[133,136,137,138],"attribut":[6,15,27,74,75,76,77,122,123,140],"attributeerror":140,"audio":139,"augment":[14,65],"augreg_in1k":53,"augreg_in1k_lwp_quant":53,"augreg_in1k_minmax_quant":53,"augreg_in1k_percentile_quant":53,"august":141,"author":[20,21],"auto":[68,107,124,126,130,134],"auto_merg":70,"auto_search":77,"auto_search_config":[56,57,58,63,77],"auto_search_in":[56,57,58,63],"auto_search_inst":77,"auto_search_model":45,"auto_wrap":97,"autoawq":[9,103,124],"autoconfig":[103,124],"autoecod":135,"autoencod":135,"autoencoder_diagram2":135,"autofp8":[9,124],"autograd":99,"autom":133,"automat":[8,14,17,28,56,57,58,70,71,87,115,116,121,123,124,128,129,130,132,133],"automixprecis":76,"automodelforcausallm":[13,80,83,100,103,107,112,119,124,133,134,136,137,138],"autosearch":77,"autosearchconfig":77,"autosearchconfig_default":[57,58,63],"autosmoothqu":[14,15,115,123,124,133],"autosmoothquant_config":[14,15,133],"autosmoothquantconfig":[14,15],"autotoken":[13,80,83,96,100,107,112,119,133,134,136,137,138],"auxiliari":116,"avail":[9,13,14,15,18,19,20,22,23,24,25,27,29,41,42,52,60,64,73,74,75,77,80,88,94,95,96,97,98,122,123,124,135,139,140],"averag":[22,27,30,82,85,117,140],"averagepool":79,"avg":140,"avgpool":70,"avoid":[6,37,56,57,58,77,78,95,96,122,124],"awai":[19,35,40,140],"awar":[14,17,19,22,82,97,99,115,116,117,124,139,140],"awq":[9,14,15,16,17,83,91,93,94,100,103,115,122,123,124,139],"awq_auto_config_help":96,"awq_config":[14,15,96,136],"awqconfig":[14,15,122],"awqprocessor":122,"axi":[3,14,27,28,31,34,35,36,39,40,74,75,80,111,140],"b":[3,6,27,37,38,56,57,58,81,96],"b0353104":87,"b_scale":38,"b_zero_point":38,"back":[18,19,35,36,39,40,135,139,140],"backbon":[14,103,116,120,124],"backend":[17,32,76,100,112,124],"background":[135,139],"backup":[133,136,137,138],"backward":[36,39,88,140],"bad":[56,57,58],"bag":[124,140],"balanc":[17,19,56,57,58,66,67,73,74,76,77,81,86,115,118,124,127,131],"bandwidth":[73,140],"bar":[18,86,124],"base":[3,4,5,6,7,9,11,13,15,17,18,19,20,22,27,30,45,47,50,52,55,56,57,58,59,63,64,70,71,77,79,81,85,86,87,89,92,98,99,100,105,107,108,115,116,117,118,123,124,127,128,134,135,139,140],"base_model":117,"basedetectionmodul":116,"baselin":77,"baseline_result":[128,129,132],"baseline_results_fold":[71,128,129,130,132],"baseline_results_folder_path":[71,128,129,132],"bash":[18,57,62,139],"basi":[47,82],"basic":[18,123,124,130,133,135,140],"basic_lr_per_img":117,"batch":[4,18,22,27,28,34,37,41,42,43,44,46,47,51,53,54,70,86,87,99,116,117,133,134,136,137,138,140],"batch_data":134,"batch_idx":34,"batch_it":104,"batch_norm":116,"batch_siz":[22,29,34,38,64,70,73,84,91,93,94,116,117,118,133,135,136,137,138,139,140],"batch_size_per_gpu":97,"batchfeatur":13,"batchnorm":[4,27,79,124],"batchsiz":[74,75,124],"bayesian":77,"bdcb8f42221bc40c411150a009a3d3a30fa74722":100,"becaus":[3,19,27,28,42,57,70,71,78,100,110,118,122,135,140],"becom":[14,19,24,55,76],"been":[18,22,27,87,107,130,133,134,136,139,140],"befor":[4,6,18,20,24,27,28,36,39,41,55,56,57,58,70,71,77,79,86,95,97,98,99,100,107,118,120,122,124,133,134,136,137,138,139,140],"beforehand":64,"begin":[88,100,134],"behalf":19,"behavior":[22,27,131],"behind":81,"being":[18,19,77,86,88,100,135,139],"belong":116,"below":[3,6,17,18,20,28,56,57,58,62,63,64,65,67,76,81,83,87,90,91,92,93,94,99,100,103,105,116,125,128,130,132,135,139,140],"benchmark":[124,135,139],"benefici":[19,80],"benefit":[17,71,118],"besid":[22,78,79],"best":[14,28,32,56,57,58,63,68,70,77,82,112,124,126,133,140],"beta":[3,5,14,17,122],"better":[17,18,19,22,28,40,55,57,66,67,70,72,77,79,80,82,87,99,115,116,117,118,120,124,127,128,129,130,131,140],"between":[11,13,17,19,21,27,30,36,39,56,57,58,62,63,65,69,72,73,74,77,82,85,86,90,92,100,116,118,130,133,135,139],"bewar":118,"beyond":139,"bf16":[27,66,67,70,71,76,78,91,93,94,97,124,126,127,131],"bf16qdqtocast":[27,72,129],"bf16withclip":27,"bfloat16":[14,16,17,19,27,36,37,38,39,66,67,72,76,78,81,104,115,122,124,127,129,131],"bfloat16_model":129,"bfloat16_onnx_model_path":129,"bfloat16_spec":122,"bfloat16spec":[14,27,72,129],"bfloat_16_onnx_model_path":71,"bfloat_format":71,"bfp":[5,35,42,66,67,68,70,73,74,75,76,119,124,127],"bfp16":[14,15,17,27,35,64,66,67,76,78,98,123,124,127],"bfp16scheme":15,"bfp16spec":[14,27,73],"bfp_16_onnx_model_path":71,"bfp_method":[35,74,79],"bfpattribut":[74,79],"bfpfixneuron":124,"bfpquantizedequant":[74,76,79,124],"bia":[3,5,9,14,16,22,23,27,37,38,87,99,107,114,116,117,118,122,124,128,132,139],"bias":19,"bias_1":116,"bias_nam":[3,5],"bias_scal":5,"bias_zero_point":5,"biascorrect":[17,124],"bidirect":38,"bigger":[22,140],"billion":139,"bin":[14,49,50,52,59,70,81,118],"binari":100,"bio":21,"biologi":139,"bit":[6,19,27,35,36,39,40,50,56,57,58,66,67,72,73,74,75,76,77,78,81,82,88,96,99,115,119,120,127,128,133,135,139,140],"bit_width":[35,74,79],"bitwidth":81,"black":139,"blob":[28,63,66,67,127,130],"block":[2,5,14,17,27,35,40,42,66,67,68,74,75,76,79,81,82,84,96,100,107,111,115,117,120,124,127,130,133,134,135,139],"block_q4_1":100,"block_siz":[14,35,40,48,49,50,52,55,59,60,61,74,75,79,122],"blockwise_tun":12,"blockwise_tuning_config":12,"blockwisetuningconfig":12,"bm_mean_1":116,"bn":116,"bn_bias_1":116,"bn_var_1":116,"bn_weight_1":116,"board":99,"bodi":117,"bool":[2,3,4,5,6,8,9,12,13,14,27,70],"boolean":[14,23,24,27,70],"boot":140,"both":[3,9,16,17,22,27,31,32,41,64,66,67,69,70,71,74,76,77,79,81,82,87,88,90,92,94,98,99,100,104,111,112,114,117,118,120,124,125,127,134,140],"bottleneck":[36,39,135],"bottom":135,"bound":[116,117],"boundari":[27,76],"boundless":70,"box":[18,116,117,135,139],"brain":[72,129],"branch":131,"brand":140,"break":[124,133,136,137,138,139,140],"brecq":[17,98,124],"brevita":[17,106,109,118,124],"brevitasquant":88,"brief":116,"bring":[35,107,134],"broaden":88,"broadli":19,"broken":80,"bug":20,"build":[9,18,20,42,56,57,58,63,76,77,100,110,130,133,140],"build_all_config":[56,57,58,63],"builder":[90,92],"built":[42,56,57,58,77,96,124],"bunch":[80,100],"burden":82,"button":[135,139],"byte":[6,19,47],"c":[21,37,41,42,43,44,45,46,47,51,52,53,54,55,56,57,58,79,117,140],"c4ai":[95,96,107,124],"cach":[14,15,16,17,22,27,57,58,63,110,115,116,120,123,124,131,133,135,139],"cache_dir":77,"cache_onnx_model_and_infer_shap":6,"calcul":[3,6,14,19,23,27,56,57,58,63,77,90,100,119,124,128,129,132,139],"calculate_quantization_param":3,"calib":[29,116],"calib_":34,"calib_000001":[29,34],"calib_000002":[29,34],"calib_000003":[29,34],"calib_000004":[29,34],"calib_000005":[29,34],"calib_100":65,"calib_data":[28,41,42,43,44,46,47,51,53,54,63,65,66,78,116,117,124,127,130],"calib_data_fold":[128,130,132],"calib_data_path":[28,29,56,57,58,62,63,65,66,67,78,124,127],"calib_data_read":[22,23,24,25,28,78,124,128,130,132],"calib_data_s":116,"calib_dataload":[13,80,82,83,84,87,100,104,112,118,119,133,135,136,137,138,140],"calib_dataread":29,"calib_imag":67,"calib_load":99,"calib_method":53,"calib_num":57,"calib_path":57,"calib_prompt":89,"calib_s":89,"calibdataread":[128,132],"calibdatas":27,"calibmethod":[27,72,128,129],"calibmovingaverag":[27,56,57,58,77],"calibmovingaverageconst":[27,56,57,58,77],"caliboptimizemem":27,"calibr":[0,3,5,7,8,11,13,16,17,19,27,32,34,41,42,43,44,45,46,47,51,53,54,56,57,58,62,69,71,72,74,75,76,77,82,98,99,100,112,117,118,119,124,128,132,133,139],"calibrate_method":[2,3,5,6,8,56,57,58,63,74,75,76,77,79,124],"calibration_cache_dir":34,"calibration_data":[29,34,128,132],"calibration_data_path":[6,7,29],"calibration_data_read":[6,7,27,29,47,77,79],"calibration_dataset_path":[41,42,43,44,46,47,51,53,54,56,57,58],"calibration_image_fold":[28,29],"calibration_method":[27,128,129],"calibrationdataread":[2,6,7,28,29,70,128,130,132],"calibrationmethod":[2,6,8,27,56,57,58,63,69,74,75,76,77,79,124],"calibtensorrangesymmetr":27,"calibworkernum":27,"call":[3,5,18,19,27,63,88,98,99,100,116,118,119,120,124,135,139,140],"can":[3,6,8,9,10,11,13,14,15,18,19,20,22,23,24,25,27,28,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48,51,53,54,55,56,57,58,60,61,62,63,64,65,66,67,68,70,72,73,74,75,76,77,78,79,80,81,82,83,84,86,87,88,89,90,92,94,95,96,97,99,100,103,105,107,109,113,115,116,117,118,120,121,123,124,125,126,127,128,129,130,131,132,133,134,135,136,139,140],"candid":77,"canni":124,"cannot":[9,18,20,21,22,27,70,79,104,107,110,120,130,133,136,137,138],"capabl":[17,31,76,86,88,111,124,126,132,135],"capi":69,"capit":139,"caption":[20,89],"captions_sourc":89,"captur":[82,133,135],"capture_pre_autograd_graph":116,"card":96,"care":[99,118,140],"carefulli":76,"carri":37,"case":[3,7,14,18,19,27,28,36,37,39,71,76,77,81,83,92,103,105,118,120,130,139],"cast":[27,71,79,124,129],"cast_cast":104,"cat":[116,133,136,137,138],"cat_sampl":[133,136,137,138],"categor":[19,107],"categori":[19,83,139,140],"cater":16,"cauchy_":118,"caus":[22,56,58,69,70,72,124,133],"caution":88,"cd":[20,89,115,131],"cdna2":125,"cdna4":124,"cell":140,"center":[77,131,140],"central":[27,133],"certain":[19,22,27,70,76,77,122,124,130,134,135],"ch_axi":[13,14,31,80,100,111,112,118,119,122],"challeng":[115,130,133],"chang":[14,18,20,21,45,71,79,88,91,93,94,107,116,124,135,139,140],"channel":[3,5,8,14,16,17,19,27,31,36,37,39,70,82,107,111,115,121,124,133,134],"channel_axi":3,"chapter":[32,112],"charact":139,"characterist":[16,19,22,76,99,130],"charg":21,"chat":[91,93,94,96,100,102,107,124,134,140],"chatglm":[15,115,124],"chatglm3":[95,96,107],"chatglm_6b":97,"chatglm_fsdp_config":97,"chatgpt":139,"check":[3,6,18,35,41,42,43,44,45,46,47,51,53,54,64,65,77,110,116,117,118,124,134,135,139],"check_hard_sigmoid_condit":6,"check_model_quantiz":6,"check_onnx_model":6,"check_reduce_mean_condit":6,"check_relu_like_nod":6,"checkout":89,"checkpoint":[48,55,60,61,91,93,94,95,96,97,103,105,116,124,131,134,139],"choic":[9,13,22,40,73,91,120,140],"choleski":14,"choos":[16,17,18,19,22,80,81,92,100,105,115,128,140],"chosen":[45,80,81],"ci":20,"circl":116,"circumst":3,"citi":89,"ckpt_path":[96,107],"cl":79,"claim":21,"clamp":100,"clariti":124,"class":[3,4,5,6,7,8,9,10,11,12,13,14,15,27,28,34,41,42,43,44,46,47,51,53,54,57,58,63,65,77,78,80,83,84,88,99,116,118,119,122,123,124,128,130,132,140],"classic":[74,81,87],"classif":[17,28,42,47,51,63,76,124,127,130],"classifi":[19,139,140],"classmethod":15,"cle":[7,8,16,17,66,67,68,124,127],"cle_algo":[78,124],"cle_config":23,"cle_scale_append_bia":23,"cle_step":[23,27,78,124],"clean":[57,58,63,116,117,124],"clear":20,"clearli":139,"cleconfig":[23,27,29,78,124,128,129],"clestep":124,"cli":[17,48,49,50,52,59,60,61,135],"click":[79,90,135,139],"clip":[3,4,6,27,79,89,135],"clip_nod":6,"clockwis":120,"clone":89,"close":[22,30,56,57,58,62,65,85,139,140],"closer":[22,35,120],"closest":[6,27],"cloud":[100,140],"cls_score_list":116,"cluster":139,"cmae":77,"cmap":140,"cmd":79,"cnn":[5,8,17,69,78,124,126,130,135],"cnn_dailymail":94,"cnn_dm":94,"co":[41,43,44,46,47,49,50,51,52,53,54,56,57,58,59,63,65,124,139],"coars":[74,75],"coat":140,"coco":[45,57,62,89,116,117],"coco2014":89,"coco2017":57,"coco2017_train_yolo_na":116,"coco2017_val_yolo_na":116,"coco_data_dir":116,"cocodataset":62,"cocodetectiondataset":116,"code":[20,27,28,47,63,66,67,68,69,70,73,74,75,87,88,96,99,100,102,109,115,116,117,121,124,127,128,129,130,132,133,134,139,140],"codeown":20,"coher":[15,96],"cohereforai":[95,96,107,124],"col":135,"collaps":19,"collat":96,"collate_fn":84,"collect":[15,20,27,86,118,124,133,140],"color":81,"color_bgr2rgb":130,"colour":139,"column":[14,81,107,115,134,140],"com":[18,28,35,36,37,38,39,40,42,47,51,63,66,67,89,116,124,127,130],"combin":[18,21,56,57,58,63,73,77,98,120,121,124,131,134],"combinatori":107,"come":[18,19,65,131,139,140],"comfort":18,"comma":94,"command":[18,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,67,70,71,79,95,96,100,107,115,124,128,129,130,131,132,134,139,140],"comment":[27,79,140],"commit":[20,100],"common":[18,27,28,35,41,66,67,69,73,74,75,76,81,100,118,121,123,127,133,135,136],"commonli":[22,23,24,25,35,41,42,43,44,45,46,47,51,53,54,65,128,130],"commun":[20,134],"compact":116,"compani":21,"compar":[6,22,28,35,40,70,71,73,75,81,82,83,86,92,115,116,117,118,124,130,133,135,139,140],"compare_qu":135,"comparison":[42,92,140],"compat":[7,9,11,13,18,20,22,28,36,39,57,71,73,84,88,89,96,99,121,122,124,134,135,139],"compens":[82,133],"competit":[107,116,117],"compil":[13,27,76,79,86,87,96,99,117,121,124,140],"complet":[21,77,82,133,136,137,138,139,140],"complex":[11,13,19,28,40,41,56,57,58,66,67,73,76,77,117,127],"compli":[20,88],"complianc":[87,117],"compon":[8,12,14,20,21,56,57,58,82,88,99,124,133,140],"compos":[77,130,139],"composit":19,"comprehens":[8,10,12,14,17,20,90],"compress":[9,13,19,40,82,86,124,135,139,140],"compromis":[17,19,118],"comput":[3,5,6,18,19,21,22,27,30,36,37,38,39,40,41,42,45,65,66,67,70,71,72,73,74,75,76,77,80,81,82,85,87,99,100,107,116,117,120,124,125,127,129,133,134,135,139,140],"computation":76,"compute_scale_loss":[14,133],"compute_scale_zp":6,"compute_scale_zp_fp":6,"concat":[4,27,79],"concat_5":67,"concaten":[4,38,63],"concent":134,"concentr":[24,55,107],"concept":[18,19,35,42,74,116,139,140],"conceptu":20,"concern":20,"conclud":77,"concret":[40,42,56,57,58],"conda":[18,90],"condit":[6,21,45,56,57,58,63,77,92,124],"conduct":[23,87,116,117,134],"confidenti":[47,124],"config":[7,8,9,10,11,12,13,14,15,22,23,24,25,27,29,42,47,48,49,50,52,53,54,55,59,60,61,62,63,64,65,66,67,72,73,74,75,76,77,78,80,83,87,89,96,99,100,103,105,112,117,118,119,123,124,127,129,130,135,136,137,138,140],"config_nam":8,"configbas":[12,14],"configur":[0,1,2,7,9,11,13,15,16,17,18,19,32,35,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,64,65,67,69,73,75,76,77,79,87,88,100,103,105,110,112,114,116,118,120,121,124,127,128,131,132,133,134,136],"confirm":18,"conflict":70,"conform":84,"confus":[19,22,72,74,75,76,81,86,110,114,115,118,128,129,130,132],"congratul":[80,140],"conjunct":55,"connect":[21,82,107,130],"consecut":[23,107,124,134],"consequ":71,"consequenti":21,"consid":[3,18,19,30,36,39,70,81,87,107,115,118,120,127,139],"consider":[70,140],"consist":[20,36,39,70,77,82,119,124,133],"const":27,"constant":[9,27,71,116,117],"constrain":[22,35,37,38,40,73,81,107,116],"constraint":[4,77,81,115,116,132,134],"construct":[24,28,119],"consult":[18,20],"consum":[5,19,27,36,39,76,78],"consumpt":[22,27,76,77],"contact":20,"contain":[2,3,6,7,8,9,13,14,18,19,21,28,41,42,43,44,45,46,47,48,49,50,51,53,54,55,59,61,63,65,66,67,70,77,79,95,99,100,103,104,105,116,117,127,131,140],"content":[9,20,21,99,124,139],"context":[30,85,139],"contextu":139,"contigu":[133,136,137,138],"continu":[20,76,77,124],"contract":21,"contrast":40,"contrib":6,"contrib_your_component_nam":20,"contribut":[82,134,139],"control":[8,9,10,12,14,25,27,56,57,58,70,76,80,115,119,131],"control_v11p_sd15_canni":89,"controlnet":124,"controlnet_id":89,"conv":[4,8,27,28,67,76,78,79,99,116,124],"conv1":[27,70],"conv2":27,"conv2d":[14,16,19,99,116,124],"conv_0":[78,124],"conv_1":[78,124],"conv_2":[78,124],"conv_501_dequantizelinear":70,"conv_501_dequantizelinear_output":70,"conv_out":70,"convei":[87,99,116],"conveni":[20,22,71,123,124],"convers":[27,71,81,82,124,126,128,132],"convert":[4,6,8,9,27,35,36,39,40,41,60,61,70,72,79,84,100,124,126,135,139,140],"convert_a8w8_npu_to_a8w8_cpu":71,"convert_bias_int32_to_int16":71,"convert_bn_to_conv":4,"convert_clip_to_relu":4,"convert_custom_op":71,"convert_dynamic_to_fix":41,"convert_fp16_to_bf16":[71,129],"convert_fp16_to_bfp16":71,"convert_fp16_to_fp32":[6,8,27,71,79],"convert_fp32_to_bf16":[71,129],"convert_fp32_to_bfp16":71,"convert_fp32_to_fp16":[60,61,71],"convert_hf_to_gguf":100,"convert_nchw_to_nhwc":[6,8,71],"convert_reduce_mean_to_global_avg_pool":4,"convert_split_to_slic":4,"convert_u16u8_to_u8u8":71,"convertavgpooltodpuvers":27,"convertbntoconv":27,"convertcliptodpuvers":27,"convertcliptorelu":27,"convertfp16tofp32":27,"converthardsigmoidtodpuvers":27,"convertleakyrelutodpuvers":27,"convertnchwtonhwc":[27,69],"convertopsetvers":27,"convertreducemeantodpuvers":27,"convertreducemeantoglobalavgpool":27,"convertsigmoidtohardsigmoid":27,"convertsoftmaxtodpuvers":27,"convertsplittoslic":27,"convolut":[23,27,70,74,105,130,135],"convtranspos":[27,71,76,79],"convtranspose2d":[16,124],"coordin":139,"copi":[21,28,118,135,139,140],"copilot":139,"copy_model_name2":135,"copy_repo_nam":139,"copybiasinit":27,"copyright":[21,45,52,55],"copysharedinit":27,"core":[20,77,82,88,133],"correct":[3,6,16,18,21,71,80,82,124,133,139,140],"correctli":[19,77,140],"correspond":[6,8,10,27,35,41,42,43,44,46,53,54,56,57,58,77,82,86,99,118,124,130,133,139,140],"cosin":[27,71,128,129,132],"cost":[19,22,40,73,81],"could":[9,22,56,57,58,96,100,121,130,135,139,140],"couldn":100,"count":[22,36,39,77],"counterclockwis":120,"counterpart":19,"coupl":[38,77,124],"cours":139,"covari":77,"cover":[20,64,124,139,140],"coverag":20,"cp":[48,49,50,52,55,59,60,61],"cpp":124,"cpu":[4,9,14,16,17,18,19,22,27,28,62,63,65,66,67,70,72,73,74,75,77,79,87,90,91,93,94,95,110,124,126,127,130,131,133,134,135,136,137,138,139,140],"cpuexecutionprovid":[2,6,8,27,72,73,74,75,79],"craft":133,"crash":135,"creat":[3,6,15,18,20,27,29,41,42,43,44,46,47,51,53,54,76,84,88,96,107,118,120,124,131,133,135,136,139],"create_infer_session_for_onnx_model":6,"criteria":77,"critic":[8,12,14,19,20,27,74,76,82,133,139],"cross":[17,66,67,68,127],"crossentropyloss":[133,136,137,138,140],"crucial":[16,20],"cryption":6,"crypto":[8,27],"crypto_mod":8,"cryptomod":[27,47],"csrc":124,"csv":[93,94,124],"cu126":[18,135,139],"cuda":[16,18,22,41,56,57,58,62,63,64,65,72,73,74,75,77,79,91,93,94,124,131,133,134,135,136,137,138,139],"cuda_visible_devic":[97,98],"cudaexecutionprovid":[27,64,72,73,74,75,79],"cumbersom":9,"current":[3,6,9,17,18,19,22,27,29,38,55,70,71,77,82,86,88,90,91,92,93,94,96,102,103,104,105,119,120,121,124,133,135,140],"custom":[6,8,9,14,15,20,27,28,34,35,36,37,38,39,45,56,57,62,63,68,70,72,73,74,75,76,77,79,96,103,124,128,132,133,136],"custom_autosmoothquant_config":133,"custom_awq_config":136,"custom_config":124,"custom_eval_data":62,"custom_evalu":[57,58,63],"custom_int8_wo":123,"custom_mod":[9,103,105,131],"custom_op":18,"customiz":124,"customizable_detector":116,"customizabledetector":116,"customqdq_to_contribqdq":6,"cut":[17,27],"cv2":[28,130],"cv3":67,"cvtcolor":130,"d":[18,31,35,36,38,39,40,57,100,111,140],"d0":[31,39,111],"d1":37,"d2":37,"d_1":81,"d_2":81,"daisi":[28,63,66,67,127,130],"dall":135,"damag":[21,116],"damp_perc":[12,14,122],"dampen":14,"dashboard":140,"data":[2,3,6,7,8,10,11,13,14,16,17,22,27,30,32,33,35,36,37,39,40,56,57,58,64,69,70,72,73,74,75,76,84,85,89,92,96,98,99,100,107,112,113,115,117,118,119,122,124,128,131,132,133,135,136,137,138,139],"data_batch":84,"data_dir":[57,87,107,116,117],"data_fold":[128,130,132],"data_it":[128,132],"data_list":[28,29],"data_load":34,"data_path":[65,117,140],"data_path_to_coco":116,"data_path_to_imagenet":87,"data_prepar":84,"data_read":[2,6,72,74,75,76,128,129,132],"data_s":[22,73],"data_typ":[27,78,124,131],"databas":130,"databrick":[96,124],"dataclass":[78,122],"dataload":[11,13,27,34,56,57,58,63,80,82,83,86,100,103,112,116,117,118,119,124,133,136,137,138,140],"dataloader_param":116,"dataread":[27,47,56,57,58,77,124],"datas":[63,74,75,77,124],"dataset":[32,34,41,42,43,44,45,46,47,51,53,54,56,57,58,62,65,71,77,83,91,93,94,96,99,100,112,115,116,117,118,119,128,130,131,132,133,135,136,137,138,139,140],"dataset_param":116,"dataset_path":[45,98],"datatyp":[6,8,14,27,42,87,96],"datatypespec":[14,124],"date":[97,135,139,141],"datetim":140,"dbrx":[15,96,124],"deal":[19,21],"debug":[8,12,14,27,70,115,116],"debug_mod":[6,8],"debugmod":27,"decemb":141,"deci":116,"decid":[63,77,134],"decim":19,"declar":20,"decod":[12,14,82,96,107,117,118,120,121,124,133,134],"decoded_predict":116,"decompos":81,"decomposit":14,"decompress":19,"decoupl":124,"decreas":[22,107,116,118,124,134,139],"decrypt":6,"decrypt_data":6,"dedic":[9,20,27],"dedicate_dq_nod":4,"dedicatedqdqpair":27,"deem":76,"deep":[7,9,11,13,17,19,28,72,74,80,83,100,119,129,130,135],"deepcopi":118,"deepseek":[15,92,96,107,124,134],"deepseek_v2":15,"deepseek_v3":15,"def":[28,29,34,57,58,63,82,84,96,99,107,116,118,128,129,130,132,133,134,135,136,137,138,140],"default":[2,3,4,5,7,8,9,10,11,12,13,14,15,22,23,24,25,27,28,35,36,37,38,39,40,45,56,57,58,62,63,65,70,71,76,77,79,82,86,89,92,103,105,116,117,120,124,129,130,131,133,135,136,139,140],"default_adaround_param":124,"default_bfp16_per_block":119,"default_config":[56,57,58],"default_fp88_per_tensor_sym_spec":135,"default_int8_per_tensor_sym_spec":[83,135,140],"default_uint4_per_group_asym_spec":[100,112],"default_w_bfp16_per_block_config":119,"default_w_fp8_a_fp8_per_tensor_config":112,"default_w_fp8_per_tensor_config":135,"default_w_int8_a_int8_per_tensor_dynamic_config":112,"default_w_int8_per_tensor_config":[83,135,140],"default_w_uint4_per_group_config":[100,112],"defaultconfigmap":8,"defer":14,"defin":[7,8,11,13,14,15,16,19,27,29,34,42,45,56,57,58,63,74,77,78,80,82,84,86,88,100,107,112,118,122,123,124,128,129,130,132,133,136],"definit":[100,119],"degrad":[71,76,81,82,107,115,133,134,135,139],"degre":[115,120],"degreg":135,"delet":[6,12,107,110,116,124,134],"delete_layer_num":[12,134],"delete_layers_index":12,"delimit":92,"deliv":[82,115,126,133],"delta":100,"demand":[17,19,56,57,58,71,87,99,107,117,124],"demo":[45,78,82,124],"demo_quant":[78,124],"demonstr":[22,23,24,25,28,32,34,64,78,82,83,89,98,112,115,116,117,119,137,138],"denot":[10,81,82,100,133],"dens":72,"densenet121":54,"depart":20,"depend":[11,13,18,19,20,88,97,107,115,118,125,131,133,139],"depict":139,"deploi":[17,22,27,36,39,70,73,76,77,83,87,99,117,126,134],"deploy":[4,16,17,19,20,22,40,56,57,58,71,73,76,78,87,99,107,115,116,117,121,124,126],"deprec":[9,124],"depth":[12,17,116,124,135,139],"depthtospac":79,"depthwis":23,"dequant":[5,6,9,19,27,35,36,39,40,81,99,100,124,125,135,140],"dequant_stub":116,"dequantize_data":6,"dequantizelinear":[27,36,79,124],"dequantizerlinear":104,"dequantstub":116,"deriv":[82,140],"desc_act":[14,122],"descend":14,"describ":[33,52,60,96,99,105,113,116,122,134,135,139],"descript":[20,133,139],"design":[17,19,20,22,47,56,57,58,65,66,67,71,76,77,82,98,100,115,118,124,127,129,134,135,139,140],"desir":[19,77,81,99,116],"desktop":[18,131],"despit":[135,139],"destruct":[86,118],"detail":[8,10,12,14,19,22,23,24,25,27,28,29,32,35,36,39,47,48,55,60,61,64,69,70,73,76,77,81,82,83,84,87,91,93,94,95,96,112,117,121,122,123,124,128,129,130,131,132,133,135,139],"detect":[14,67,68,86,116,117,124,130,140],"detection_imag":67,"determin":[9,14,19,20,22,27,30,32,36,39,70,77,80,81,112,115,118,133,140],"dev":134,"develop":[17,18,20,79,88,98,100,116,117,130],"deviat":22,"devic":[9,11,13,14,21,22,27,36,39,41,42,45,52,55,72,73,74,75,76,79,84,87,91,93,94,95,96,99,103,117,124,129,133,134,135,136,137,138,139,140],"device_map":[107,134],"devicetyp":14,"devop":20,"dfl_head":116,"di":[31,39,111],"diagram":[20,135,139],"dial":140,"dict":[2,3,5,6,8,9,11,12,13,14,15,27,56,57,58,63,70,82],"dictat":77,"dictionari":[3,5,6,8,11,13,14,15,27,45,76,84,96,118,133,139,140],"did":140,"differ":[3,6,8,10,12,14,16,18,19,21,22,27,30,31,35,39,41,42,43,44,56,57,58,62,65,69,71,72,73,76,77,79,81,85,86,87,90,96,99,100,107,111,112,116,117,118,124,125,130,134,135,139,140],"differenti":139,"difficult":[86,116],"difficulti":[25,118,133],"diffus":[17,68,109,124,139],"diffusers_root":89,"dim":[133,136,137,138],"dimens":[3,14,24,31,36,37,38,39,70,86,107,111],"dimension":[37,139],"dir":[131,139],"direct":[20,21,38,77,99,116,139],"directli":[11,13,18,19,20,27,28,41,42,43,44,46,47,51,53,54,63,65,66,71,72,88,99,103,105,107,116,120,123,127,130,139,140],"directml":131,"directori":[9,18,20,22,27,29,68,70,77,79,88,90,109,110,116,124,131,139],"disabl":[22,77,86,124],"disable_shape_inf":[60,61],"disappear":72,"discard":[22,45],"disclaim":21,"discov":134,"discrep":100,"discret":[24,55,77],"discuss":[20,55],"disk":[6,22,27,47,124,140],"displai":[124,135,140],"distanc":[63,139],"distinct":[32,112],"distinguish":[82,139],"distribut":[2,18,21,24,27,30,32,34,55,86,112,118,124,135],"div":[27,79],"div_1":67,"divers":[28,83],"divid":[14,77,82,83,111,139],"divis":[37,39],"dll":[18,72,73,74,75,79],"dlrm":124,"dm":100,"dml":131,"dn":[31,37,39,111],"dnn":119,"do":[18,19,21,22,27,30,39,56,57,58,70,71,72,74,75,76,77,79,81,86,92,99,110,114,115,116,117,118,125,128,129,130,132,135,139,140],"do_constant_fold":9,"do_onnx_ev":[48,49,50,52,55,59,60,61],"doc":[18,20,100,133],"docstr":124,"document":[14,18,19,21,22,23,24,25,64,70,72,74,75,76,81,86,87,88,90,96,97,110,114,115,116,118,122,124,126,128,129,130,131,132,140],"doe":[13,14,20,22,27,67,69,70,71,87,88,110,124,131,135,139],"doesn":100,"domain":[24,35,36,37,38,39,40,55,124],"don":[2,3,45,133,136,140],"done":[27,39,100,131,135,139,140],"dot":139,"down":[80,120,139,140],"down_proj":[14,82,86,107,115,122,123,133,136],"download":[28,41,42,43,44,45,46,47,48,51,53,54,55,56,58,60,61,62,63,65,66,67,68,89,95,96,97,100,109,116,117,127,130,131,134,135,140],"downsampl":135,"downstream":[9,101,103,105],"dpu":[6,27,70],"dpu_leaky_relu_alpha":6,"dq":[72,79,124,140],"dr":47,"draft":133,"draw":140,"dress":140,"drew":140,"drop":[22,56,57,58,63,80,107,115,134],"drop_last":[133,136,137,138],"dry":140,"dtype":[13,14,83,87,91,93,94,99,112,115,116,117,118,119,122,125,135,140],"dual":[74,139],"dualquantnod":76,"dublin":139,"due":[19,24,27,55,60,61,81,87,118,132,139],"dummi":[81,118,135],"dummy_input":[116,117],"dump":[89,116,130,133,136,140],"dump_data_fold":89,"dump_data_read":70,"dump_float":70,"dump_model":70,"dump_result":70,"dumpbin":18,"duplic":[20,27],"dure":[3,6,11,13,14,17,18,19,22,25,27,28,29,32,34,47,55,56,57,58,62,64,65,70,77,79,82,84,86,97,99,112,115,116,124,129,130,133,134,135,139,140],"dynam":[8,13,14,16,17,22,32,35,40,41,66,67,70,72,73,75,76,78,83,100,103,112,115,119,121,123,124,127],"dynamic_quantized_model":[48,49],"dynmaic":27,"e":[8,9,14,18,20,27,35,56,57,58,81,82,86,90,92,99,103,105,107,116,117,124,125,131,133,134,135,139,140],"e2m1":[40,42,75,79,80],"e2m3":[40,42,75,79,80],"e3m2":[40,42,75,79,80],"e4m3":[15,40,42,75,79,80,123],"e4m3fn":[17,124],"e5m2":[17,40,42,75,79,80],"e8m0":[14,75],"e_":81,"each":[2,3,8,9,14,15,16,20,22,27,29,30,31,34,35,40,42,45,56,57,58,70,72,73,74,75,77,80,81,82,86,87,90,92,99,100,107,111,115,118,119,122,128,129,132,133,134,139,140],"eager":[9,13,16,17,86,99,124,133,136,137,138],"eager_mod":[9,13,14],"earli":[22,36,39,92,124,131],"earlier":[135,139,140],"early_stop":73,"earlystop":[63,74,75,124],"eas":[19,22,72,74,75,76,81,86,110,114,115,118,124,128,129,130,132],"easi":[17,20,29,65,99,100,118],"easier":[23,27,70,77,87,117,124,134],"easili":[18,98,99,116,118,122,140],"ecosystem":[20,88],"edg":[17,22,36,39],"edit":79,"editor":18,"effect":[14,18,19,27,35,36,39,70,73,74,75,81,82,88,116,117,118,120,125,133,134],"effici":[16,19,22,27,41,42,66,67,70,71,73,74,75,76,77,82,83,100,107,115,118,121,124,126,127,129,131,133,135,139],"eg":9,"eight":119,"either":[11,13,18,19,27,77,82,84,94,107,133,134,135],"elaps":97,"element":[6,14,17,19,27,35,40,42,73,74,75,76,80,81,107,119,124,140],"element_dtyp":[40,75,79],"element_typ":6,"elementari":139,"eleutherai":96,"elif":[72,73,74,75],"elimin":[70,107],"els":[72,73,74,75,96,104,133,135,136,137,138,140],"elucid":19,"ema":124,"embed":[16,105,107,124,134,139],"embed_token":[107,122],"embeddingbag":16,"emerg":[76,139],"emoji":139,"emploi":[19,115],"empow":17,"empti":[14,27,70,77,82,99,118,133],"en":[39,77],"enabl":[8,14,16,18,19,22,27,29,35,36,39,42,47,64,66,67,72,77,79,82,86,88,90,98,100,121,124,126,127,129,134],"enable_data_cach":34,"enable_npu_cnn":[6,8,27,56,57,58,79],"enable_npu_transform":[6,8,27],"enablenpucnn":[29,47,64],"enablesubgraph":27,"enablevaimlbf16":27,"encapsul":[8,10,12,14,88],"encod":[9,100,133,136,137,138],"encoder_hidden_st":135,"encount":[19,20,22,56,57,58,72,74,75,76,81,86,110,114,115,118,128,129,130,132],"encourag":[20,90],"encrypt":[6,8,27,47,124],"encrypt_algo":6,"encrypt_data":6,"encrypted_data":6,"encryptionalgorithm":27,"end":[8,18,22,27,42,82,90,92,100,130,131,134,139,140],"end_node_1":[78,124],"end_node_2":[78,124],"endswith":[28,130],"energi":[24,55],"enforc":[6,107],"engin":[20,40,139],"enhanc":[14,17,19,36,39,42,62,65,73,74,75,76,82,88,115],"enough":[77,131,134,139,140],"enrich":[87,134],"ensur":[3,7,11,13,18,20,22,27,29,30,47,56,57,58,64,66,67,70,71,77,79,80,88,90,92,98,122,127,133,135,137,138],"enter":135,"entir":[2,8,14,35,42,45,47,74,92,99,107,115,124,134,135],"entri":[20,107,120,133],"entropi":[2,16,17,27,77,124],"enum":133,"enum_data":[28,29],"enumer":[27,34,128,129,132,135,140],"env":[57,62],"environ":[17,18,20,22,27,41,73,79,86,90,107,116,124,131,135,139,140],"eo":[92,139],"eor":92,"eos_token":[133,136,137,138],"ep":[107,126],"epoch":[12,117,140],"epsilon":[6,37,86],"equal":[6,19,23,27,66,67,68,76,82,87,99,118,127,139],"equat":[6,19,100],"equival":[19,100,118],"erf":79,"error":[8,11,12,13,14,18,21,22,24,27,30,35,40,55,66,67,69,74,75,77,81,82,85,86,97,107,115,116,118,124,127,130,133,139],"especi":[23,24,25,32,40,42,67,107,112,139,140],"essenti":[7,11,13,18,20,56,57,58,134,135,140],"establish":20,"estim":[30,85,139],"etc":[6,15,16,27,35,56,57,58,63,76,83,99,100,103,105,117,122,123,124],"eval":[13,70,80,83,87,90,91,92,93,94,98,99,100,112,116,117,118,119,124,133,135,136,137,138,140],"eval_50000":65,"eval_batch":97,"eval_data":[62,65],"eval_data_path":[62,65],"eval_dataload":134,"eval_mod":92,"eval_model":[107,124],"eval_output_path":97,"eval_result_output_path":97,"eval_task":97,"evaldataread":27,"evalmetr":27,"evalu":[27,28,45,56,57,62,63,68,76,77,83,100,108,109,117,124,125,128,129,132,133,135,136,137,138,140],"even":[14,19,21,27,35,39,40,71,79,81,107,117,139],"event":21,"eventu":135,"everi":[6,80,82,99,116,120,124,133],"everyon":140,"everyth":133,"evolut":77,"ex":[79,140],"exact":27,"exact_match":92,"exactli":[100,107,134],"examin":139,"exampl":[3,9,13,14,15,17,19,20,27,32,34,45,48,49,50,51,52,54,56,57,58,59,60,62,63,64,65,66,67,70,72,76,77,78,79,80,81,84,86,87,88,89,91,92,93,94,95,97,99,100,103,112,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,134,135,139,140],"example_arg":116,"example_fil":92,"example_input":[9,87,99,114,116,117],"example_quark_torch_llm_eval_harness_offlin":90,"exce":[56,57,58,69,77],"exceed":[69,70,77],"except":[27,86,122],"excess":4,"exchang":47,"exclud":[3,4,5,6,8,14,15,27,66,67,78,86,94,96,116,121,122,123,124,127,131],"exclude_lay":[15,115,122,123,131],"exclude_layers_nam":[15,96,133,136],"exclude_nod":[66,67,127],"exclude_subgraph":67,"exec":48,"execut":[2,8,9,23,27,41,42,63,64,70,71,76,77,79,97,99,100,124,126,131],"execution_provid":[2,6,8,64],"executionprovid":[27,64],"exemplifi":19,"exercis":88,"exhaust":77,"exist":[3,18,27,76,77,82,110,130,133,140],"exist_ok":[34,128,129,132,135],"exp":[117,133,136,137,138],"expand":[20,27,79,82,124,133],"expand_dim":28,"expect":[9,11,13,19,20,69,77,88,118,124,130,140],"expens":140,"experi":[17,22,23,24,25,115,116,117,129,132,140],"experiment":[17,76,79,87,88,124,140],"expert":140,"explain":[5,28,34,56,57,58,72,74,80,83,128,129,132,139,140],"explan":[116,122,129],"explicit":[19,72],"explicitli":[4,19,27,82,99,133],"exploit":77,"explor":[17,56,57,58,77,80],"expon":[17,35,40,41,42,66,67,73,74,75,76,80,81,119,127],"exponent_of_scale1":116,"exponent_of_scale2":116,"export":[1,13,14,16,17,19,41,43,44,45,46,48,49,50,52,53,54,55,56,57,58,59,60,61,67,87,91,94,98,99,114,117,124,126,133,136,137,138,139,140],"export2oga":55,"export_config":[9,105,124,135],"export_dir":[9,87,99,105,114,116,124,135],"export_for_train":[87,99,116,117],"export_gguf":[9,100,102],"export_gguf_model":9,"export_onnx":[9,41,43,44,46,53,54,57,87,99,104,116,117],"export_onnx_dir":87,"export_onnx_model":[9,135],"export_path":[9,100,104,135],"export_quark_model":[9,105],"export_safetensor":[9,83,103,124,133,136,137,138],"export_safetensors_model":[9,124],"export_yolo_to_onnx":67,"exported_model":99,"exported_model_dir":105,"exported_onnx_model":116,"exporterconfig":[9,10,105,124,135],"expos":88,"express":[19,21,27],"expressli":21,"extend":[5,35,36,39,42,74],"extendedcalibrationmethod":6,"extendeddequantizelinear":79,"extendedquantformat":[6,8,27,74,75,76,79,124,129],"extendedquantizelinear":[36,79],"extendedquanttyp":[6,8,74,75,76,79,124,129],"extens":[8,17,20,22,98,109,124],"extern":[2,6,8,70,88,98,105],"external_data":71,"external_data_loc":70,"external_data_size_threshold":70,"extra":[2,27,72],"extra_info":[29,64,128,129],"extra_op_types_to_quant":[6,8],"extra_opt":[2,3,5,6,8,56,57,58,63,74,75,76,77,79,124],"extract":[92,100,133,135,139],"extraoptypestoquant":27,"extrem":[115,124],"f":[28,34,48,96,100,128,129,130,132,133,134,135,136,137,138,140],"f37072fd":87,"face":[0,1,9,16,18,67,80,83,84,96,97,100,101,119,131,134,135,139],"face_quant":67,"facebook":[13,49,50,52,59,83,95,96,103,107,112,119,123,124,134,140],"facilit":[34,36,39,88,116,121,126,131],"fact":[17,72,76,86,105,135],"factor":[3,10,14,19,27,31,33,39,77,81,82,103,111,113,115,118,133,135],"fail":18,"failur":[20,70,124],"fair":92,"fake":[2,13,99,105,107,124,125,140],"fake_calibr":2,"fake_datatyp":14,"fake_quant":9,"fakebook":134,"fakequant":[13,86,99],"fall":45,"fals":[2,3,4,5,6,8,9,12,13,14,15,24,27,34,45,56,57,58,63,69,70,77,78,80,83,84,87,96,99,100,103,104,107,112,116,117,118,120,122,123,124,128,133,134,135,136,137,138,140],"famili":[80,124,130],"familiar":[135,139],"famou":[134,139],"faq":124,"fashion":[17,86,133],"fashionmnist":140,"fast":[8,20,42,68,72,74,75,78,100,120,124,129],"fast_finetun":[73,74,75],"faster":[18,19,22,41,42,64,69,72,73,76,124,129,135,139],"fastfinetun":[27,56,57,58,63,74,75,77,124],"fastft":[77,124],"fatal":[8,12,14,27],"favor":[9,19,124],"fc":107,"fc1":118,"feasibl":[19,100],"featur":[16,22,28,29,30,64,70,79,80,82,83,85,86,100,120,121,131,133,135,139,140],"februari":141,"fed":[19,139],"feed":[6,27,130,139],"feedback":[20,140],"feel":[45,135,139],"fetch":83,"few":[18,19,22,23,24,25,27,76,81,91,100,130,133,139,140],"fewer":[73,81],"fewshot":91,"fid":89,"fidel":82,"field":[12,15,123,133,134],"figur":[28,63,66,67,82,100,115,118,127,128,129,132,133,139],"file":[7,9,13,14,18,20,21,22,23,24,25,27,28,29,34,41,42,47,52,56,57,58,60,63,66,67,68,70,72,73,74,75,77,79,86,88,90,92,94,95,96,97,98,100,102,103,105,109,114,115,116,117,120,121,124,127,133,134,136,139,140],"file_nam":117,"file_path":[14,34],"filenam":140,"filesystem":18,"filter":[77,92,135,139],"final":[19,27,47,51,62,65,77,80,81,82,107,116,117,119,134,135,139],"final_layer_norm":[118,134],"find":[3,6,9,48,56,57,58,77,82,84,100,115,117,124,126,133,134,139,140],"find_best_candid":77,"find_int16_scal":6,"find_n_candid":77,"find_quant_scale_zp":3,"find_quantized_valu":3,"fine":[8,17,18,30,42,63,66,67,74,80,82,85,99,107,115,116,124,127],"finer":[35,40,42,74,75,81,131],"finetun":[62,65,68,72,74,75,78,128,129,132,135],"finetune_checkpoint":97,"finetune_dataset":97,"finetune_seqlen":97,"finish":[99,116,124,134],"firmwar":21,"first":[3,14,62,65,70,77,79,82,86,88,92,100,116,118,124,130,133,139,140],"first_lay":122,"first_stag":14,"firstli":135,"fit":[21,124,140],"fix":[6,17,20,22,27,33,41,70,73,113,118,133,135,139],"fix_shap":[41,71],"fixedse":[74,75,77,124],"fixneuron":70,"fixshap":27,"flag":[3,4,6,8,9,10,14,27,70,120,131,139],"flash":21,"flatten":140,"flexibl":[8,22,32,65,73,74,75,76,77,88,92,112,123],"float":[3,5,6,9,10,12,13,14,15,16,17,19,22,25,27,32,34,35,36,37,38,39,40,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,63,66,67,68,69,72,74,75,76,77,81,82,87,96,99,100,103,112,116,117,118,120,122,123,124,126,127,129,133,135,136,137,138,139,140],"float16":[2,14,16,17,19,27,36,39,60,61,76,81,104,121,124,125,129,131,135],"float16_model":129,"float16_onnx_model_path":129,"float16spec":14,"float32":[2,14,16,19,27,28,34,81,91,93,94,100,128,129,131,132],"float32_model":[128,129,132],"float32_onnx_model_path":129,"float8":[19,125],"float_16_onnx_model_path":71,"float_32_onnx_model_path":71,"float_model":[34,99,128,132],"float_model_path":[128,130,132],"float_onnx_model_path":77,"float_output":130,"flow":[16,92,124,131,140],"flower":135,"flux":124,"focu":139,"focus":[82,90],"fold":[4,9,27,28,116,118],"fold_batch_norm":4,"fold_batch_norm_after_concat":4,"fold_fp32_yolo_nas_m":116,"foldbatchnorm":27,"folder":[28,29,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,61,62,63,65,66,67,68,79,86,89,95,96,99,103,109,110,116,120,127,128,129,130,131,132,134,139,140],"folder_to_sav":116,"foldrelu":[27,128],"follow":[3,14,16,18,19,20,21,27,28,29,34,41,42,43,44,45,46,47,48,49,50,51,53,54,55,56,57,58,59,61,62,64,65,70,74,76,77,78,79,80,81,83,85,86,87,89,92,94,95,96,97,100,107,112,115,116,117,118,119,120,121,123,124,126,127,128,129,130,131,132,133,134,135,139,140],"footprint":[19,73,82,140],"forc":[3,27,74,75],"forcequantizenoinputcheck":[27,129],"forg":18,"forget":38,"form":[19,37,105,120],"format":[2,8,9,10,13,14,15,16,17,19,20,27,29,35,38,40,41,43,44,45,46,47,51,53,54,56,58,65,66,67,68,70,71,72,73,74,75,76,80,82,84,87,92,99,100,101,116,117,123,124,126,127,128,129,130,131,132,133,135,139,140],"former":[76,107],"formula":[5,14,36,39,140],"forward":[38,82,99,107,116,117,118,133,134,139,140],"forward_back_pass":135,"found":[3,8,77,81,87,99,107,116,117,118,131,139],"four":[9,71,87,92,120,121,130,139],"fp":2,"fp16":[8,27,70,72,89,100,110,115,124,126,131,135],"fp16_model":[60,61],"fp32":[8,27,66,67,72,80,98,99,100,116,117,124,126,127,139],"fp32_yolo_nas_m":116,"fp4":[14,17,42,80,96,103,124],"fp4_e2m1":[14,40,75],"fp4pergroupspec":14,"fp6":[35,42,80,124],"fp6_e2m3":[17,40,75,124],"fp6_e3m2":[17,40,75,124],"fp6e2m3":14,"fp6e2m3pergroupspec":14,"fp6e3m2":14,"fp6e3m2pergroupspec":14,"fp8":[9,14,15,16,17,35,42,80,83,89,103,104,115,123,124,135],"fp8_e4m3":[14,40,75,112,122,124],"fp8_e4m3fn":[17,124],"fp8_e5m2":[17,40,75,124],"fp8_per_tensor_spec":[112,122],"fp8e4m3":[14,124],"fp8e4m3perchannelspec":14,"fp8e4m3pergroupspec":14,"fp8e4m3pertensorspec":[14,135],"fp8e5m2":14,"fp8e5m2perchannelspec":14,"fp8e5m2pergroupspec":14,"fp8e5m2pertensorspec":14,"fp8scheme":15,"fp8\u2460":96,"fpx":115,"frac":[81,86,100,118,120],"framework":[19,22,28,56,57,58,70,72,83,98,100,126,135],"free":[21,45,120,135,139],"freez":[13,99,103,116,117,135],"freezed_quantized_model":135,"frequent":139,"fresh":131,"friendli":[40,81,98,99,107,116,117,121,133],"from":[3,4,5,6,8,9,10,13,14,15,17,19,20,21,22,23,24,25,27,28,29,30,34,35,36,37,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,63,64,66,70,71,72,73,74,75,76,77,78,79,80,81,82,83,85,86,88,90,91,94,96,99,102,103,104,105,107,112,114,115,116,117,118,119,122,123,124,127,128,129,130,131,132,133,134,135,136,137,138,139,140],"from_config":[103,124],"from_dict":[107,134],"from_pretrain":[13,80,83,96,100,103,107,112,119,124,133,134,135,136,137,138],"from_subgraph":3,"frozen":[9,118],"frozen_model":[87,99,116,117],"frozenfakequant":13,"fruit":139,"fsdp_config":97,"full":[6,16,19,20,22,23,24,25,36,39,77,103,139],"full_shard":97,"fulli":[20,87,99,107,116,130,132,134],"fun":140,"func":116,"function":[2,4,6,7,8,9,11,13,14,19,20,57,58,63,70,72,84,96,99,103,104,105,114,116,123,124,128,132,133,135,139,140],"fundament":[17,120,133],"furnish":21,"further":[17,18,19,22,55,56,57,58,80,82,87,120,130,134],"furthermor":[47,74],"fuse":[4,27,70,79,82,118,124,133],"fuse_gelu":4,"fuse_instance_norm":4,"fuse_l2_norm":4,"fuse_layer_norm":4,"fusegelu":27,"fuseinstancenorm":27,"fusel2norm":27,"fuselayernorm":27,"fusion":[27,70],"fuss":140,"futur":[20,27,88],"fx":[16,17,86,109,124],"fx_graph":[9,13,114],"fx_graph_mod":[9,13,14,87,99,114,116,117],"g":[8,9,14,18,20,27,35,48,55,56,57,58,60,61,81,82,99,103,105,107,116,117,124,125,133,134,140],"g128":[91,93,94,97],"gain":[17,82,86,133,135,140],"gan":135,"gap":124,"gate":[38,80],"gate_proj":[14,82,86,107,122,123,133,136],"gather":79,"gaussian":135,"gb":[70,139],"gcc":[124,140],"gelu":[4,27,124],"gemm":[8,24,25,27,55,71,76,78,79,124],"gemma2":[15,124],"gemma3":[15,124],"gemma3_text":15,"genai":126,"genai_config":90,"gener":[6,13,14,16,18,20,24,27,28,29,33,34,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,62,65,68,69,70,71,76,77,80,81,84,90,92,94,105,107,113,114,116,121,124,128,130,131,133,135,136,139,140],"generation_config":[49,50,52,59,103],"get":[6,9,14,15,18,28,39,49,50,52,59,68,80,82,83,99,100,107,109,116,117,123,124,126,130,131,134,135,137,138,139,140],"get_annotate_tensor":6,"get_available_provid":[72,73,74,75],"get_clip_min_max":6,"get_config":[9,15,82,83,96,123,124,133,136,137,138],"get_data_load":117,"get_dataload":[133,136,137,138],"get_datatype_shap":6,"get_default_config":[8,28,29,78,124,128,130,132],"get_exclude_nod":6,"get_export_model":9,"get_input":[34,128,129,130,132],"get_library_path":[64,70,72,73,74,75,79],"get_lr_schedul":117,"get_model":[117,133,136,137,138],"get_model_input_nam":28,"get_model_typ":96,"get_next":[28,29,128,130,132],"get_optim":117,"get_output":[34,130],"get_pilev":[133,136,137,138],"get_provid":64,"get_qdq_to_remov":6,"get_qmin_qmax_for_qtyp":6,"get_qrange_for_qtyp":6,"get_schem":15,"get_supported_schem":15,"get_token":[96,133,136,137,138],"get_wikitext_dataset":[107,134],"ggml":100,"ggml_common_aggr":100,"ggml_half":100,"ggml_half2":100,"gguf":[9,16,17,96,101,124],"gigant":140,"gimp":140,"git":[20,89],"github":[18,20,28,42,47,51,63,66,67,89,116,117,127,130,139],"gitignor":20,"give":[18,99,116,118,135,140],"given":[3,6,7,11,13,14,19,27,86,124,135,140],"glanc":116,"global":[8,10,14,27,78,81,122,123],"global_config":[8,15,22,23,24,25,27,29,47,64,72,73,78,118,123,124],"global_quant_config":[8,13,14,74,75,76,80,83,87,99,100,103,112,116,117,118,119,122,124,135,140],"globalaveragepool":[4,70,79],"go":[130,133,140],"goal":[30,56,57,58,70,81,85,140],"goe":81,"gold":90,"good":[20,67,77,80,115,130,135,140],"googl":135,"got":69,"gotten":140,"gp":77,"gpedit":18,"gpt":[96,124,139],"gpt2":[9,15],"gpt_oss":15,"gptj":[9,15],"gptnext":9,"gptq":[14,15,16,17,27,68,83,96,100,103,115,122,123,124],"gptq_config":[14,15],"gptq_quantized_model":50,"gptqconfig":[14,15,122],"gptqprocessor":122,"gpu":[9,12,14,17,19,22,27,41,42,56,57,58,62,65,70,72,73,74,75,76,77,79,89,90,91,93,94,95,96,107,117,122,123,124,125,126,129,131,134,135,139,140],"gqa":124,"grad":116,"gradient":[57,116,130],"gradient_acc_step":97,"gradient_accumulation_step":97,"gradual":105,"grai":140,"grain":[35,42,74,75,80,82,99,107,131],"grant":[21,131],"granular":[27,28,35,36,39,40,75,76,81,83,115,124],"graph":[6,9,16,17,22,27,28,70,86,104,109,118,120,121,124,128,129,130,132],"graph_model":[87,99,116,117],"graphic":140,"graphmodul":[13,86,99,116,117],"grayscal":140,"great":133,"greater":[56,58,69,70,77],"greatli":[22,139],"green":116,"grid":[77,82,115,133,135,139],"grid_h":135,"grid_w":135,"grok":[15,96,124],"group":[9,10,14,16,18,19,27,35,40,41,66,67,73,74,75,77,80,81,100,111,115,122,123,124,127,133,140],"group_siz":[9,13,14,15,80,96,97,100,102,111,112,115,118,119,122,131],"group_size_per_lay":131,"groupsiz":27,"grow":76,"gs128":[91,93,94],"gsm8k":92,"guarante":[20,88,100],"guess":70,"guess_output_rank":70,"gui":140,"guid":[19,20,28,56,57,58,64,68,77,80,83,84,87,100,109,115,119,128,129,130,132,134,135,140],"guidanc":[29,63,66,67,70,89,96,115,126,127],"guidance_scal":135,"guidelin":[20,90,130],"gz":[41,42,43,44,46,47,51,53,54,65],"h":[37,97,100,107,134,135,140],"ha":[6,7,11,13,14,15,18,21,22,27,35,36,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,54,55,56,58,59,61,62,65,66,67,69,72,75,80,90,100,111,116,118,120,126,127,128,129,130,132,133,134,135,136,139,140],"had":[120,135],"hadamard":[14,24,55,115,120,121,124],"half":[35,40,76,81,135],"half_even":[13,14,15,83,87,99,100,103,112,116,117,118,119,122,123,135,140],"half_to_even":119,"halt":[56,57,58],"halv":19,"han":[133,136,137,138],"hand":[19,28,75,125],"handi":100,"handl":[7,9,11,13,14,19,28,31,83,111,123],"happen":[14,77,140],"har":[93,94,97,124],"hard":[6,27,99,118],"hardsigmoid":79,"hardwar":[9,16,17,19,28,32,40,69,73,74,76,83,87,90,92,99,100,107,112,115,116,117,120,121,124,125,126],"harmon":[24,55],"haspredict":116,"hat":100,"have":[14,19,20,27,35,36,39,40,41,42,43,44,45,46,47,51,53,54,56,57,58,65,70,71,74,75,76,77,79,80,81,87,98,99,100,107,116,117,118,124,125,126,131,133,134,135,139,140],"haven":[131,140],"head":[69,99,107,116,117,124,134,139],"health":20,"height":37,"hello":[13,80,83,100,112],"help":[19,22,27,28,30,70,76,78,85,115,116,118,121,122,124,126,135,140],"helper":[6,14,80],"henc":[24,55,81,118],"here":[18,19,22,23,24,25,28,42,64,68,72,73,74,75,76,77,79,81,84,86,91,92,96,97,100,103,109,112,116,117,118,120,121,122,124,126,128,129,130,132,135,139,140],"herebi":21,"herein":21,"hereof":21,"heterogen":[35,36,37,38,39,40],"hf":[24,48,55,60,61,91,93,94,95,96,100,101,102,103,107,131,134,135,139],"hf_datasets_cach":[135,139],"hf_format":[9,91,93,94,96,97,131,139],"hf_format_export":9,"hf_token":80,"hidden":[8,20,38,81],"hidden_s":[14,38,55],"hierarch":[8,12,14,139],"high":[20,22,39,41,56,57,58,66,67,76,77,81,82,99,100,105,122,124,127,139],"higher":[14,19,22,27,40,62,65,70,71,76,78,79,82,87,96,107,124,125,133,135,139,140],"highli":[47,121],"hint":[124,140],"hip":[18,74,75,124],"hipcc":18,"histogram":[27,30,85,86],"histori":[77,139],"hold":[88,118],"holder":21,"home":116,"hook":[82,133],"hopefulli":140,"hour":135,"how":[8,9,13,14,15,19,22,23,24,25,27,28,29,34,50,52,55,56,57,58,59,60,62,64,65,67,77,83,84,91,92,93,94,98,103,105,112,115,116,122,125,126,130,134,135,139,140],"howev":[19,21,71,74,80,90,100,116,117,120,121,128,130,132,139],"hpcai":[96,124],"hqq":[27,124],"hspace":81,"html":[77,140],"http":[14,18,28,35,39,41,42,43,44,46,47,49,50,51,52,53,54,55,56,58,59,62,63,65,66,67,77,89,99,116,127,130,131,133,134,135,139,140],"hub":[116,135,139],"hug":[9,16,18,80,83,84,96,97,100,101,119,131,134,135,139],"huggingfac":[15,41,43,44,46,47,48,49,50,51,52,53,54,55,56,58,59,60,61,65,91,95,96,124,135,139],"huggingface_hub":[135,139],"huggingface_hub_cach":[135,139],"human":139,"hw":[92,116],"hw_emul":[81,124],"hw_emulation_interfac":81,"hybrid":131,"hyper":[56,57,58],"hyperparamet":[77,82,87,117,118,121,122,133],"i":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,51,53,54,55,56,57,58,62,63,64,65,66,67,68,69,70,71,72,73,77,78,79,81,82,83,84,85,86,87,88,89,90,91,92,94,96,97,98,99,103,104,105,107,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,127,128,129,130,131,132,133,134,135,136,137,138,139,140],"id":96,"idea":[24,55,77,82,118,119,120,133,140],"ideal":[40,73],"ident":[27,86,92,118,124,135],"identif":21,"identifi":[14,20,45,52,55,76,82,96,115,121,124,133],"idx":34,"ieee":19,"ignor":124,"ignore_warn":8,"ignorewarn":27,"igpu":[76,126,131],"illustr":[19,76,82,116,117,120,133],"ilsvrc":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00000236":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00000262":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00000293":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00001079":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00002138":[41,42,43,44,46,47,51,53,54,65],"ilsvrc2012_val_00002663":[41,42,43,44,46,47,51,53,54,65],"imag":[27,28,29,37,41,42,43,44,45,46,47,51,53,54,62,63,65,66,67,70,71,76,89,115,116,117,127,128,130,132,135,139],"image_classif":[28,63,66,67,68,109,127,130],"image_classification_example_quark_onnx_ryzen_ai_best_practic":66,"image_filenam":130,"image_fold":[28,29],"image_grid":135,"image_path":130,"imagedataread":[28,29,78,124],"imagen":135,"imagenet":[17,41,42,43,44,46,47,51,53,54,65,124,130],"imagin":140,"img":[135,140],"img1":140,"img2":140,"img_nam":28,"img_tensor":140,"immedi":[3,19],"impact":[22,76,129,134,139],"implement":[6,14,20,27,35,71,74,75,79,81,88,100,118,124,128,130,132,133,139],"impli":[21,27],"implicit":119,"implicitli":100,"import":[9,11,12,13,14,15,18,22,23,24,25,27,28,29,34,47,56,57,58,64,70,72,73,74,75,76,77,78,79,80,82,83,86,99,100,102,103,104,107,112,114,116,118,119,122,123,124,128,129,130,132,133,135,136,137,138,139,140],"import_file_format":[91,92,93,94,96],"import_model_dir":[9,91,92,93,94,96,97,105],"import_model_from_safetensor":[9,103,124],"import_model_info":[9,105,124],"improv":[11,13,22,23,24,25,28,35,40,42,62,64,65,66,67,69,70,76,77,82,87,107,115,120,124,127,130,135,139,140],"imread":[28,130,140],"imshow":140,"in_feat":118,"in_featur":[107,118],"inaccur":21,"inaccuraci":21,"inc":[21,45,52,55],"includ":[4,8,9,13,17,18,20,21,22,23,27,40,56,57,58,60,64,70,72,74,75,76,77,78,79,82,88,89,96,101,102,114,115,116,117,119,122,123,124,126,129,130,131,133,135,136,139,140],"include_auto_mp":[8,76,77],"include_cl":[6,8,23,46,56,57,58,77,124],"include_fast_ft":[6,8,56,57,58,63,74,75,77,124],"include_rot":[6,8,55],"include_sq":[6,8,55,59,77],"incom":[30,85],"incomplet":139,"incorpor":[89,120],"incorrect":124,"increas":[22,71,81,82,118,128,135,140],"increasingli":135,"incur":[80,82,120,133],"indent":[133,136],"independ":[27,35,40,42,111],"index":[12,18,20,69,76,77,103,128,129,130,132,134,135,139,140],"indic":[2,3,4,9,10,14,64,70,76,81,86,116,134],"indirect":21,"individu":[35,40,42,73,74,75,76,82,90,107,134,135],"industri":[119,134,139],"ineffect":[77,124],"inf":124,"infer":[6,9,11,13,17,19,22,27,28,32,40,56,57,58,63,66,69,70,71,72,73,74,75,76,77,79,80,82,89,90,100,107,112,116,118,120,124,126,127,128,129,130,131,132,135,139,140],"infer_devic":[22,64],"infer_float_timm_model":65,"infer_float_yolo_model":62,"infer_model_and_save_output":[128,129,132],"infer_on_imag":130,"infer_pack_shap":124,"infer_shap":[6,124],"inferdevic":[56,57,58,63,73,74,75,124],"inferenc":[74,75],"inferencesess":[6,34,64,70,72,73,74,75,79,128,129,130,132],"infin":6,"influenc":[14,71,107,117,124,134],"info":[8,9,12,14,27,100,107,110,133,134,136,137,138,140],"inform":[3,6,8,9,19,20,21,22,23,24,25,27,30,41,42,47,52,60,69,70,77,82,83,85,88,95,96,97,98,99,100,103,105,122,128,129,130,131,132,134,135,139,140],"infrastructur":20,"infring":21,"ingest":92,"ingredi":140,"inherit":[3,5],"init":124,"init_list":6,"initi":[3,6,19,27,56,57,58,75,77,87,96,100,119,133,136,137,138],"inner":99,"inp":[14,34,118,122,133,136],"input":[3,5,6,7,8,9,11,13,14,15,19,27,28,31,41,42,43,44,45,46,47,51,53,54,56,57,58,60,61,63,64,67,69,70,76,77,79,82,83,84,86,87,89,92,94,99,100,107,111,116,117,119,120,124,128,129,130,132,133,135,139,140],"input1":34,"input1_nam":[29,34],"input2":34,"input2_nam":[29,34],"input_1":27,"input_2":27,"input_arg":[9,87,99,104,116,117,135],"input_data":[28,34,64,128,129,130,132],"input_data_load":[128,129,132],"input_dict":84,"input_fe":34,"input_fold":130,"input_folder_path":34,"input_forget":38,"input_height":29,"input_histogram":86,"input_id":[13,80,83,84,100,112,133,134,136,137,138],"input_imag":[28,67,89],"input_layernorm":[14,82,107,122,133,136],"input_list":84,"input_model":[6,71],"input_model_path":[22,23,24,25,28,29,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,63,66,67,70,71,72,74,75,76,78,124,127,128,129,130,132],"input_nam":[3,5,9,28,29,34,70,128,129,130,132],"input_nod":[6,8],"input_node_map":6,"input_path":71,"input_qdq_histogram":86,"input_ref_histogram":86,"input_ref_histogram_absmean_ch0":86,"input_ref_histogram_absmean_ch1":86,"input_s":[28,38,116],"input_scal":[3,5],"input_shap":29,"input_tensor":[14,84,87,99,112,116,117,118,122],"input_tensor_nam":29,"input_width":29,"inputdataset":34,"insensit":76,"insert":[19,24,27,55,71,72,76,86,99,100,116,117,120],"insid":[82,133,140],"inside_layer_modul":[12,14,96,122],"insight":86,"inspect":[116,124,133],"inspir":115,"instabl":[40,72],"instad":14,"instal":[17,19,20,27,28,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,73,74,75,79,83,89,90,97,98,109,116,127,133,134,136,137,138],"instanc":[3,4,6,19,27,37,45,57,58,63,70,80,84,122,128,132],"instancenorm":[4,27,37,79],"instances_train2017":[62,116],"instances_val2017":[62,116],"instanti":[13,80,83,87,88,114,124,128,130,132],"instead":[9,14,19,47,62,65,71,73,74,75,80,81,82,86,103,105,120,133,135,139,140],"instella":15,"instruct":[15,18,20,34,64,86,89,90,91,92,95,96,107,115,116,117,121,123,124,134,135,139],"insuffici":124,"int":[3,6,8,9,12,14,15,17,22,23,24,27,29,35,36,38,39,40,70,124,129,133,136,137,138,140],"int16":[6,16,17,27,36,39,54,66,67,76,78,124,127,128],"int16_cnn_accur":78,"int16_cnn_default":78,"int16_transformer_accur":78,"int16_transformer_default":78,"int16bia":[27,71],"int16method":6,"int16scal":27,"int16spec":[27,128],"int2":14,"int2pergroupspec":14,"int3":[14,16,17,115,122,124],"int32":[9,14,16,17,27,36,39,70,76,124,128],"int32bia":27,"int32spec":27,"int3perchannelspec":14,"int3pergroupspec":14,"int4":[9,14,15,16,17,19,27,79,91,93,94,96,97,100,102,103,104,115,122,123,124,126,131,139],"int4_matmul_nbit":60,"int4_wo_128":[15,96,123],"int4_wo_32":[15,123],"int4_wo_64":[15,123],"int4perchannelspec":14,"int4pergroupspec":14,"int4pertensorspec":14,"int4spec":27,"int4weightonlyschem":15,"int8":[6,9,14,15,16,17,19,27,28,36,39,40,41,42,43,44,46,47,50,51,52,53,54,55,59,61,66,67,69,72,75,76,78,79,80,81,83,87,89,96,98,99,103,104,112,115,116,117,118,119,120,121,123,124,126,127,128,130,132,135,140],"int8_cnn_accur":78,"int8_cnn_default":78,"int8_config":[78,124],"int8_per_tenser_dynamic_spec":112,"int8_per_tensor":99,"int8_per_tensor_fl":87,"int8_per_tensor_pow2":87,"int8_per_tensor_spec":[116,122],"int8_per_weight_tensor_spec":117,"int8_qdq":52,"int8_transformer_accur":78,"int8_transformer_default":[50,52,55,59,61,78],"int8_wo":15,"int8perchannelspec":14,"int8pergroupspec":14,"int8pertensorspec":[14,15,83,103,122,123,135,140],"int8schem":15,"int8spec":[22,23,24,25,27,78,124,128,130],"int_max":70,"integ":[6,27,33,70,76,79,80,86,113,130,135,139,140],"integr":[17,19,20,22,28,82,100,106,109,124,126,136,140],"intellig":[74,77],"intend":[2,56,57,58,80,139,140],"intens":[76,107,117,131],"intent":20,"inter":116,"interact":18,"intercept":19,"interest":[81,130,140],"interfac":[2,88,98,124,139,140],"intermedi":[6,27,38,77,107,120],"intern":[14,77,92,98,124,139],"interpret":[99,139],"interv":6,"intk":98,"intric":19,"intro_contrib":20,"introduc":[20,35,40,42,62,65,71,74,75,76,81,100,115,116,118,119,124,139,140],"introduct":[20,81,107,116,135,139,140],"introductori":28,"intuit":[81,135,139,140],"int\u2461":96,"invalid":[77,124],"inventori":130,"invers":[14,120,133],"invest":20,"invoc":124,"invok":[18,92,98],"involv":[14,16,19,30,33,76,85,88,100,113,134],"io":77,"iofc":38,"iou":117,"ipu":14,"ipynb":136,"ipython":135,"ir":139,"ireland":139,"irrespect":[28,83],"irretriev":19,"is_approximately_equ":6,"is_avail":[18,133,135,136,137,138,139],"is_clip_with_min_max":6,"is_dynam":[13,14,15,80,83,87,99,100,103,112,116,117,118,119,122,123,135,140],"is_leaky_relu_with_alpha":6,"is_node_needs_annot":6,"is_scale_qu":14,"is_version_below":6,"islic":[116,117],"isn":139,"issu":[20,22,57,70,72,74,115,116,124,139],"item":[56,57,58,63,96,133,136,137,138,140],"iter":[22,28,29,77,104,128,129,132,135],"iteration_limit":77,"itertool":[116,117],"its":[3,11,13,15,16,18,19,20,22,27,28,35,40,62,65,77,79,80,81,82,83,86,88,103,115,118,120,123,124,132,133,139,140],"itself":[14,18,19,71,82,105,117,133,139],"iv":6,"j":[96,124],"job":[27,70,140],"join":[28,34,107,128,129,130,132,133,134,136,137,138,139],"joint":[77,124],"journei":17,"jpeg":[41,42,43,44,46,47,51,53,54,65,140],"jpg":[28,45,62,63,66,67,71,116,127,128,129,130,132,140],"json":[9,10,13,14,16,17,24,27,49,50,52,55,59,60,61,62,86,90,92,96,97,101,103,105,107,114,115,116,121,123,124,133,134,136,140],"json_export_config":[9,10,105,124,135],"json_path":[13,114],"jsonexporterconfig":[9,10,105,124,135],"judg":27,"june":141,"jupyt":117,"just":[27,47,72,99,117,133,135,139,140],"k":[17,81,96,120,124,135,139],"k2":[15,123],"k_1":81,"k_2":81,"k_proj":[9,14,15,82,96,107,118,122,133,136],"karpathi":139,"keep":[3,9,19,22,56,57,58,77,100,115,116,117,135],"keep_float_weight":3,"keep_io_typ":71,"kei":[6,9,19,76,77,80,87,88,96,100,103,115,118,131,134,139],"kept":[76,100],"kernel":[4,27,71,81,110,115,120,124],"kernel_ext":18,"kimi":[15,123],"kimi_k2":[15,123],"kind":[21,99],"king":139,"knob":140,"know":[19,139],"known":[19,32,40,41,42,43,44,45,46,47,51,53,54,65,70,99,110,112,134,140],"kv":[10,14,15,16,17,115,120,123,124,131],"kv_b_proj":[15,123],"kv_cach":[9,10,14,124],"kv_cache_cfg":122,"kv_cache_dtyp":96,"kv_cache_fp8":122,"kv_cache_group":[10,14],"kv_cache_quant_config":14,"kv_cache_schem":[15,83,96,123,124,138],"kv_group":9,"kv_layer":9,"kv_layer_nam":[9,123],"kv_layers_nam":[15,96],"kv_scale":9,"kwarg":[8,9,27,69,78,124,134],"l":[135,139],"l1":[56,57,58,63,77,118],"l2":[27,56,57,58,63,71,76,77,124,128,129,130,132],"l2norm":[4,27],"l2target":76,"lab":[133,136,137,138],"label":[34,140],"labels_map":140,"lack":135,"laion":135,"laion400m":135,"lamb_in1k":[22,41,43,44],"lamb_in1k_adaquant_quant":[41,43],"lamb_in1k_adaround_quant":44,"lamb_in1k_fix":41,"lamb_in1k_quant":[41,43,44],"land":139,"languag":[9,16,17,82,84,95,100,105,107,109,115,118,121,122,124,125,131,133,135,140],"language_model":[68,84,95,96,97,107,109,115,118,120,124,131,134,139],"laptop":[18,131],"larg":[2,4,9,16,17,24,25,27,70,73,77,82,84,86,105,115,116,117,118,121,124,130,131,133,134,135,140],"larger":[19,22,71,80,107,116,120,124,131,134,139,140],"last":[14,47,86,100],"last_lay":122,"latenc":[56,57,58,72,99,129],"latent":[27,135],"later":[18,19,70,118,135,139,140],"latest":[9,18,72,129],"latter":[22,76],"launch":97,"law":139,"layer":[4,8,12,13,14,15,19,22,23,27,36,38,39,65,66,67,68,76,77,78,86,96,105,107,116,118,120,121,122,123,124,125,127,130,133,134,136,139,140],"layer0":27,"layer_config":[15,123],"layer_id":122,"layer_importance_depth_prun":12,"layer_norm":118,"layer_norm_field":[12,134],"layer_num_field":[12,134],"layer_quant_config":[14,122],"layer_type_config":[8,15,27,78,123,124],"layer_type_quant_config":14,"layerimportanceconfig":134,"layerimportancepruneconfig":[12,107,134],"layernorm":[4,27,79,98,118,123],"layerwis":53,"layerwise_percentil":53,"layerwisemethod":[2,27],"layerwisepercentil":[27,124],"layout":[9,38,71,124],"lead":[11,13,19,22,28,41,42,43,44,71,73,76,81,115,129,130,133,134],"leaderboard":124,"leakag":88,"leaki":[6,27],"leakyrelu":[27,79],"learn":[7,8,9,10,11,12,13,14,17,19,22,28,66,67,72,74,75,80,83,100,119,120,124,126,127,129,130],"learnabl":87,"learning_r":[22,27,64,66,67,72,73,78,97,124,127,128,129,130],"learningr":[63,74,75,77,124,129],"least":[12,77,82,133,134],"leav":[27,139,140],"left":[14,28,81,82,86,96,107,118,129,133,135,136,137,138],"legaci":135,"legal":20,"len":[130,133,135,136,137,138,140],"length":[31,39,94,111,139],"less":[6,19,27,76,80,99,100,107,118,124,134,140],"let":[18,35,80,100,116,117,130,133,135,139,140],"level":[3,8,14,17,19,22,27,35,42,70,74,76,77,90,107,120,122,130,135,139,140],"leverag":[17,76,77,81,88,98,125,126,132,133],"lfloor":100,"li":[19,62,65,81,133],"liabil":21,"liabl":21,"librari":[9,19,20,28,36,39,65,70,79,80,87,88,98,103,105,118,119,126,135],"licens":20,"life":130,"lifecycl":20,"light":[17,106,109,124],"lightweight":98,"like":[3,6,7,8,14,15,17,18,19,21,24,27,63,67,70,72,77,78,80,83,86,88,100,116,124,126,129,135,139,140],"likelihood":77,"limit":[6,21,27,70,73,76,77,87,91,92,95,96,124,139],"lin1":118,"line":[18,63,66,67,112,120,127,130,133,135,139,140],"line_encod":[133,136,137,138],"linear":[6,14,16,19,36,39,40,82,96,98,105,107,118,121,122,124,125,133,139,140],"linear1":118,"linear2":118,"linear_lay":98,"linear_relu_stack":140,"link":[18,20,22,23,41,43,44,46,53,54,73,74,75,79,84,90,99,104,116,135,139],"linker":140,"linux":[16,17,72,73,74,75,79,122,124,135,139,140],"list":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,22,23,24,25,63,76,77,79,82,90,91,99,103,105,116,117,118,120,123,124,133,136,137,138,139,140],"list_avail":[15,123,124],"listdir":[28,130],"littl":[25,81,99,100,140],"ll":140,"llama":[9,15,24,55,61,68,80,83,86,90,91,93,94,95,98,102,107,115,118,120,121,123,124,131,134,139],"llama2":[9,48,52,55,60,61,91,93,94,96,98,100,102,103,122,124,131],"llama2_checkpoint_fold":95,"llama3":[9,102,124],"llama4":[15,124],"llama_templ":[123,124],"llamaattent":107,"llamadecoderlay":107,"llamaforcausallm":107,"llamamlp":107,"llamamodel":107,"llamarmsnorm":107,"llamarotaryembed":107,"llayernorm":98,"llinear":98,"lllyasviel":89,"llm":[12,16,17,24,82,90,91,93,94,96,97,100,108,115,118,120,121,123,124,126,133,135,136,139],"llm_eval":[90,91,92,93,94,97,139],"llm_prune":[95,107,134],"llm_ptq":[96,115,118,120,124,131],"llm_qat":97,"llm_qat_":97,"llm_quant":139,"llmtemplat":[15,82,83,96,124,133,136,137,138],"lm":[93,94,124],"lm_head":[15,96,107,115,121,122,123,131,133,136],"lm_logit":[133,136,137,138],"lmhead":[91,93,94],"load":[6,9,13,14,16,18,22,27,28,29,45,47,56,57,58,76,91,93,94,96,99,100,105,107,116,117,124,133,134,136,137,138,140],"load_dataset":[107,133,134,135,136,137,138],"load_onnx_model":130,"load_param":[13,114],"load_pre_optimization_config_from_fil":14,"load_quant_algo_config_from_fil":[14,96,133,136,137,138],"load_state_dict":[99,124],"loader":[16,29,65,140],"local":[9,18,91,93,94,100,131,135,139],"local_model_cach":140,"locat":[18,20,70,79,82,133,135,139,140],"log":[9,18,27,47,70,77,97,134],"log2":80,"log_dir":97,"log_fil":97,"log_severity_level":[8,12,14],"logic":88,"login":[135,139],"logit":[131,133,136,137,138,140],"logo":21,"logseveritylevel":27,"long":[18,20,45,81,99,100,110,118,139],"longer":[22,129],"look":[3,8,77,129,139,140],"loop":[27,77],"lose":[25,139],"loss":[14,19,22,27,35,40,41,43,44,56,57,58,66,67,71,73,76,80,82,99,115,117,127,128,129,130,132,133,136,137,138,140],"loss_fn":140,"lossi":[19,140],"lost":[19,135,140],"lot":[70,117,135,140],"love":140,"low":[19,39,42,66,67,74,75,81,82,99,115,127,133,139],"lower":[19,22,70,73,76,81,82,96,118,129,130,135,140],"lowercas":96,"lpnormal":[4,79],"lr":[97,140],"lr_schedul":117,"lsoftmax":98,"lsq":[17,87,99,124],"lstm":38,"lwpmetric":27,"m":[6,18,27,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,61,63,65,66,67,71,79,81,97,100,107,111,120,127,128,129,130,131,132,134,140],"m_":81,"machin":[8,10,12,14,43,44,66,67,127,135,139,140],"made":[124,130,140],"mae":[14,27,133],"magnitud":[73,82],"mai":[3,14,18,19,20,21,27,28,56,57,58,70,71,77,82,86,87,100,103,105,107,116,117,118,121,125,130,132,133,134,135,139,140,141],"main":[20,24,27,28,41,42,43,44,46,47,49,50,51,52,53,54,55,56,58,59,63,65,66,67,83,88,95,97,100,119,127,130,133,134,140],"main_depth_prun":134,"main_devic":[107,134],"mainli":[55,77,99,100,107,117],"maintain":[20,27,36,39,71,72,73,74,76,82,88,116,123,129,133],"mainten":[14,20],"major":[100,117],"make":[18,19,20,21,22,23,24,27,29,40,55,70,72,73,76,77,82,86,87,92,107,133,134,135,136,139,140],"makedir":[34,128,129,130,132,135],"man":139,"manag":[19,27,30,85,130,131,139,140],"mani":[18,21,22,23,27,63,76,79,80,81,116,118,130],"manipul":19,"manner":[77,99,116],"mantissa":[35,72,74,75,81,119],"manual":[56,57,58,76,79,88,121,133,134],"manual_se":135,"manufactur":21,"map":[3,6,8,9,14,19,27,56,57,58,99,103,116,117,133,135,139,140],"map0":62,"margin":[56,57,58],"mask":[69,116],"massiv":139,"match":[8,15,22,27,34,36,38,39,77,80,92,100,140],"materi":99,"mathbb":120,"mathemat":139,"matmul":[3,24,25,27,55,60,61,71,76,78,79,124,129],"matmul1":27,"matmul10":27,"matmul2":27,"matmul_4bit":60,"matmul_4bits_hqq_quantized_model":60,"matmul_4bits_quantized_model":60,"matmul_nbit":[50,60],"matmulconstbonli":27,"matmulnbit":[27,50,68,124],"matmulnbitsparam":27,"matplotlib":[135,140],"matric":[14,120],"matrix":[14,24,72,74,77,81,107,120,121,129],"matter":140,"maverick":124,"max":[3,5,6,14,27,30,79,81,85,86,87,94,99,100,118,139,140],"max_epoch":117,"max_grad_norm":12,"max_it":117,"max_new_tok":94,"max_seq_len":[96,97,133,136,137,138],"max_valu":6,"maxdepth":20,"maxdet":117,"maxim":77,"maximum":[6,9,19,27,30,56,57,58,69,70,77,80,81,85,119,140],"maxloopnum":27,"maxpool":[27,79],"mb":[41,42,43,44,46,47,49,50,51,52,53,54,59,62,65,130],"md":[18,20],"meadow":135,"mean":[6,20,27,30,31,35,36,37,39,40,66,67,72,74,75,80,81,85,86,92,96,99,100,107,111,115,116,117,118,121,124,125,127,128,130,135,139,140],"meaning":119,"meanwhil":[107,117],"measur":[27,56,57,58,76,77,130,139],"mechan":[82,88,116,139],"medic":130,"medium":[117,135],"meet":[4,20,32,45,63,66,67,77,79,87,112,116,117,127,128,129,132],"megvii":117,"mem":134,"mem_opt_level":22,"memori":[6,12,19,22,27,47,60,61,66,67,72,73,74,75,76,78,82,95,96,100,124,127,129,131,133,134,140],"mention":[87,100],"menu":18,"merchant":21,"merg":[9,10,20,21,49,50,52,59,70,82,115,116,129,133],"messag":[27,69,124],"met":77,"meta":[48,55,60,61,80,86,91,93,94,95,96,100,102,103,107,115,120,121,124,131],"metadata":100,"meteor":[90,91,93,124],"method":[2,3,5,6,8,9,13,14,16,17,19,22,27,31,32,57,58,62,63,65,66,67,69,73,77,82,83,84,86,87,88,98,99,100,111,112,115,119,120,121,122,123,124,127,130,134,135,139,140],"methodologi":115,"metric":[27,45,56,57,58,63,71,76,77,86,90,92,124,128,129,130,132,133],"metrics_output_dir":[90,93,94],"mfma_scal":124,"mha":124,"mi210":[89,125],"mi250":125,"mi300":[123,125],"mi300x":124,"mi350":123,"mi355":123,"micro":[17,21,35,40,45,52,55,74],"microexpon":[35,40,42,76,124],"microsc":[17,35,40,74,76,124],"microsoft":[18,28,63,66,67,95,96,97,107,124,127,130,139,140],"middle_lay":122,"might":[14,18,19,22,29,64,69,70,71,79,80,100,115,118,120,126,129,130,139,140],"migrat":[25,105],"million":130,"min":[3,5,6,14,27,30,79,85,86,87,99,100,140],"min_kv_scal":[10,14,15,123],"min_lr_factor":12,"min_max":[14,15,83,103,122,123,135,140],"min_val":100,"min_valu":6,"mind":[19,115],"mine":140,"mini":[92,95,96,107,117,124],"miniconda":18,"miniforg":[18,140],"miniforge3":18,"minim":[19,22,28,30,56,57,58,66,67,73,76,77,81,82,85,100,107,115,118,127,130,133],"minimalist":130,"minimis":140,"minimum":[6,10,14,15,18,19,27,30,79,85,100,123,140],"minmax":[2,8,16,17,27,56,57,58,63,66,67,69,72,74,75,76,77,79,85,87,98,124,127,128,129],"minms":[2,16,17,27,56,57,58,66,67,69,77,79,124,127],"minmse_mod":6,"minmsemodepof2scal":27,"minor":[41,42,43,44,80,124],"minut":[18,110],"misalign":[11,13],"mislead":124,"mismatch":[18,124],"miss":[71,77,140],"mistral":[15,96,123,124,139],"mistralai":[95,96,107,124,139],"mit":[20,21,45,52,55,133,136,137,138],"mitig":[21,24,41,43,44,55,133],"mix":[3,8,9,17,68,73,78,104,124,134],"mixed_precis":54,"mixedprecisiontensor":[76,124],"mixtral":[15,95,96,107,124,134],"mkdir":[28,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,63,66,67,127,130],"mlcommon":89,"mllama":15,"mlp":[14,82,86,107,115,118,122,123,133,136],"mlp_intermediate_size_nam":12,"mlp_pruning_modul":12,"mlp_pruning_ratio":12,"mlp_scaling_lay":12,"mmlu":[97,139],"mmlu_machine_learn":139,"mmlu_manag":[91,139],"mmlu_professional_law":139,"mmlu_sociologi":139,"mnist":17,"mobil":22,"mobilenet":[23,87,99],"mobilenet_v2":87,"mobilenetv2":87,"mobilenetv2_050":[22,41,43,44],"mobilenetv2_100":65,"mode":[3,5,6,8,9,13,14,16,17,27,35,40,76,86,88,90,109,110,122,124,134,140],"model":[3,5,6,8,11,12,13,14,15,16,21,22,23,24,25,26,27,30,32,36,39,64,72,76,78,81,82,84,85,86,88,98,104,105,109,112,115,117,118,120,124,125,126,133,136],"model2inspect":82,"model_acc":140,"model_accuraci":140,"model_arg":[91,93,94,139],"model_cach":140,"model_copi":118,"model_decoder_lay":[12,14,96,118,120,122,133,134,136],"model_dir":[9,95,96,97,100,102,103,115,120,124,131,134,139],"model_export":[87,96,97,131,139],"model_export_dir":97,"model_file_path":[13,114],"model_id":[89,133,135,136,137,138],"model_import":[9,124],"model_info_dir":[9,105,124],"model_input":[2,6,7,27,47,79],"model_input_nam":[28,128,130,132],"model_loss":140,"model_max_length":[96,133,136,137,138],"model_nam":[41,43,44,46,53,54,62,65,87,92,97],"model_name_or_path":[48,49,50,52,55,59,60,61],"model_name_pattern_map":96,"model_output":[6,7,27,47,79],"model_output_path":70,"model_path":[45,55,98,130,134,139],"model_prun":[107,134],"model_reload":[91,93,94,96,97],"model_select":135,"model_simp":[116,117],"model_state_dict":105,"model_trust_remote_cod":97,"model_typ":[9,15,82,96,100,102,114,123,133,136,137,138],"modelexport":[9,105,124,135],"modelimport":[9,105,124],"modelproto":[2,3,4,5,6,7,27,47,69,70],"modelprun":[11,107,134],"modelquant":[7,13,22,23,24,25,27,28,29,47,72,74,75,76,78,80,82,83,86,87,99,100,103,112,116,117,118,119,124,128,129,130,132,133,135,136,137,138,140],"modern":[73,74],"modif":[47,115,116,117,124],"modifi":[6,13,21,22,79,96,116,117,124,140],"modified_annotate_input":6,"modified_mod":116,"modifiedmodel":116,"modul":[8,9,10,11,13,14,15,16,20,30,70,82,85,86,87,96,99,100,112,116,117,118,124,133,140],"module2inspect":[14,122,133,136],"modulelist":[107,118],"moduletyp":6,"moe":[96,107,124,134],"monitor":77,"moonshotai":[15,123],"more":[9,11,13,14,18,19,22,23,24,25,27,28,32,35,40,42,45,55,56,57,58,63,69,71,73,74,75,76,77,80,81,82,83,87,90,99,100,107,112,116,117,122,124,126,128,129,130,131,132,133,134,135,139,140],"moreov":[70,103],"most":[16,20,27,40,41,42,43,44,46,47,51,53,54,65,70,72,73,77,82,86,90,96,100,105,121,131,134,135,139,140],"mostcommon":27,"motherboard":21,"motiv":[86,116],"move":[18,27,116,140],"mpimg":140,"mqa":124,"msbuild":79,"msc":18,"mse":[14,16,17,82,85,87,115,124,133],"mseobserv":117,"much":[18,22,25,100,116,120,134,135,139,140],"mul":[27,67,79,118],"multi":[9,17,56,57,58,91,92,93,94,99,118,124,139],"multi_devic":[9,13,82,133,136,137,138],"multi_gpu":[91,93,94,95,96,134],"multilay":14,"multimod":91,"multipl":[4,8,17,27,36,73,74,77,82,94,95,96,100,103,123,124,133,139,140],"multipli":[5,27],"multitask":139,"must":[5,9,20,27,36,38,39,70,71,77,79,80,82,84,92,102,116,118,130,133,134,135,139],"mv":116,"mx":[14,17,19,35,40,68,74,115,124],"mx4":[35,42,74,76,79,124],"mx4_adaqu":42,"mx6":[14,15,17,35,42,74,76,79,123,124],"mx6_adaqu":42,"mx6scheme":15,"mx6spec":14,"mx9":[14,17,35,42,76,79,124],"mx9_adaqu":42,"mx9spec":14,"mx_element_dtyp":14,"mxattribut":[75,76,79],"mxfixneuron":124,"mxfp":124,"mxfp4":[15,40,75,76,79,96,122,123,124,137],"mxfp4e2m1":42,"mxfp4e2m1_adaqu":42,"mxfp4scheme":15,"mxfp6":[40,75,79,124],"mxfp6_e2m3":[15,76,123],"mxfp6_e3m2":[15,76,123],"mxfp6e2m3":[15,42,96,123,124],"mxfp6e2m3_adaqu":42,"mxfp6e2m3schem":15,"mxfp6e3m2":[15,42,96,123,124],"mxfp6e3m2_adaqu":42,"mxfp6e3m2schem":15,"mxfp8":[40,75,79,124],"mxfp8_config":80,"mxfp8_e4m3":76,"mxfp8_e5m2":[76,124],"mxfp8_spec":80,"mxfp8e4m3":[42,96],"mxfp8e4m3_adaqu":42,"mxfp8e5m2":[42,96],"mxfp8e5m2_adaqu":42,"mxint8":[40,42,75,76,96],"mxint8_adaqu":42,"mxquantizedequant":[35,75,79,124],"mx\u2462":96,"my":140,"my_collate_fn":84,"my_shirt":140,"mymodel":118,"mysteri":140,"mysubmodul":118,"n":[6,16,18,27,35,36,37,39,40,81,89,92,100,107,120,133,134,136,137,138,139,140],"n01440764":[41,42,43,44,46,47,51,53,54,65],"n01443537":[41,42,43,44,46,47,51,53,54,65],"n15075141":[41,42,43,44,46,47,51,53,54,65],"n_job":77,"n_run":[133,136,137,138],"n_split":[133,136,137,138],"n_trial":77,"na":[68,99,124],"naiv":86,"name":[3,4,5,6,8,9,10,12,14,15,16,18,19,20,21,22,27,28,29,34,35,36,37,38,39,40,41,42,43,44,46,48,53,54,70,72,74,75,76,77,79,81,82,86,87,89,95,96,97,99,100,103,107,110,114,115,118,120,124,128,129,130,132,133,134,135,136,139],"nan":[86,124],"narrow":118,"nativ":[70,72,79,100,124,129,140],"natur":74,"navig":[18,120,126,135,139],"nbit":27,"nccl":97,"nchw":[8,27,69],"nchw_onnx_model_path":71,"ndarrai":6,"ndflhead":116,"nearest":[39,80],"necessari":[6,7,11,13,20,24,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,59,60,61,62,63,65,66,67,70,71,80,88,97,120,127,128,132,135,139],"necessarili":81,"necessit":[19,32,112],"neck":116,"need":[2,6,9,13,16,17,18,19,20,22,27,32,34,41,42,43,44,45,46,47,51,53,54,56,57,58,62,63,65,71,72,73,74,75,76,77,79,80,83,87,89,96,98,100,103,105,107,112,116,117,118,120,121,123,124,128,129,130,132,133,134,135,136,139,140],"neg":[36,39],"neglect":116,"neither":18,"nerv":133,"netron":[28,116,135],"network":[9,13,17,19,22,66,67,69,72,73,76,99,107,114,117,118,119,120,127,130,135,139,140],"neural":[5,13,17,19,22,66,67,72,73,76,116,117,119,126,127,130,135,139,140],"neuralnetwork":140,"neuron":[38,107,134,139],"new":[3,9,15,18,19,20,21,28,36,39,42,47,51,63,76,77,79,80,88,94,96,100,120,121,127,130,135,139,140],"new_templ":96,"newer":18,"next":[17,18,27,28,29,62,65,76,100,104,128,130,132,133,139],"next_modul":122,"nhwc":[8,27,69],"nhwc_onnx_model_path":71,"nibbl":100,"night":89,"nightli":18,"nll":[133,136,137,138],"nmsthre":117,"nn":[9,11,13,14,15,16,82,96,98,99,116,118,123,124,133,136,137,138,140],"no_cuda":[48,49,50,52,59,60,61],"no_grad":[116,118,133,136,137,138,140],"no_merge_realq_config":9,"node":[3,4,5,6,8,9,19,27,36,39,66,67,69,70,71,75,76,79,99,104,116,118,127],"node_nam":5,"nodeproto":[3,6],"nodes_list":6,"nodes_to_exclud":[3,4,5,6,8,27,124],"nodes_to_quant":[3,4,5,6,8],"noisi":135,"non":[9,20,21,37,69,79,82,86,87,99,107,118,124,133,134,135],"non_overflow":87,"none":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,27,28,29,63,64,70,77,78,84,92,96,99,103,118,124,128,129,130,132,133,136,137,138,140],"none_default":92,"none_psu_prompt":92,"none_psu_prompt_eos_stop":92,"nonequilibrium":135,"noninfring":21,"nonoverflow":[2,6,16,17,27,77,79,124],"norm":[4,27,76,77,107,122,134],"norm_modul":122,"normal":[4,12,22,27,28,29,37,47,70,82,84,100,118,130,133],"normalization_lay":98,"note":[3,4,7,9,13,15,18,20,21,27,36,39,41,43,47,67,70,74,76,77,86,87,88,89,90,92,99,100,105,116,117,119,123,133,134,135,139,140],"notebook":[117,135,139],"noteworthi":91,"notic":[21,79,120,133,135],"notifi":[20,21],"novelti":81,"now":[11,13,18,56,57,58,77,80,96,100,104,114,116,121,122,123,124,130,133,135,139,140],"np":[28,34,128,129,130,132],"npu":[4,5,8,16,27,72,76,78,79,87,90,92,99,117,128,129,131,132],"npu_cnn":[17,70,79],"npu_transform":[17,79],"npulimitationcheck":27,"npy":[29,71,128,129,130,132],"nsampl":[133,134,136,137,138],"nsgaii":77,"nuanc":16,"num":[57,89,92,134],"num_anchors_list":116,"num_batch":140,"num_calib_data":[55,95,96,131,139],"num_direct":38,"num_epoch":97,"num_eval_data":94,"num_fewshot":[91,92],"num_gpu":97,"num_hidden_lay":134,"num_imag":135,"num_inference_step":135,"num_it":[66,67,127],"num_iter":[22,27,64,72,73,78,124,128,129,130],"num_process":97,"num_sampl":34,"num_train_epoch":97,"num_work":34,"number":[12,18,19,22,24,25,27,29,35,37,38,40,41,56,57,58,66,67,71,72,73,74,75,77,80,81,89,91,92,94,107,116,119,120,127,129,135,139,140],"numel":[133,134,136,137,138],"numer":[14,19,27,40,42,72,74,75,76,129,139,140],"numiter":[63,74,75,77,124,129],"numiterlr":77,"numpi":[28,34,128,129,130,132],"nv":[22,116],"nvcc":18,"nvidia":[64,134,135,139],"o":[14,28,34,63,66,67,120,127,128,129,130,131,132,135,140],"o_proj":[14,82,107,120,122,133,136],"object":[6,7,8,9,15,27,41,42,43,44,46,47,51,53,54,65,67,68,70,74,75,116,117,128,129,132,133,140],"oblig":21,"observ":[13,14,19,83,87,99,100,112,118,119,122,124,130,140],"observer_cl":[13,14,87,99,100,112,116,117,118,119,122],"observer_method":[14,15,83,103,122,123,135,140],"observerbas":14,"obtain":[6,15,21,30,48,55,60,61,80,95,96,99,100,119,120,123],"obviou":139,"occupi":19,"occur":[19,70,73,97,124,130,135],"ocp":[14,40,75,123,124],"ocp_fp8_e4m3":16,"ocp_fp8e4m3":124,"ocp_mxfp4":16,"ocp_mxfp4diffsspec":14,"ocp_mxfp4spec":[14,80],"ocp_mxfp6":16,"ocp_mxfp6e2m3spec":[14,80],"ocp_mxfp6e3m2spec":[14,80],"ocp_mxfp8_e4m3":16,"ocp_mxfp8e4m3spec":[14,80],"ocp_mxfp8e5m2spec":[14,80],"ocp_mxint8":16,"ocp_mxint8spec":[14,80],"ocp_mxspec":14,"octob":141,"off":[17,18,56,57,58,70,82,130,133,140],"offer":[19,28,32,35,40,64,112,121,123,127,128,129,131],"offici":[20,36,37,38,39,79,84,100,116,117],"offlin":[90,120,124,140],"offset":[19,116,140],"often":[19,30,62,65,67,71,84,85,107,115,120],"oga":[55,90,124],"oga_fp32_model":55,"oga_gener":92,"oga_refer":92,"oga_valid":55,"ok":79,"old":76,"older":18,"olmo":15,"omiss":21,"omit":[133,136],"onc":[28,83,88,99,131,133,139],"one":[3,9,18,19,22,27,31,36,38,39,42,56,57,58,63,70,71,76,77,81,82,86,88,100,103,107,111,112,116,117,118,119,120,121,122,128,129,130,132,133,134,139,140],"ones":[19,77,91,124,139,140],"onli":[3,6,9,13,14,15,16,17,18,21,22,23,24,25,27,29,32,35,38,39,45,47,55,61,70,71,72,73,77,79,81,83,86,87,90,92,99,100,101,102,103,104,105,112,114,115,116,117,118,119,120,122,123,124,125,128,129,130,132,134,135,139,140],"onlin":[115,120],"onnx":[5,9,10,18,19,23,24,25,26,27,29,30,31,32,36,39,41,42,47,48,49,50,51,52,54,59,60,62,64,65,77,79,83,87,99,100,101,109,117,124,126,128,129,130,132,139,140],"onnx_aten":9,"onnx_aten_fallback":9,"onnx_evalu":67,"onnx_export_config":10,"onnx_fallthrough":9,"onnx_format":[91,92,93,94],"onnx_load_model_with_decrypt":6,"onnx_ml_pb2":[3,5],"onnx_model":[50,52,59],"onnx_model_path":[34,72,73,74,75,79,128,129,130,132],"onnx_path":[57,58,63,89],"onnx_quant":3,"onnx_save_model_with_encrypt":6,"onnx_valid":[41,42,43,44,46,47,48,49,50,51,52,53,54,59,60,61],"onnxexporterconfig":10,"onnxquant":3,"onnxruntim":[3,5,6,27,28,29,34,36,39,56,57,58,62,63,64,66,67,69,70,71,72,73,74,75,77,79,124,127,128,129,130,131,132],"onnxruntime_genai":131,"onnxruntime_pybind11_st":69,"onnxruntimeerror":69,"onnxsim":[27,79,116,117],"onto":76,"oom":124,"op":[4,5,6,16,27,72,73,74,116,118,124],"op_level_per_channel":3,"op_typ":27,"op_types_to_calibr":2,"op_types_to_quant":[3,4,5,6,8],"open":[18,20,40,105,124,133,134,136,140],"openai":135,"opencv":28,"oper":[2,3,4,5,6,8,9,10,16,17,19,27,35,36,37,38,39,40,70,71,72,73,74,75,76,79,81,82,96,98,99,100,103,104,116,117,118,120,124,129,133,139,140],"operaton":27,"operator_export_typ":9,"operatorexporttyp":9,"oppos":92,"opset":[9,27,70,71,79,124],"opset_vers":[9,70],"opt":[13,15,25,50,59,68,83,95,96,98,103,107,112,118,119,123,124,134,140],"optim":[0,3,5,8,9,11,13,14,16,17,19,22,27,28,32,55,56,57,58,64,65,66,67,70,71,73,74,76,77,78,82,83,87,98,99,107,112,115,116,117,118,120,121,124,126,127,128,129,130,132,133,140],"optim_devic":[22,64],"optimalgorithm":[63,74,75,77,124],"optimdevic":[56,57,58,63,73,74,75,124],"optimize_model":[6,8,79],"optimized_rotation_path":14,"optimizemodel":[27,69],"optimum":[48,49,50,52,59,60,61,90,124,135],"option":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,22,27,29,35,36,38,39,40,60,72,73,74,75,76,77,78,79,86,87,88,90,96,97,99,103,115,121,124,133,136,137,138,140],"optuna":77,"optypestoexcludeoutputquant":27,"optypestoquant":[24,25,27],"orang":139,"order":[9,13,14,56,57,58,79,107,115,118],"ordin":139,"org":[14,18,35,39,55,62,99,131,133,134,135,139,140],"organ":[29,41,42,43,44,45,46,47,51,53,54,62,65],"origin":[3,6,9,10,13,15,16,19,20,22,27,32,56,57,58,70,77,81,82,87,99,103,107,112,116,117,118,121,124,133,134,135,139,140],"original_model":[103,116,124],"ort":[34,64,70,72,73,74,75,79,128,129,132],"ort_input":[128,129,132],"ort_out":[128,129,132],"ort_sess":[128,129,132],"orthodox":117,"orthogon":120,"os_cpu":6,"oss":124,"osscar":[12,95],"osscarconfig":[12,107],"other":[4,6,9,15,16,17,18,19,20,21,22,27,33,45,70,71,72,73,74,75,76,77,80,81,84,86,87,88,96,100,103,104,105,110,113,114,115,116,118,123,124,125,128,129,130,131,132,135,139,140],"otherwis":[3,6,8,14,16,19,20,21,22,27,71,72,74,75,76,77,81,86,110,114,115,118,128,129,130,132,139],"our":[20,28,36,39,69,87,100,101,116,130,133,134,135,139],"out":[18,20,21,34,35,37,63,116,118,135,139,140],"out_feat":118,"out_featur":[107,118],"out_proj":118,"outcom":139,"outlier":[24,25,30,55,85,120,133],"outlin":[18,20,63,66,67,88,115,127],"output":[3,6,7,8,9,14,19,22,27,30,34,45,56,57,58,60,61,63,64,67,70,71,76,77,82,85,86,87,89,90,92,99,107,117,118,124,129,130,131,133,134,135,139,140],"output_1":27,"output_2":27,"output_dir":[9,70,83,87,96,97,99,100,102,103,104,105,116,117,124,128,129,131,132,133,136,137,138,139],"output_fil":[128,129,132],"output_filenam":130,"output_fold":130,"output_imag":67,"output_model":71,"output_model_path":[29,41,42,43,44,46,47,48,49,50,51,52,53,54,55,57,59,60,61,63,66,67,70,71,72,74,75,76,127,128,129,132],"output_nam":[9,34,70,130],"output_nod":[6,8],"output_numpi":[128,129,132],"output_path":[55,71,130],"output_tensor":[14,87,99,116,117,122],"outputindex":76,"outputs_1":116,"outputs_2":116,"outputs_path":92,"outsid":140,"over":[8,10,12,14,35,74,75,81,86,110,117,118,130,131],"overal":[22,71,75,76,77,99,118],"overflow":[19,30,72,87,99,124,129],"overhead":[60,61,71,82,120,124],"overrid":[8,123,131],"overridden":[8,14,27],"overview":[28,83,140],"own":[15,16,20,35,40,45,80,84,101,124,135,136,139,140],"owner":20,"ownership":20,"p":[28,41,42,43,44,47,49,50,51,52,59,63,66,67,127,130,131,134],"pack":[6,9,38,124],"pack_method":[9,10,105],"packag":[6,18,22,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,59,60,61,62,63,65,66,67,90,97,116,127,131,135,139,140],"pad":[27,38,79,80,99,133,136,137,138,139],"pad_token":[133,136,137,138],"padding_sid":[96,107,133,136,137,138],"page":[18,20,28,48,55,60,61,83,95,96,99,105,126,130,131,134,135,139,140],"pair":[24,27,55,72,76,77,82,100,104,129,133],"paper":[14,22,23,35,74,82,118,119,124,133,134],"para":6,"parallel":[77,124,135,139],"param":[6,12,116],"param_num":134,"paramet":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,19,22,25,27,29,30,31,32,41,56,57,58,63,64,66,67,70,71,74,76,77,79,80,82,85,87,88,99,105,107,111,112,114,115,116,122,123,124,127,129,131,133,134,135,139,140],"parent":[3,118,124],"pars":[87,88,99],"part":[41,42,43,44,45,46,47,48,49,50,51,53,54,55,59,61,62,65,76,77,96,99,100,105,115,116,117,124,130,135,139,140],"parti":116,"partial":124,"particular":[14,17,21,92,140],"particularli":[30,72,73,74,76,85,133],"partli":17,"pass":[19,20,27,42,71,96,99],"past":[60,79,135],"path":[2,6,7,9,13,14,18,24,27,28,34,41,42,43,44,46,47,51,53,54,57,65,70,76,79,82,84,86,89,91,92,93,94,95,96,97,98,100,107,110,124,128,129,130,132,133,135,139],"path_to_hf_model":134,"pathlib":9,"pattern":[6,15,22,27,96,116,121,123,124,135],"pdf":14,"pdollar":62,"peak":132,"peopl":89,"per":[3,5,8,14,16,17,19,20,23,27,31,36,37,38,39,40,43,44,70,77,80,81,82,83,86,100,111,115,117,120,121,122,123,124,140],"per_channel":[3,5,6,8,14,27],"per_device_eval_batch_s":97,"per_device_train_batch_s":97,"per_gpu_eval_batch_s":[48,49,50,52,59,60,61],"per_group":[9,13,14,100,102,112,119,122],"per_tensor":[14,87,99,112,116,117,118,122],"perblockbfpobserv":119,"perblockmxobserv":19,"percentag":[14,27],"percentil":[2,6,14,16,17,27,56,57,58,63,68,69,77,79,85,124],"percentilecandid":27,"perceptron":[14,118],"perchannel":96,"perchannelminmaxobserv":[14,19,100,112],"perfectli":110,"perform":[3,5,11,13,14,16,17,18,19,20,22,23,27,28,29,30,34,35,41,43,44,47,56,57,58,69,70,71,73,76,77,78,80,81,82,83,85,86,87,98,99,100,115,117,119,120,124,128,129,130,131,132,133,135,139,140],"pergroup":96,"pergroupminmaxobserv":[13,122],"perhap":[40,86],"permiss":[21,48,55,60,61,95,96,131],"permit":21,"perplex":[90,91,94,100,120,121,133,136,137,138],"persist":115,"person":[21,140],"pertensorminmaxobserv":[19,83,87,99,100,112,118,122],"pertensorpowof2minmaxobserv":[87,116],"pertensorpowof2minmseobserv":117,"peun":11,"phase":[64,77,82,110,116,133],"phi":[15,95,96,107,124],"phi3":[15,92],"phi4":124,"photo":140,"physic":139,"pick":19,"pickl":86,"pictur":[139,140],"piec":139,"pil":[135,140],"pile":[133,136,137,138],"pilev":84,"pileval_for_awq_benchmark":[96,115,131,139],"pillow":135,"pin_memori":34,"pip":[27,28,79,83,90,97,116,131,133,134,135,136,137,138,139,140],"pipe":135,"pipelin":[124,131,135,136,137,138],"pixel":140,"place":[9,15,16,17,20,29,70,77,96,99,100,112,116,123,124,134,140],"placeholderobserv":122,"plai":[134,139],"plan":27,"platform":[16,17,18,56,57,58,70,73,79,121,123,124,131],"pleas":[18,19,20,22,23,24,25,27,28,35,41,42,43,44,46,47,51,53,54,62,64,65,71,72,73,74,75,76,77,81,82,84,86,90,92,97,100,110,112,114,115,116,118,124,128,129,130,132,133,134,135,139],"plethora":126,"plot":86,"plt":140,"plu":[96,124],"plural":139,"png":[28,63,66,67,71,86,127,128,129,130,132,135],"po":6,"point":[3,5,6,16,17,19,20,22,27,30,33,34,35,36,38,39,40,42,56,57,58,66,67,68,70,72,74,75,76,81,85,86,96,99,103,105,113,117,120,124,127,129,130,133,135,139,140],"pointwis":118,"polici":[18,20],"pool":[4,27],"poor":[27,71],"poorli":[41,43,44],"popular":[83,88,100,101,123,124,126,135,140],"portion":[21,139],"pos2scal":6,"pos_rang":6,"posit":[6,27,139],"possess":[16,122],"possibl":[9,18,21,22,25,30,63,76,77,81,85,99,100,116,118,124,140],"post":[14,17,19,22,32,56,57,58,63,64,66,67,99,100,108,112,116,117,118,121,124,125,126,127,133,140],"post_attention_layernorm":[14,82,107,122,133,136],"postprocess":67,"potenti":[11,13,19,38,40,56,57,58,77,82,124,133],"pow":[87,99,117],"power":[14,17,27,30,47,51,66,67,69,74,76,80,81,88,107,116,117,124,126,127,134],"powerof2":27,"poweroftwomethod":[2,6,8,27,56,57,58,69,77,79],"powof2":116,"ppl":[48,49,50,52,55,59,60,61,95,97,107,124,133,134,136,137,138],"ppl_eval":[133,136,137,138],"practic":[17,22,63,68,76,82,107,118,119,124,126,133,134],"practition":76,"pre":[14,16,17,18,19,22,28,29,56,57,58,77,83,99,107,116,118,121,123,124],"pre_layer_id":122,"pre_quant_opt_config":118,"pre_quant_optim":118,"pre_trained_path":117,"pre_trained_weight":99,"prec":[46,47,51,53,54,65],"preced":[4,21,82,118,133],"precis":[3,8,17,19,25,32,35,36,39,40,41,42,66,67,68,69,72,73,74,75,77,78,81,87,105,112,116,117,124,125,127,129,131,135,139,140],"pred":140,"pred_bbox":116,"pred_scor":116,"predefin":[56,57,58,77,78],"predict":[30,34,81,85,86,90,92,135,140],"prefer":[18,40,63],"prefix":[19,22,72,74,75,76,81,86,110,114,115,118,128,129,130,132],"prelu":[27,79],"prep_model":116,"prep_model_for_convers":116,"prepar":[9,13,17,70,98,99,124,140],"prepare_data":[41,42,43,44,46,47,51,53,54],"preprend":92,"preprocess":[29,63,66,67,124,127,128,130,132],"preprocess_imag":130,"prequant_stat":139,"prequantoptconfig":14,"prerequisit":17,"presenc":133,"present":[21,64,116,117],"preserv":[22,41,66,67,73,74,76,78,81,82,86,127],"pretrain":[65,87,90,91,93,94,117,135,139],"pretrained_weight":116,"pretrainedmodel":[82,133,136,137,138],"pretrainedtoken":[133,136,137,138],"prev_modul":122,"prev_op":[14,118,122,133,136],"prevent":[14,20,21,27,124,130],"previou":[22,32,37,72,76,78,112,114,118,135,139,140],"previous":135,"primari":88,"primarili":[21,33,98,113,115],"print":[6,8,15,18,27,34,47,64,82,96,118,123,124,128,129,130,132,133,134,135,136,137,138,140],"print_a16w8_a8w8_nod":71,"print_quantize_dynamic_info":6,"print_quantize_info":6,"print_summari":8,"printsummari":27,"prior":139,"priorit":[56,57,58,139],"prioriti":[76,77,139],"probabilist":135,"probabl":[139,140],"problem":72,"proce":77,"procedur":117,"process":[2,3,5,7,11,12,13,14,18,19,20,22,27,28,29,32,35,40,41,47,62,63,64,65,71,74,75,76,77,79,82,83,86,88,99,100,112,116,117,118,123,124,126,129,130,131,133,139,140],"process_images_and_inf":130,"processed_data":[128,130,132],"processor":126,"produc":[2,11,13,14,20,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,76,77,140],"product":[19,21,22,40,72,74,75,76,81,86,107,110,114,115,118,128,129,130,132,134,139],"profession":139,"profil":[20,76],"program":[79,97],"progress":[14,77,124],"progressivespec":14,"project":[9,14,18,20,24,40,55,96,99,118,120,124,139,140],"prompt":[18,79,92,135,139,140],"prompt_process":139,"propag":[116,140],"proper":[9,99,115,116,134],"properli":[20,56,57,58,133,136],"properti":[87,133],"proportion":[66,67,127],"propos":[14,20,24,36,39,55,107],"proprietari":105,"protect":[27,129,139],"proto":[6,27],"protobuf":[47,69,70],"provid":[2,4,6,7,8,9,11,13,15,16,17,19,20,21,26,27,28,34,41,42,43,44,46,47,51,53,54,62,63,64,66,67,71,72,73,74,75,76,77,78,79,80,82,83,84,86,87,88,89,90,92,96,97,98,100,103,104,107,115,116,121,122,123,124,126,127,128,130,131,132,133,136,140],"provider_opt":6,"prune":[1,17,108,109,124],"pruner":1,"pruning_algo":95,"pruning_algo_config":[107,134],"pruning_config":[107,134],"pruning_model":[11,107,134],"pseudo":[133,135],"pseudocod":117,"psnr":[56,57,58,63,71,124,128,129,132],"psu":92,"psu_prompt":92,"psu_prompt_eos_stop":92,"pt":[13,45,67,80,83,86,100,107,112,133,134,136,137,138],"pth":[9,13,87,101,105,114,116,117,140],"pth_path":[13,114],"ptq":[17,19,22,23,24,25,26,56,57,58,63,64,66,67,87,99,100,108,109,117,124,125,127,140],"ptq_qat_exp":117,"public":21,"publish":21,"pull":[18,20],"pullov":140,"pure":[77,79,134],"purpos":[14,20,21,40,77,79,107,119,130,139],"push":76,"put":[96,116,118,133,139,140],"pwd":89,"py":[41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,71,81,84,87,89,90,91,92,93,94,95,96,97,98,100,115,116,117,120,124,127,128,131,132,134,139],"py39":110,"pyd":18,"pyplot":140,"python":[20,27,28,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,70,71,78,79,87,89,91,92,93,94,95,96,97,98,99,116,117,120,122,127,128,129,130,132,133,134,135,136,139,140],"python3":[95,96,115,131,139],"pythonpath":89,"pytorch":[11,12,14,19,22,64,65,67,82,84,85,86,87,88,89,95,96,97,100,104,111,112,115,117,124,125,126,131,133,134,135,139],"pytorch_model":[49,50,52,59],"pytorchlight":98,"pytroch_light":98,"q":[6,19,72,79,96,100,124,139,140],"q4_0":100,"q4_1":[16,100],"q8_0":100,"q8_1":100,"q_grid":135,"q_imag":135,"q_layer_nam":[15,96],"q_proj":[14,15,82,96,107,118,122,133,136],"qarepvgg_block":116,"qat":[17,19,87,99,108,109,117,124,140],"qat_spec":14,"qatspec":14,"qbfloat16":[76,79],"qbfp":[74,76,79],"qconfig":[7,8,22,23,24,25,27,28,29,47,64,72,73,78,98,124,128,129,130,132],"qdq":[0,6,8,9,13,19,27,50,70,71,74,75,76,79,86,99,124,125],"qdq_quantiz":5,"qdqnputransformerquant":5,"qdqoptypeperchannelsupporttoaxi":27,"qdqquantiz":5,"qfloat16":79,"qint16":[56,57,58,63,76,77,79,124],"qint32":79,"qint8":[2,5,8,56,57,58,63,76,77,79,124],"qk4_1":100,"qkv":[118,124],"qlayerconfig":[8,22,23,24,25,27,29,47,64,72,73,78,124,128,129,130],"qlinearop":[3,5],"qmax":6,"qmc":77,"qmin":6,"qmodel":140,"qmodel_acc":140,"qmodel_accuraci":140,"qmodel_loss":140,"qmx":[75,76,79],"qoper":[36,39],"qparamslinear":9,"qrono":[14,16,17,83,103,122,124],"qronos_config":14,"qronosconfig":[14,122],"qscale_typ":98,"qscheme":[13,14,87,99,100,112,116,117,118,119,122],"qschemetyp":[13,14,83,87,99,100,112,116,117,118,119,122],"qserver":115,"qtensorconfig":27,"qtype":[3,6],"qualiti":[20,70,81,86,124,130,135,139,140],"quant":[16,19,25,27,50,68,87,89,99,112,116,117,133,135,136,137,138],"quant_algo":[96,115,120,131,139],"quant_config":[9,13,22,23,24,25,27,29,74,75,76,77,78,80,82,83,86,87,96,99,100,103,105,112,116,117,118,119,122,124,133,135,136,137,138,140],"quant_config_file_path":89,"quant_format":[6,8,27,74,75,76,79,124],"quant_glb_config":87,"quant_granular":27,"quant_method":103,"quant_mod":[9,13,14,87,99,114,116,117],"quant_model":[13,80,83,86,87,100,112,117,119,135,140],"quant_model_nonsmooth":118,"quant_model_smooth":118,"quant_pre_process":70,"quant_result":116,"quant_schem":[96,97,104,115,120,131,139],"quant_spec":[13,14,15,103,118,123],"quant_stub":116,"quant_typ":79,"quant_util":[6,124],"quantconv2d":19,"quantformat":[8,70,79,124],"quantgranular":27,"quantiz":[0,1,2,4,9,10,16,24,25,26,30,34,35,36,38,39,40,64,82,84,85,88,90,91,92,93,94,98,104,105,108,109,110,118,124,125,126,129,133,134,136],"quantizaiton":27,"quantization_config":[9,28,77,78,103,105,124,128,130,132],"quantization_spec":14,"quantizationconfig":[8,13,14,15,74,75,76,80,83,87,99,100,103,112,116,117,118,119,123,124,135,140],"quantizationmod":[3,5,9,13,14,87,99,114,116,117],"quantizationparam":3,"quantizationschem":15,"quantizationschemecollect":15,"quantizationspec":[13,14,87,99,100,112,116,117,118,119,124],"quantize_bias_stat":3,"quantize_bias_tensor":5,"quantize_data":6,"quantize_diffus":89,"quantize_initi":3,"quantize_model":[7,13,22,23,24,25,27,28,29,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,72,74,75,76,78,80,82,83,86,87,99,100,103,112,116,117,118,119,124,128,129,130,132,133,135,136,137,138,140],"quantize_model_pipelin":[82,133,136,137,138],"quantize_quark":[63,66,67,96,98,115,120,124,127,131,139],"quantize_stat":79,"quantize_timm":65,"quantize_weight":3,"quantize_weight_per_channel":3,"quantize_yolo":62,"quantizealloptyp":[27,129],"quantizebia":27,"quantized_configur":6,"quantized_llm":139,"quantized_model":[50,52,55,59,61,64,70,82,97,99,102,103,116,117,124,128,132,133,136,137,138],"quantized_model_path":[22,23,24,25,28,71,78,124,128,130,132],"quantized_output":130,"quantized_result":[128,129,132],"quantized_results_fold":[71,128,129,130,132],"quantized_results_folder_path":[71,128,129,132],"quantized_tensor_typ":[2,3,5],"quantized_value_map":3,"quantizedconv2d":99,"quantizefp16":27,"quantizelinear":[27,39,79,124],"quantizerlinear":104,"quantlinear":[9,19,140],"quantschem":96,"quantstub":116,"quanttyp":[2,5,8,56,57,58,63,73,76,77,79,124],"quark":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,23,24,25,26,27,30,31,32,34,35,36,37,38,39,40,41,42,45,47,48,49,50,51,52,54,59,60,62,63,64,65,70,77,78,79,81,84,85,87,88,91,93,94,95,98,101,102,103,104,108,111,112,114,115,116,117,120,121,122,123,124,128,129,130,132,134,136,137,138],"quark_0":18,"quark_ci":140,"quark_debug":86,"quark_debug_act_hist":86,"quark_debug_input_pickl":86,"quark_debug_nan":86,"quark_exported_model":100,"quark_format":9,"quark_graph_debug":124,"quark_model":[117,135],"quark_quant":[56,57,58],"quark_quickstart_tutori":140,"quarot":[14,16,17,25,68,108,115,124],"quarot_config":[14,24],"quarotconfig":[14,24,122,124],"queen":139,"queri":139,"question":[20,100],"quick":[28,63,66,67,70,126,127],"quicker":77,"quickli":[18,78,96,140],"quickstart":[17,135,139],"quickstart_result":140,"quint16":79,"quint32":79,"quint8":[56,57,58,79],"quit":[100,135],"qunat":3,"qweight":103,"qwen":[15,95,96,107,120,123,124,133,136,137,138],"qwen1":[92,96,124],"qwen2":[15,95,96,107,120,124,133,134,136,137,138],"qwen2_mo":15,"qzero":103,"r":[6,14,19,36,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,61,63,65,66,67,69,90,95,96,97,107,120,124,127,131,134,140],"r1":[14,55,120,121,124],"r2":[14,55,120],"r3":[14,55,120],"r4":[14,55,120],"r_config_path":[24,55],"r_matrix_dim":24,"r_scale":38,"r_zero_point":38,"ra_in1k":[54,65],"ra_in1k_mixed_precision_quant":54,"ra_in1k_quant":54,"rabbit":[135,139],"rabbit_prompt1":135,"rais":[3,8,80,86,124],"ran":140,"rand":[34,84,87,99,116,117],"randint":[34,119],"randn":[116,117,135],"random":[14,24,27,34,70,77,119,130,140],"random_data_reader_input_shap":70,"random_quant":[71,130],"random_quantized_output":130,"random_r1":14,"random_r2":14,"randomdataread":27,"randomdatareaderinputdatarang":27,"randomdatareaderinputshap":[27,70],"randomli":[14,77],"rang":[2,3,5,6,8,10,17,19,27,34,35,36,38,39,40,56,57,58,66,67,72,73,74,75,76,77,81,86,117,118,127,130,133,134,135,136,137,138,139,140],"rank":[36,39,70],"rate":[22,95,107,129],"rather":[14,30,85,124,139],"ratio":[107,124,134],"raw":[28,42,47,48,49,50,51,52,55,59,60,61,63,66,67,100,107,127,130,133,134,136,137,138],"raw_predict":116,"rb":38,"rbb":38,"rceil":100,"re":[72,140],"reach":[20,56,57,58,76,80,135,139],"read":[17,27,100,128,132],"readabl":124,"reader":[2,6,7,22,27,28,47,70,76,128,130,132],"readi":[11,13,20,28,56,57,58,80,83],"readm":[18,20],"readthedoc":77,"real":[6,9,10,19,29,30,69,77,85,105,107,116,130],"real_quant":[9,10,103,105],"realist":140,"realiz":[99,107],"realli":[81,140],"reap":76,"reason":[5,9,21,100,116,135,139],"rec":[41,43,44],"recal":140,"recalcul":27,"recalibr":135,"recap":17,"recent":134,"recip":[90,99,140],"recogn":[99,116],"recognis":140,"recommend":[9,16,22,27,29,70,71,77,79,87,118,131,135,139,140],"reconstruct":[66,67,107,127],"reconvert":70,"record":[30,82,85,99,133,140],"recov":[9,117,134,135],"recoveri":107,"recreat":140,"recurr":38,"recurs":3,"red":116,"reduc":[3,5,6,8,11,12,13,19,22,27,30,35,41,45,60,61,66,67,70,72,73,74,75,76,77,79,80,82,85,86,107,115,117,118,120,124,127,129,130,133,134,139,140],"reduce_rang":[3,5,6,8],"reducemean":[4,27,79],"reduct":[19,107],"redund":[70,79,134],"ref_input":86,"refactor":[20,124],"refer":[6,19,20,22,23,24,25,28,32,34,39,41,42,52,60,64,68,69,70,72,73,74,75,76,77,81,82,83,84,85,86,87,88,95,96,97,98,100,105,107,109,110,112,114,115,116,118,124,125,126,127,128,129,130,131,132,133,134,135,139,140],"refin":[30,77,85,124],"reflect":[19,34],"reg_distri_list":116,"regain":135,"regard":[107,116,124,135],"regardless":[71,74,75],"regist":[15,36,39,41,42,43,44,46,47,51,53,54,65,70,72,73,74,75,79,88,96],"register_custom_ops_librari":[64,70,72,73,74,75,79],"register_schem":[15,123],"register_templ":[15,96,123],"registr":124,"regress":[30,85,140],"regular":27,"rel":[27,81,82,86,99,116,118,133],"relat":[6,20,27,47,99,100,124,139],"relationship":[20,77,99,139],"releas":[18,20,21,67,76,88,131],"release_vers":[18,131],"relev":[14,20,22,23,24,25,41,42,52,60,64,81,86,88,95,96,97,98,133],"reli":[47,77,89,90,116],"relianc":21,"reliev":[24,55],"reload":[13,103,124],"relu":[3,4,6,27,79,99,140],"relu9":27,"relu_":116,"remain":[19,36,39,45,71,76,107,120,135],"rememb":140,"remov":[6,19,27,77,119,120,124,134,135,140],"remove_initi":6,"remove_nod":6,"removeinputinit":27,"removeqdqbetweenop":27,"removeqdqconvclip":27,"removeqdqconvgelu":27,"removeqdqconvleakyrelu":27,"removeqdqconvprelu":27,"removeqdqconvrelu":27,"removeqdqinstancenorm":27,"removeqdqmuladd":27,"renam":[18,124],"render":[20,21,39,140],"reorder":[9,10,13,105],"repalc":130,"repeat":[77,133,139],"repeatedli":139,"replac":[9,13,16,17,19,27,70,76,80,98,99,100,112,117,122,124,128,129,130,132,140],"replace_inf_valu":71,"replace_inf_weight":71,"replaceclip6relu":27,"repo":[28,42,47,51,63,66,116,117,127,130,135,139],"report":[18,20,90,140],"repositori":[20,21,135,139],"repres":[3,19,27,32,33,35,56,57,58,70,73,74,75,77,80,81,84,96,99,112,113,116,126,130,135,139,140],"represent":[6,9,19,21,27,35,73,74,81,116,135,139,140],"reproduc":[27,87],"request":[20,48,55,60,61,80,95,96,98,101,131,135,139],"request_access":135,"requir":[4,14,18,19,20,22,27,32,40,70,71,73,76,77,79,82,83,87,88,90,92,96,97,99,107,112,115,116,117,122,124,130,131,133,134,135,139,140],"requirements_gpu":65,"rerun":27,"res_orig":118,"res_quant_nonsmooth":118,"res_quant_smooth":118,"rescal":118,"research":[77,107,117,134,140],"reserv":[21,45,52,55],"reset_model":9,"reshap":[27,69,79,80],"resid":20,"residu":130,"resiz":[28,79,130],"resnet":[28,42,47,51,63,87,99,124,127,130],"resnet152":[23,46],"resnet152_cle_quant":46,"resnet152_quant":46,"resnet18":87,"resnet50":[28,29,42,66,68,127,130],"resnet50_quant":29,"resnetv17_conv0_fwd":[66,127],"resnetv17_stage1_conv0_fwd":[66,127],"resolut":[117,135],"resolv":[20,49,50,52,59,97],"resourc":[22,56,57,58,73,77,134],"respect":[21,65,81,94,100,120,135,139],"respond":20,"respons":[20,21,77,88,92,139],"rest":[18,119,131,140],"restart":18,"restor":[9,19],"restrict":21,"restructuredtext":20,"result":[3,14,16,17,19,22,29,32,42,55,63,67,77,92,99,103,112,115,118,120,124,128,129,131,132,133,135,139,140],"retain":[22,42,76,135,140],"retent":[66,67,127],"retrain":[17,19,22,107],"retriev":[3,8,9,80,81,119,124],"retrieve_dataset":92,"return":[2,3,4,6,7,8,9,11,13,14,15,18,27,28,29,34,47,57,58,63,69,77,82,84,96,99,107,116,118,128,129,130,132,133,134,135,136,137,138,139,140],"return_tensor":[13,80,83,100,107,112,133,134,136,137,138],"reus":34,"reusabl":15,"revers":[38,135],"reverse_convers":71,"review":[20,139],"revis":21,"rewind":[28,29],"rewrit":70,"rgb":135,"right":[19,20,21,28,45,52,55,56,57,58,81,86,118,119,129,139,140],"rigid":22,"rigor":[78,122],"risk":[20,21],"rm":[48,49,50,52,59],"rmax":[3,6],"rmax_overrid":6,"rmin":[3,6],"rmin_overrid":6,"rmin_real_rang":6,"rmse":133,"rnn":38,"roadmap":[20,21],"robust":[17,30,40,66,67,85,127,133],"rocm":[16,18,21,41,64,72,73,74,75,79,124,131,134,135,139],"rocm6":[18,134,135,139],"rocmexecutionprovid":[27,64,72,73,74,75,79],"roi":69,"role":[77,134],"room":139,"root":[8,140],"rotary_emb":107,"rotat":[14,15,24,55,83,96,108,115,123,124],"rotated_quantized_model":55,"rotated_smoothed_quantized_model":55,"rotation_config":[14,15,24,55],"rotation_s":[14,124],"rotationconfig":[14,15,122],"roug":[90,91,93,124],"round":[14,19,22,35,39,40,66,67,72,77,80,81,119,127,140],"round_method":[13,14,15,83,87,99,100,103,112,116,117,118,119,122,123,135,140],"rounding_mod":[35,40,74,75],"roundtyp":[13,14,83,87,99,100,112,116,117,118,119,122],"routin":133,"row":[107,134,135],"rsmnorm":121,"rst":[20,66,90],"rule":[84,139],"run":[6,18,19,20,27,28,30,34,36,39,41,42,45,64,69,85,90,91,92,93,94,95,97,98,99,102,110,116,118,120,122,124,125,126,128,129,130,131,132,133,134,135,136,137,138,139,140],"run_calibr":2,"run_onnx_model":6,"run_quark_awq_exampl":136,"run_quark_exampl":133,"run_quark_fp4_exampl":137,"run_quark_fp8_exampl":138,"runnabl":[99,117,124,134],"runtim":[2,3,17,27,29,32,36,39,64,70,73,77,79,99,100,112,124,126,130,135,139,140],"runtime_except":69,"runtimeexcept":69,"runwayml":89,"ryzen":[16,28,124,128,132],"ryzenai":123,"s16s16_mixed_s8s8":[54,78],"s16s16_mixed_s8s8_aaw":54,"s16s8_asw":78,"s16s8_asws_adaqu":78,"s16s8_asws_adaround":78,"s2":81,"s3":116,"s8s8_aaw":[43,44,46,53,54,56,57,58,78],"s8s8_aaws_adaqu":78,"s8s8_aaws_adaround":78,"s_":81,"s_2":118,"s_b":81,"sacrif":82,"sacrific":72,"safe":[99,131],"safe_seri":[107,134],"safetensor":[9,10,13,16,17,83,101,105,114,124,131,133,135,139],"safetensors_path":[13,114],"sai":[86,116,118],"salient":82,"same":[6,10,14,19,27,32,36,37,39,45,66,67,70,72,74,75,76,82,92,100,103,111,112,127,133,134,135,139,140],"sampl":[45,77,91,92,94,112,131,133,135,136,137,138,140],"sample_1":45,"sample_2":45,"sample_idx":140,"sample_quark_model":[116,117],"sampler":77,"sampler_algo":77,"samsum":94,"sandal":140,"satisfactori":77,"satisfi":[6,117],"satur":[39,129],"save":[6,7,8,9,12,13,14,22,27,47,56,57,58,63,66,67,70,76,77,86,92,93,94,97,100,105,116,117,118,124,127,128,129,130,131,132,135,139,140],"save_as_external_data":[6,60,61,70,71],"save_dir":[9,95,107,114,134],"save_gpu_memori":[12,134],"save_metrics_to_csv":[93,94],"save_model":[116,117],"save_onnx_model_with_external_data":6,"save_param":[9,13,114],"save_pretrain":[103,107,134],"save_pruned_model":95,"saved_format":[9,124],"saved_path":89,"savetensorhistfig":27,"saw":140,"sb":81,"scalar":[6,31,36,38,39,111,118],"scale":[3,5,6,9,10,14,15,16,17,19,22,23,27,28,30,31,33,35,36,37,38,39,40,42,47,51,56,57,58,66,67,69,72,73,74,75,76,82,85,87,99,100,103,105,111,113,114,115,116,117,118,123,124,126,127,130,133,140],"scale2po":6,"scale_calculation_mod":14,"scale_clamp_min":[14,118,122],"scale_format":14,"scale_typ":[13,14,15,27,83,87,99,100,103,112,116,117,118,119,122,123,135,140],"scaledfakequant":140,"scalequantspec":14,"scaletyp":[13,14,27,83,87,99,100,112,116,117,118,119,122],"scaling_lay":[14,118,122,133,136],"scenario":[2,16,28,39,77,83,124],"schedul":[20,65],"schema":[87,99,116,117],"scheme":[14,15,16,19,22,24,81,82,83,86,96,98,124,125,126,133,136,137,138,140],"scheme_nam":15,"scienc":139,"scope":[82,116,117,133],"score":[89,90,93,94,139],"scout":124,"scratch":[22,27,139],"screen":[27,47],"screenshot":28,"script":[17,20,42,45,65,70,87,98,100,116,120,121,124,131,133,134,135,136,137,138],"scrollabl":140,"sd":[89,135],"sd1":[89,124],"sd3":124,"sdxl":[17,89,124],"seamless":[17,124],"seamlessli":[17,28,125,126],"search":[18,68,82,115,116,124,126,131,133,139],"search_algo":[57,58,63],"search_cache_dir":[57,58,63],"search_devic":77,"search_evalu":[57,58,63,77],"search_metr":[57,58,63],"search_metric_toler":[57,58,63],"search_model":77,"search_spac":[56,57,58,63,77],"search_space_advanc":63,"search_space_with_gpu":[56,57,58],"search_space_xint8":[56,57,58,63],"search_stop_condit":77,"searched_candid":77,"second":[14,77,92,97,115],"second_stag":14,"secret":6,"secret_kei":6,"section":[18,27,28,41,42,43,44,46,47,51,53,54,65,83,99,126,127,130,135,139,140],"secur":[20,21],"see":[14,18,29,36,48,55,60,61,69,72,76,79,83,86,90,91,92,95,96,116,118,120,121,123,124,128,129,130,132,133,135,139,140],"seed":[116,133,136,137,138],"seem":99,"seen":[62,65,118,134,135,139],"segment":139,"select":[9,14,18,19,22,27,45,74,76,77,80,82,94,115,124,133,134,135,139],"self":[3,14,28,29,34,99,116,117,118,128,130,132,139,140],"self_attn":[14,82,107,118,120,122,133,136],"self_attn_layer_norm":118,"sell":21,"semant":135,"semi":[107,134],"sensibl":140,"sensit":[86,115,118],"sentanc":139,"sentenc":139,"sentiment":139,"separ":[3,14,27,70,76,92,94],"septemb":141,"seq_len":[94,96,131,133,136,137,138,139],"seq_length":38,"seqlen":[98,133,136,137,138],"seqlen_for_ev":[133,134,136,137,138],"sequenc":[2,38,94,139],"sequenti":[82,124,133,140],"seri":[35,45,56,57,58,135,139,140],"serial":[9,103,105],"serialis":140,"serv":[34,82,88,133],"server":[134,140],"sess_opt":[6,72,73,74,75,79],"session":[6,34,57,58,63,64,70,72,73,74,75,79,116,130,140],"session_opt":6,"sessionopt":[6,64,70,72,73,74,75,79],"set":[6,7,8,9,11,13,14,15,16,17,18,20,22,23,24,27,29,32,33,45,55,63,64,69,70,71,72,73,74,75,76,77,78,79,84,87,88,91,92,93,94,96,100,107,112,113,117,120,121,123,124,128,132,133,134,136,137,138,139],"set_calibration_method":72,"setup":[14,17,28,91,100,130,134,135],"seven":119,"sever":[19,26,27,40,42,74,75,77,79,81,87,100,107,115,116,117,118,121,122,123,134],"sg":116,"sgd":140,"sgmodul":116,"sh":[18,57,62,89,139],"shall":21,"shape":[6,27,28,31,36,37,38,39,41,69,70,80,81,100,111,116,118,124,133,135,136,137,138,140],"shape_infer":70,"shard":103,"share":[10,14,17,19,22,27,32,35,40,41,42,66,67,72,73,74,75,76,80,82,86,90,99,110,112,114,115,118,119,127,128,129,130,132,133,140],"shift":[27,33,35,81,82,113,115,118,119,133],"shift_label":[133,136,137,138],"shift_logit":[133,136,137,138],"ship":[20,140],"shirt":140,"shoe":140,"short":[20,22,81,107,119],"shortli":140,"shot":[92,107],"should":[9,10,11,13,14,18,20,27,29,36,38,39,56,57,58,70,74,77,78,79,80,82,84,86,88,92,95,96,100,105,116,117,119,122,133,134,135,139,140],"show":[9,22,23,24,25,28,50,55,59,67,76,83,92,107,110,116,117,123,128,129,130,132,134,140],"shown":[27,28,47,70,76,81,83,92,100,116,130,135],"shrink":[135,140],"shuffl":[34,84,133,136,137,138],"shufflenet":23,"side":[18,28],"sigma":118,"sigmoid":[6,27,67,79],"sign":[27,35,74,75,81,115,119],"signal":139,"signficantli":135,"signific":[17,20,22,76,82,107,115,133,135],"significantli":[22,32,41,43,44,67,73,76,77,112,115,120,124,129,130,135,139],"silu":107,"similar":[19,20,27,56,57,58,71,128,129,132,135,139,140],"similarli":[81,130],"simpl":[11,13,22,23,24,25,27,34,47,72,73,74,75,76,81,84,86,100,129,133,135,136,137,138,139,140],"simpleconv":[99,116],"simpler":[19,40],"simpli":[19,22,27,32,45,72,74,75,76,81,86,110,112,114,115,118,121,128,129,130,132],"simplifi":[17,18,19,27,28,79,83,96,116,117,118,123,124,133],"simplifymodel":27,"simul":[19,27,124],"simulate_bf16":71,"simulatedpu":27,"simultan":[22,76],"sinc":[9,36,39,71,77,120,130,139],"singl":[27,75,77,80,81,90,118,119,124,133,135,140],"single_gpu":16,"situat":[24,55,56,57,58],"size":[4,11,13,14,17,19,22,27,28,35,37,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,62,65,66,67,69,70,77,79,80,81,87,95,96,99,100,107,115,116,117,120,123,124,127,130,133,134,135,136,137,138,139,140],"skip":[27,70,115,130],"skip_evalu":97,"skip_finetun":97,"skip_onnx_shap":70,"skip_optim":70,"skip_prun":95,"skip_quant":[89,96,97,139],"skip_symbolic_shap":70,"slice":[4,27,67,70,79],"slice_1":67,"slight":[135,139],"slightli":[124,135,140],"slow":[124,135],"slower":18,"small":[14,20,35,40,42,64,71,72,75,77,81,99,107,117,120,124,140],"smaller":[4,14,19,47,75,77,81,111,134,135,139,140],"smallest":134,"smarter":124,"smooth":[14,25,27,68,115,121,122],"smooth_config":115,"smooth_fc_fc":121,"smooth_quant":[25,59],"smoothalpha":77,"smoothed_quantized_model":59,"smoothli":[56,57,58,116],"smoothquant":[7,8,15,16,17,83,96,100,108,115,120,122,123,124],"smoothquant_config":[14,15,118],"smoothquantconfig":[14,15,25,118,122],"smoothquantprocessor":122,"snapshot":139,"sneaker":140,"snippet":[47,82,96],"so":[18,19,21,25,27,38,64,70,71,72,73,79,103,116,119,130,131,133,134,135,139,140],"social":139,"sociologi":139,"softmax":[14,27,79,98,139],"softmax_quant_spec":14,"softwar":[21,126,134],"sole":[20,27],"solut":[17,20,69,77,107,110],"solv":[116,139],"some":[3,6,9,17,22,25,27,28,56,57,58,62,65,66,67,70,71,76,78,86,87,96,103,105,107,116,118,121,124,125,127,128,129,130,131,132,133,135,139,140],"someth":[18,139],"sometim":[19,22,70,72,74,75,76,81,86,110,114,115,118,121,128,129,130,132,139],"soon":131,"sophist":140,"sort":[76,140],"sota":65,"sourc":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,18,20,105,116,135],"space":[27,45,56,57,58,63,70,77,78,118,124,135,140],"space1":[56,57,58,63],"space2":[56,57,58,63],"spacetodepth":79,"span":[41,42,43,44,46,47,51,53,54,65],"spars":107,"sparsiti":107,"spdx":[45,52,55],"speak":16,"spec":[14,22,23,24,25,27,29,47,64,72,73,78,80,100,122,124,128,129,130,135],"special":[9,17,21,77,118,132,139],"special_tokens_map":[49,50,52,59,103],"specif":[3,4,5,6,8,12,14,15,18,19,21,22,27,28,35,40,56,57,58,63,66,67,72,73,74,75,76,77,79,80,81,82,83,84,86,87,88,89,92,99,103,105,107,110,114,115,118,120,122,123,124,125,127,128,129,130,132,134,139,140],"specifi":[3,4,5,6,7,8,9,10,11,13,14,15,20,22,23,24,27,28,29,35,36,38,39,40,56,57,58,62,65,70,71,76,77,82,83,86,87,90,91,92,93,94,99,118,122,124,128,130,131,132,133,135,139,140],"specific_layer_config":[8,27,78,124],"specific_tensor_precis":[6,8,76,124],"speed":[12,19,35,66,67,73,74,75,76,77,127,134,135,139],"speedup":124,"spinquant":[14,55,120,121],"split":[4,27,79,81,107,133,134,135,136,137,138,139,140],"split_large_kernel_pool":4,"splite":[35,40],"splitext":130,"splitlargekernelpool":27,"spot":140,"sq_alpha":55,"sq_config":25,"sqrt":[37,120],"squar":[8,30,85,115],"squeez":[79,140],"squish":140,"ssim":[56,57,58,63],"stabil":[14,20,74,135],"stabilis":14,"stabilityai":[89,135],"stabl":[9,17,40,77,89,124,135],"stablediffusionpipelin":135,"stack":[133,136,137,138,139],"stage":[14,19,77,124,130,140],"stand":81,"standalon":79,"standard":[9,19,20,22,40,73,77,90,120,124,131],"start":[6,8,14,18,20,27,28,45,56,57,58,63,66,67,77,78,83,87,110,126,127,131,133,135,136,137,138,139,140],"start_epoch":117,"start_node_1":[78,124],"start_node_2":[78,124],"state":[17,19,22,72,74,75,76,81,86,100,110,114,115,118,128,129,130,132,140],"state_dict":[100,140],"statement":[27,140],"static":[3,5,8,13,14,16,17,22,27,29,30,32,57,58,63,80,83,85,86,103,104,112,114,115,119,120,121,123,124,128,132],"static_group":[14,122],"staticmethod":[57,58,63],"statist":[30,85,86,118,124,140],"statu":69,"std":130,"stderr":92,"stem":139,"step":[3,17,18,19,20,23,28,57,58,63,64,70,71,76,77,80,83,96,99,112,116,117,118,119,121,124,128,130,132,133],"step1":47,"step2":47,"step3":47,"still":[3,39,80,100,112,135,139,140],"stop":[22,45,56,57,58,63,77,92],"storag":[34,41,42,43,44,46,47,51,53,54,65,66,67,70,73,76,80,81,100,107,127,139],"store":[9,13,18,19,27,29,47,70,71,77,81,86,100,103,114,119,131,135,139,140],"str":[2,3,4,5,6,7,8,9,10,11,12,13,14,15,27,28,29,56,57,58,63,70,96,128,129,130,132,133,134,136,137,138,140],"straightforward":[19,27,28,83],"straightforwardli":107,"strateg":133,"strategi":[9,16,17,27,28,63,66,67,73,77,81,115,120,121,124,127,128,130,132],"stream":134,"streamlin":[16,28,88,123],"strength":98,"strict":[47,92],"strictli":81,"stride_tensor":116,"strike":[19,74,86],"string":[14,22,24,27,35,38,40,70,82,133,140],"strip":[133,136,137,138],"strive":[20,86],"strongli":18,"struct":100,"structur":[11,13,15,18,22,35,68,77,82,100,107,109,121,133,134,139,140],"stuck":110,"studio":[18,79,140],"style":20,"sub":[27,29,35,42,74,79,81,124,131,139],"sub_1":67,"sub_block_s":[35,74],"sub_block_shift_bit":[35,74],"subblock":81,"subclass":[88,123],"subdivid":80,"subfold":20,"subgraph":[3,8,27,67,124],"subgraphs_to_exclud":[6,8,124],"subgroup":75,"subject":[20,21],"sublicens":21,"submiss":[20,140],"submit":[20,48,55,60,61,95,96],"suboptim":[28,130],"subscal":81,"subscript":81,"subsect":[18,139],"subsequ":[18,34],"subset":[41,42,43,44,46,47,51,53,54,65,81],"substanti":[19,21],"substitut":19,"subsystem":[18,135,139,140],"subtract":80,"success":[18,19,70],"successfulli":[6,18,70,100,102,135],"sudo":18,"suffer":[27,71],"suffici":[72,73,105,129,130],"suffix":27,"suggest":[18,77,131,135,140],"suit":[45,70,140],"suitabl":[76,121,124],"sum":[133,134,136,137,138,140],"summar":[87,90],"summari":[8,20,27,86,91,93,94,117,124],"summary_io_quantization_error":86,"summary_ref_input_error":86,"summary_ref_output_error":86,"summary_weight_error":86,"super":[34,57,116,118,130,140],"super_gradi":116,"superior":[17,115],"suppli":[117,124],"support":[3,6,9,13,14,15,16,17,19,20,27,28,29,30,31,34,36,38,39,41,42,47,55,56,57,58,63,64,67,70,71,72,73,74,76,77,81,83,85,86,87,89,91,93,94,98,99,100,101,102,103,104,105,110,111,114,115,116,118,119,120,121,122,124,125,126,128,129,130,131,132,134,135,139,140],"supportsreplacenumclass":116,"suppos":36,"suppress":[8,27],"sure":[18,19,27,92,133,134,135,136,139,140],"surround":139,"swap":[135,139,140],"swish":27,"switch":139,"sym_shape_infer_temp":124,"symbol":[70,135],"symmetr":[6,13,14,15,16,17,19,27,31,33,43,44,46,47,51,53,54,66,67,69,78,83,87,99,100,103,111,112,113,115,116,117,118,119,121,122,123,124,127,128,132,135,140],"sync":140,"system":[16,17,18,21,27,88,123,124,133,135,139,140],"systemat":77,"t":[2,3,35,37,38,40,45,100,118,131,133,135,136,139,140],"t1":[36,39],"t2":[36,39],"t3":[36,39],"tab":140,"tabl":[27,35,40,62,65,70,74,87,100,123,130,140],"tag":[100,140],"tag_quant_nod":116,"tail":118,"tailor":[32,73,76,112,118],"take":[15,18,20,22,27,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,65,66,67,77,96,99,100,103,116,123,130,135,139],"taken":[70,118],"tanh":79,"tar":[41,42,43,44,46,47,51,53,54,65],"target":[4,6,9,11,13,14,17,19,27,40,63,66,67,76,77,79,82,87,103,107,127,128,129,132,133],"target_devic":14,"target_vers":6,"targetoptyp":76,"targetquanttyp":76,"task":[17,48,49,50,52,56,57,58,59,60,61,77,90,91,93,94,116,117,124,135,139],"tbd":123,"team":20,"tech":[96,124],"technic":[20,21,82,133],"techniqu":[4,19,22,23,24,25,26,35,42,66,67,73,74,76,81,98,127,134,140],"technologi":[19,22,72,74,75,76,81,86,110,114,115,116,118,128,129,130,132],"tee":97,"templat":[1,18,56,57,58,82,96,124,133,136,137,138],"temporari":[20,27,47,77,124],"ten":110,"tens":139,"tensor":[2,3,5,6,8,9,10,11,13,14,16,17,19,23,27,30,31,34,35,36,37,38,39,40,43,44,70,72,73,74,75,76,81,82,83,85,86,87,99,100,111,115,116,117,118,119,120,121,123,124,128,129,130,131,132,133,135,136,137,138,139,140],"tensor_hist":27,"tensorflow":126,"tensorproto":[3,6],"tensors_rang":[3,5],"tensorsdata":2,"tensorsrangefil":27,"term":[11,13,19,20,21,22,72,74,75,76,80,81,86,99,110,114,115,118,128,129,130,132],"termin":[6,18,77,110,135,139,140],"test":[29,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,61,65,70,77,99,100,116,117,124,130,133,134,135,136,137,138,139],"test_conf":117,"test_data":140,"test_dataload":140,"test_imag":[28,63,66,67,127,130],"test_loss":140,"test_prompt":89,"test_siz":89,"testdata":[107,133,136,137,138],"testenc":[107,133,134,136,137,138],"text":[13,48,49,50,52,59,60,61,80,81,83,86,100,107,112,133,134,136,137,138,140],"text_encod":[89,124],"text_encoder1":135,"text_encoder_2":[89,124],"text_to_imag":89,"than":[6,14,18,19,22,29,30,33,47,56,58,62,63,65,70,71,73,76,77,80,81,85,100,113,115,116,118,120,124,128,131,135,139,140],"thank":[20,100],"thankfulli":100,"thei":[11,13,14,16,19,20,27,81,84,100,120,123,124,133,134,135,139,140],"them":[19,22,29,35,40,45,62,63,65,66,67,70,71,73,80,81,82,88,96,100,115,116,122,123,126,127,131,133,135,139,140],"theori":[139,140],"therebi":[19,24,55,77,82,127],"therefor":[70,71,76,90,120,139,140],"thereof":21,"thermodynam":135,"thi":[2,3,4,5,6,7,8,9,11,12,13,14,15,18,20,21,22,23,24,25,27,28,29,30,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,69,70,71,72,73,74,75,76,77,78,79,81,82,83,84,85,86,88,89,90,92,95,96,97,98,99,100,103,104,105,107,110,112,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140],"thing":140,"think":[19,100,139],"third":116,"thorough":122,"thoroughli":80,"those":[8,14,15,18,23,40,45,73,82,140],"though":[71,107,118],"thought":[135,140],"three":[32,35,42,70,71,77,84,98,100,112,119,129,134],"threshold":[14,17,56,57,58,70,77,124],"threshold_init_meth":14,"through":[9,13,17,19,27,32,34,74,75,76,81,82,83,88,92,96,98,103,107,112,115,118,123,126,130,133,134,135,139,140],"throughout":47,"thu":[18,81,82,86,120],"thudm":[95,96,97,107],"thumb":139,"tile":80,"time":[6,19,20,21,22,27,28,32,45,56,57,58,73,76,77,78,81,87,88,97,100,107,110,112,116,117,118,120,124,128,129,130,132,134,139,140],"time_limit":77,"timefram":135,"timeout":97,"timestamp":140,"timestep":135,"timm":[41,43,44,46,53,54,124],"tini":[99,139],"tinygsm8k":92,"tinygsm8k_inputs_limit":92,"tinygsm8k_references_limit":92,"titl":[133,139,140],"tmp":9,"tmpdir":27,"to_bfp":[35,74,79],"to_bfp_prim":[35,74],"to_fold":116,"to_quantization_spec":[14,15,80,83,103,122,123,135,140],"toctre":20,"todo":5,"togeth":[27,71,77,80,120,133,139],"toi":140,"token":[9,13,55,60,61,80,83,90,94,96,100,103,112,115,119,121,133,134,135,136,137,138],"tokenization_auto":96,"tokenized_output":[13,80,83,100,112],"tokenizer_config":[9,49,50,52,59,103],"tokenizer_path":[9,100,102],"toler":[6,45,56,57,58,63,76,77],"too":[14,22,135,139,140],"tool":[17,18,19,20,22,27,41,60,61,69,70,86,87,89,101,115,116,117,124,126,128,129,130,131,132,134,140],"tool_vers":6,"toolkit":[17,100,124],"top":[62,65,76,139,140],"top1":[42,76],"top5":42,"topic":[34,63,66,67,89,95,98,115,122,127],"topilimag":130,"torch":[9,10,11,12,13,14,15,18,34,41,43,44,46,48,49,50,52,53,54,55,57,59,60,61,68,70,80,81,83,86,87,88,89,90,95,96,97,98,99,100,101,102,103,104,105,107,109,112,114,115,116,117,119,120,121,123,124,131,133,134,135,136,137,138,139,140],"torch_dtyp":[107,134,135],"torch_extens":110,"torchaudio":[18,134,135,139],"torchscript":70,"torchvis":[18,87,89,99,130,134,135,139,140],"tort":21,"total":[71,81,107,134],"total_batch_s":97,"total_tim":97,"totensor":[130,140],"toward":130,"tpe":[77,124],"tqdm":[133,134,136,137,138],"tqt":[14,17,87,99,124],"tqtspec":14,"tqtthresholdinitmeth":14,"trace":[9,82,117,133],"track":20,"trade":[17,56,57,58,82,133],"trademark":21,"tradeoff":12,"tradit":[22,76,99],"tradition":100,"trail":[119,135],"train":[11,13,14,17,19,22,32,41,56,57,58,63,64,65,66,67,72,73,74,75,97,99,100,108,112,117,118,121,124,125,126,127,129,130,133,135,139,140],"train2017":[62,116],"train_batch_s":116,"train_dataload":[116,140],"train_dataset":[133,136,137,138],"train_in_it":117,"train_load":[99,117],"train_model":116,"trainabl":116,"trainable_modul":12,"trainer":[108,117,124],"training_data":140,"transfer":135,"transform":[4,5,6,8,9,13,14,18,19,24,27,30,50,52,55,59,70,77,78,80,83,85,96,100,103,105,112,115,116,118,119,120,124,126,128,130,132,133,134,135,136,137,138,140],"translat":[116,139],"transpos":[27,28,71,79,124],"trasnform":6,"travers":19,"treat":[27,82],"treatment":140,"tree":[41,43,44,46,47,51,53,54,56,58,65],"trial":[77,140],"trick":140,"trickier":140,"trigger":[56,57,58],"trillion":139,"troubleshoot":[17,18],"trouser":140,"true":[3,4,6,8,9,12,13,14,15,18,23,24,27,28,29,30,34,47,56,57,58,63,64,66,67,69,70,71,72,73,74,75,76,77,79,82,83,85,87,96,99,103,104,107,112,116,117,119,122,123,124,127,128,129,130,132,133,134,135,136,137,138,139,140],"true_sequenti":[12,122],"trust_remote_cod":[93,94,96,133,134,136,137,138],"try":[18,36,39,87,97,121,124,130,131,135,139,140],"tsv":89,"tunabl":82,"tune":[8,17,30,42,63,66,67,77,80,85,107,115,116,118,124,127],"tupl":[3,6,8,9,27],"turbo":[89,124],"turn":[22,62,65,70],"tutori":[72,74,75,76,80,100,119,133,134],"tw":118,"tweak":140,"twice":124,"two":[14,17,19,22,27,30,34,35,39,42,45,57,58,63,66,67,69,72,74,76,77,79,82,83,87,90,99,100,105,107,116,117,118,121,124,126,127,128,129,130,134,135,139,140],"two_stage_search":77,"twostagespec":14,"txt":[20,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,59,60,61,63,65,66,67,70,90,92,97,127,131],"type":[2,3,4,5,6,8,9,11,13,14,15,16,17,18,22,27,30,32,42,48,55,70,71,74,75,76,77,80,82,83,84,87,90,91,93,94,96,98,99,100,112,115,116,118,119,122,123,124,130,131,133,134,135,136,137,138,139,140],"typedef":100,"typic":[14,16,17,18,19,20,22,30,31,34,35,40,56,57,58,66,67,76,81,82,84,85,86,87,99,107,111,115,118,121,127,130,133,134,139],"typo":[78,122],"typograph":21,"u":[80,86,139,140],"u16s8_aaw":78,"u16s8_aaws_adaqu":78,"u16s8_aaws_adaround":78,"u8s8_aaw":78,"u8s8_aaws_adaqu":78,"u8s8_aaws_adaround":78,"u8u8_aawa":124,"ubuntu":[18,135,140],"ud":97,"uint":103,"uint16":[6,16,17,27,36,38,39,71,76,78,79,124],"uint16spec":27,"uint32":[16,17,27,36,39,76,79,124],"uint32spec":27,"uint4":[9,13,14,15,16,17,27,79,91,93,94,96,100,104,112,122,123,124],"uint4_int4_flag":[9,104],"uint4_per_group_asym_spec":122,"uint4_wo_128":[15,82,123,133,136],"uint4_wo_32":[15,123],"uint4_wo_64":[15,123],"uint4perchannelspec":14,"uint4pergroupspec":14,"uint4pertensorspec":14,"uint4spec":27,"uint4weightonlyschem":15,"uint8":[6,9,14,16,17,27,36,39,48,49,71,76,78,79,96,100,103,104,124],"uint8_dynamic_qu":[48,49,78],"uint8_t":100,"uint8perchannelspec":14,"uint8pergroupspec":14,"uint8pertensorspec":14,"uint8spec":[22,23,24,25,27],"ultralyt":45,"unaccept":[82,133],"unam":18,"unambigu":139,"unbias":77,"unchang":[22,120],"uncom":[112,140],"under":[20,41,42,43,44,46,47,48,49,50,51,52,53,54,55,59,60,61,88,100,102,107,116,117,124,134,135,139],"undergo":19,"underli":125,"understand":[16,77,80,122,135,139],"undesir":124,"undo":135,"unencrypted_data":6,"unet":[124,135],"unexpect":77,"unfamiliar":135,"unfortun":70,"unifi":[22,124],"uniform":[22,76],"uniformli":82,"uninstal":[56,57,58,62],"union":[2,7,8,9,11,13,14,15,27,100],"uniqu":[14,15],"unit":[5,20,82,124,126,133],"unk":[133,136,137,138,139],"unknown":[6,70,124,139],"unless":[8,14,19,22,27,39,72,74,75,76,81,86,110,114,115,118,128,129,130,132],"unlik":[22,35,72,99,133],"unnecessari":39,"unquant":[19,135],"unregist":15,"unregister_schem":15,"unset":27,"unsign":[27,115],"unspecifi":27,"unsqueez":[79,130,140],"unstructur":[107,134],"unsupervis":135,"unsupport":27,"until":[76,77,80,103,105,116,135,139],"unus":140,"unzip":[18,62,68,109,116],"up":[3,8,17,18,20,22,28,55,66,67,84,117,123,127,128,130,132,139],"up_proj":[14,82,107,122,123,133,136],"updat":[3,20,21,22,27,70,118,124,130,134],"upgrad":21,"upon":[48,55,60,61,95,96,133],"upsampl":135,"upsample_downsampl":135,"upscal":124,"upward":[35,40,82,133],"url":[18,56,58,134,135,139],"us":[2,3,4,5,6,7,8,9,10,11,13,14,15,16,17,18,19,20,21,24,25,27,28,30,32,33,35,36,37,39,41,42,43,44,45,46,47,48,49,50,51,52,53,55,56,57,58,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,81,82,83,84,85,86,87,88,90,91,92,94,95,98,103,104,105,107,108,109,112,113,114,115,116,117,120,121,122,124,125,126,127,128,129,130,132,133,134,136,137,138,139,140],"usabl":[20,103,105,124,134],"usag":[18,19,20,22,70,72,73,74,75,76,100,124,129,130],"use_adaqu":[41,43],"use_adaround":44,"use_dynamic_qu":8,"use_external_data_format":[2,6,8,27,69,70,78,124],"use_fast":[96,133,136,137,138],"use_gptq":50,"use_moving_averag":55,"use_pof2":6,"use_random_had":24,"use_sc":6,"use_unsigned_relu":3,"used_scale_zp_map":3,"usefp32scal":27,"usematmulnbit":27,"user":[0,1,7,11,13,16,19,27,29,34,68,76,82,83,87,88,89,95,96,98,99,100,112,116,117,119,121,124,128,129,130,132,133,134,135,136,139,140],"user_input":140,"user_nam":116,"userandomdata":[27,29,64],"usernam":20,"useunsignedrelu":27,"usign":139,"usual":[36,39,56,57,58,69,87,107,139],"util":[0,11,13,19,29,34,41,42,43,44,46,50,53,54,55,59,62,64,65,72,77,80,83,84,88,90,92,93,99,100,112,118,119,122,124,126,133,136,137,138,140],"v":[12,14,96,115,120,135,139],"v0":[67,95,96,107,124,131,134,139],"v01":[96,124],"v1":[28,42,63,66,68,89,100,107,124,127,130,133,134,135,136,137,138],"v2":[87,99],"v_proj":[9,14,15,82,96,107,118,120,122,133,136],"vae":[89,124],"vai_lib_path":73,"vaiml":27,"val":[41,43,44,46,47,51,53,54,57,117,133,136,137,138],"val2017":[62,116],"val_batch_s":116,"val_data":[41,42,43,44,45,46,47,51,53,54,62,65],"val_imag":[41,42,43,44,46,47,51,53,54,65],"val_load":99,"valid":[3,18,41,42,43,44,45,46,47,51,53,54,65,99,100,116,124,133,136,137,138],"valid_dataload":116,"validation_data":107,"valu":[3,5,6,9,14,15,22,23,24,25,27,30,31,33,35,36,37,38,39,40,56,57,58,64,70,73,74,75,76,77,80,81,82,85,86,92,96,99,100,107,111,113,115,116,118,120,123,124,129,130,131,133,134,139,140],"valuabl":20,"valueerror":[3,8,69],"vanilla":35,"vanish":130,"vari":[32,76,112],"variabl":[18,79,86,96,124,135,139,140],"varianc":37,"variant":35,"variat":[41,42,43,44,135,139],"varieti":[17,19,98,100],"variou":[4,16,17,19,22,27,32,73,76,77,87,88,112,115,121,123,124,126,135,140],"ve":[18,140],"vector":[6,120,135,139],"verbos":[9,70],"veri":[9,27,69,70,81,86,118,130,135,139,140],"verifi":[17,18,71,87,99,118],"versa":71,"versatil":[22,100],"version":[3,6,9,11,13,14,19,21,27,70,71,79,82,89,92,96,97,116,124,126,134,135,139,140,141],"via":[9,18,47,64,90,98,124,131,140],"vice":71,"video":139,"view":[28,77,92,107,116,133,136,137,138,139],"virtual":135,"vision":[28,42,47,51,63,65,87,90,91,96,107,109,116,117,124,127,130,139,140],"visit":131,"visual":[18,79,117,135,139,140],"vit":135,"vit_small_patch16_224":53,"vital":20,"viti":[3,5,27,126],"vitisbfpquant":5,"vitisdequantizelinear":124,"vitisextendedquant":5,"vitisinstancenorm":124,"vitislstm":124,"vitisonnxquant":[3,5],"vitisqdq":71,"vitisqdqnpucnnquant":5,"vitisqdqquant":5,"vitisquantformat":[6,124],"vitisquantizelinear":124,"vitisquanttyp":[6,124],"vllm":[9,101,103,105,124],"vlm":[91,93,94],"vmaf":[71,124],"vocab":[49,50,52,59],"vulner":21,"w":[37,38,81,89,118,124,133,135,136,140],"w3":115,"w4":115,"w8":124,"w8a8":[120,121,124],"w_bfp16_a_bfp16":96,"w_fp8_a_fp8":[96,115],"w_fp8_a_fp8_per_tensor":122,"w_fp8_a_fp8_per_tensor_config":122,"w_int4_per_channel_sym":104,"w_int4_per_group_sym":[96,104,139],"w_int8_a_int8_per_tensor":[120,122],"w_int8_a_int8_per_tensor_config":122,"w_int8_a_int8_per_tensor_sym":[96,115,120],"w_int8_per_channel_a_int8_per_tensor":121,"w_int8_per_channel_a_int8_per_tensor_kv_cache_int8_per_tensor":121,"w_int8_per_channel_a_int8_per_token":121,"w_int8_per_channel_a_int8_per_token_kv_cache_int8_per_token":121,"w_int8_per_tensor":120,"w_int8_per_tensor_a_int8_per_tensor":121,"w_int8_per_tensor_a_int8_per_tensor_kv_cache_int8_per_tensor":121,"w_mx6_a_mx6":96,"w_mx_fp4_a_mx_fp4_sym":124,"w_mx_fp4_a_mx_fp6_sym":124,"w_mx_fp6_e2m3_a_mx_fp6_e2m3":124,"w_mx_fp6_e2m3_sym":124,"w_mx_fp6_e3m2_a_mx_fp6_e3m2":124,"w_mx_fp6_e3m2_sym":124,"w_mx_fp8_a_mx_fp8":124,"w_mx_int8_per_group_sym":124,"w_mxfp4_a_mxfp4":[96,124],"w_mxfp4_a_mxfp4_sym":124,"w_mxfp4_a_mxfp6":124,"w_mxfp4_a_mxfp6_e2m3":124,"w_mxfp4_a_mxfp6_e3m2":124,"w_mxfp6_e2m3":124,"w_mxfp6_e2m3_a_mxfp6_e2m3":124,"w_mxfp6_e3m2":124,"w_mxfp6_e3m2_a_mxfp6_e3m2":124,"w_mxfp8_a_mxfp8":124,"w_mxint8":124,"w_scale":38,"w_uint4_a_bfloat16_per_group_asym":104,"w_uint4_asym":97,"w_uint4_per_group":122,"w_uint4_per_group_asym":[96,104,115,131],"w_uint4_per_group_config":122,"w_zero_point":38,"wa":[18,41,43,44,46,47,50,51,52,53,54,55,59,79,117,130,140],"wai":[15,57,58,63,79,81,99,107,116,123,124,135,139],"walk":89,"wanna":77,"want":[3,5,15,18,25,36,39,41,42,62,65,71,73,74,75,77,83,90,92,96,121,122,123,130,134,136,139,140],"warn":[8,12,14,27,70,124],"warranti":21,"watch":140,"wb":38,"wbb":38,"we":[3,6,9,14,18,20,22,23,24,25,28,34,35,42,45,55,56,57,58,62,63,65,70,71,72,73,74,76,77,78,79,82,83,84,86,87,88,90,91,92,96,98,99,100,103,105,107,116,117,118,120,124,126,128,129,130,131,132,133,134,135,136,139,140],"websit":[41,42,43,44,46,47,51,53,54,65],"weight":[3,5,6,8,9,10,13,14,15,16,17,19,22,23,24,25,27,29,32,38,47,56,57,58,61,64,66,67,69,70,72,73,75,76,78,79,81,82,83,86,87,89,97,99,100,102,103,104,105,107,112,114,115,116,117,119,120,121,122,123,124,125,127,128,129,130,132,133,134,135,139,140],"weight_1":116,"weight_decai":12,"weight_fli":9,"weight_format":[9,10,105],"weight_group":9,"weight_lr":12,"weight_merge_group":10,"weight_method":6,"weight_nam":[3,5],"weight_qtyp":[3,5],"weight_scal":[3,5],"weight_spec":[29,47,72,128,129],"weight_stat":86,"weight_tensor_nam":76,"weight_tensor_name1":76,"weight_tensor_name2":76,"weight_typ":[6,8,56,57,58,63,74,75,76,77,79,124],"weight_zero_point":103,"weights_only_quant":[52,60],"weightscal":[27,72],"weightsonli":27,"weightsymmetr":[56,57,58,63,77],"weighttargetquanttyp":76,"welcom":[20,45],"well":[19,32,35,71,73,77,79,88,112,116,118,122,124,134,140],"were":[22,114,116,124,130,139],"wether":63,"wget":[18,28,42,47,49,50,51,52,59,63,66,67,116,127,130],"what":[17,69,77,80,99],"wheel":18,"when":[6,8,9,14,15,18,22,23,24,27,29,32,36,39,56,57,58,63,64,70,71,72,73,74,75,76,77,79,81,83,86,89,95,96,100,110,112,114,115,118,120,123,124,128,129,130,132,133,135,139,140],"where":[6,7,14,19,27,30,35,36,37,39,56,57,58,70,73,74,75,76,79,81,85,94,118,120,124,128,132,133,134,139,140],"whether":[2,3,4,5,6,8,9,10,12,13,14,20,21,23,27,45,62,65,70,71,77,81,86,107,116,119],"which":[2,3,7,9,13,14,16,18,19,21,22,27,28,32,35,41,42,43,44,46,47,50,51,52,53,54,55,56,57,58,59,62,63,65,70,71,72,73,75,76,77,78,79,80,81,82,84,86,90,96,99,100,105,107,112,114,115,116,117,118,120,124,125,130,131,133,134,135,139,140],"while":[14,16,18,19,20,27,28,32,35,36,39,42,69,71,72,73,74,75,76,77,79,80,81,88,100,105,112,115,120,123,129,131,133,135,139],"whl":[18,68,109,134,135,139],"who":[135,136,140],"whole":[81,87,100],"whom":21,"whose":[5,27,47,70,76,82,133],"why":[80,81,116,139,140],"wide":[17,36,39,66,67,76,86,100,115,119,125,127,133],"width":[19,37,56,57,58,76,77,81,88,107,115,116,128,134],"wiki":[39,100],"wiki2":[95,107],"wikipedia":[39,139],"wikitext":[84,97,100,107,120,133,134,136,137,138],"wikitext2":[48,49,50,52,55,59,60,61,93,100],"wikitext_for_gptq_benchmark":115,"wildcard":10,"win32":18,"window":[16,17,72,73,74,75,79,110,124,135,139,140],"winogrand":97,"wise":[12,17,22,66,67,68,76,77,122,123,124,127,133],"wish":[70,140],"with_cast":[71,129],"with_mixed_precis":54,"within":[6,14,18,20,24,27,35,40,42,45,55,56,57,58,63,73,74,75,76,77,81,82,88,96,124,133,135,139,140],"without":[17,18,19,21,22,27,41,53,71,72,74,75,76,77,80,81,82,86,88,100,110,114,115,118,120,124,128,129,132,133,135,140],"woman":139,"won":140,"wonder":140,"word":[9,103,104,139],"work":[18,19,20,27,70,76,77,80,116,131,135,140],"worker":[27,89],"workflow":[16,18,20,47,64,99,116,124,131,140],"workload":[18,124],"world":[77,90],"worri":140,"wors":[29,135],"worst":118,"would":[14,35,40,92,103,116,135,139,140],"write":[20,27,96,100,136,139,140],"written":[20,82,133,136],"wrongli":124,"wsl":[18,135,139,140],"x":[6,18,35,36,37,38,39,40,90,91,93,94,99,100,107,116,118,124,135,140],"x1":135,"x3":124,"x4":124,"x8":139,"x_q":81,"x_r":81,"x_scale":[36,38],"x_tini":117,"x_zero_point":[36,38],"xint8":[8,29,47,51,62,65,66,67,69,78,124,126,127,130],"xint8_adaqu":78,"xint8_adaquant_config":132,"xint8_adaround":[62,65,78],"xint8_adaround_config":132,"xint8_quantized_model":132,"xint8spec":[27,29,47,64],"xl":[89,124],"xsum":94,"xw":118,"xxx":78,"xzf":[41,42,43,44,46,47,51,53,54],"y":[18,35,36,37,38,39,40,118,140],"y_scale":[36,39],"y_zero_point":39,"ye":70,"yet":[18,96,135,140],"yield":[22,29,87,115,129,130],"yolo":[45,67,68,99,124],"yolo_na":[57,116],"yolo_nas_":[57,62,116],"yolo_nas_inf":57,"yolo_nas_pow2_int_qu":116,"yolo_nas_s_coco":116,"yolov":[56,58],"yolov3":[56,68],"yolov7":124,"yolov8":[67,124],"yolov8n":[45,67],"yolox":117,"yolox_":62,"yolox_tini":117,"you":[13,15,17,18,19,20,22,27,28,31,32,36,39,41,42,43,44,45,46,47,51,53,54,56,57,58,62,63,64,65,66,67,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,86,88,89,90,92,94,96,97,100,105,109,110,112,114,115,116,118,119,120,121,122,123,125,126,127,128,129,130,131,132,133,134,136],"your":[15,17,18,19,21,22,27,29,34,41,42,43,44,45,46,47,51,53,54,56,57,58,63,65,66,67,71,79,83,84,89,90,96,98,115,116,124,126,127,128,129,130,131,132,135,139,140],"your_28x28_imag":140,"your_model":96,"your_path":134,"yourself":20,"z":[6,19,100,140],"zalando":140,"zendnn":123,"zero":[3,6,14,19,22,33,35,36,37,38,39,40,56,57,58,69,72,80,87,99,103,105,107,113,134,135,140],"zero_grad":140,"zero_point":[6,9,87,100,114],"zero_point_typ":14,"zeropoint":9,"zeropointtyp":14,"zip":[18,62,68,100,109,131],"zoom":135,"\u2463":96,"\u2464":96,"\u2465":96},"titles":["AMD Quark APIs for ONNX","Quark APIs for PyTorch","ONNX model calibration","ONNX quantizer","ONNX model optimization","QDQ quantizer","ONNX quantization utilities","ONNX model quantization","ONNX quantization configuration","PyTorch model export and reloading","PyTorch model export configuration","Pruning","Pruning configuration","PyTorch quantization","Quantization configuration","Quantization LLM Template","Getting started with AMD Quark","Welcome to AMD Quark Documentation!","Installation Guide","Quantization with AMD Quark","Quark\u2019s <code class=\"docutils literal notranslate\"><span class=\"pre\">contrib</span></code> Area","Quark license","Quantization Using AdaQuant and AdaRound","Quantizing Using CrossLayerEqualization (CLE)","QuaRot","SmoothQuant (SQ)","Accuracy Improvement Algorithms","Full List of Quantization Configuration Features","AMD Quark for ONNX","Adding Calibration Datasets","Calibration Methods","Quantization Schemes","Quantization Strategies","Quantization Symmetry","Using ONNX Model Inference and Saving Input Data in NPY Format","BFPQuantizeDequantize","ExtendedDequantizeLinear","ExtendedInstanceNormalization","ExtendedLSTM","ExtendedQuantizeLinear","MXQuantizeDequantize","Block Floating Point (BFP) Example","Microscaling (MX) Example","Quark ONNX Quantization Example","Quark ONNX Quantization Example","Auto-Search for General Yolov8 ONNX Quantization","Quark ONNX Example for CrossLayerEqualization (CLE)","Quantizing a ResNet50-v1-12 Model in crypto mode","Dynamic Quantization for Llama-2-7b","Dynamic Quantization for OPT-125M","Quantizing a model with GPTQ","Quantizing a ResNet50-v1-12 Model","Quantizing an OPT-125M Model","Quark ONNX Example for LayerWisePercentile","Quantization using Mixed Precision","Quark ONNX Quantization Example","Auto-Search for Ryzen AI ONNX Model Quantization","Auto-Search for Ryzen AI Yolo-NAS ONNX Model Quantization","Auto-Search for Ryzen AI Yolov3 ONNX Model Quantization with Custom Evaluator","Quantization using SmoothQuant","Quantizing Llama-2-7b model using MatMulNBits quantizer","Quark ONNX Quantization Example","Yolo_nas and Yolox Quantization","Auto-Search for Ryzen AI Resnet50 ONNX Model Quantization","Accelerate with GPUs","Hugging Face TIMM Quantization","Best Practice for Ryzen AI in Quark ONNX","Best Practice for Ryzen AI in Quark ONNX","Accessing ONNX Examples","Frequently Asked Questions (FAQ)","Optional Utilities","Tools","Introduction","BFP16 (Block floating point) Quantization","Introduction","Microscaling (MX)","Mixed Precision","Automatic Search for Model Quantization","Configuring ONNX Quantization","Supported Data and Op Types","Using OCP MX (Microscaling)","Two Level Quantization Formats (MX4, MX6, MX9: shared Microexponents)","Introduction to AWQ Algorithm","AMD Quark for PyTorch","Adding Calibration Datasets","Calibration Methods","Debugging quantization degradation in AMD Quark","Image Classification Models FX Graph Quantization","Brevitas Integration","Diffusion Model Quantization using Quark","Language Model Evaluations in Quark","LM-Evaluation-Harness Evaluations","LM-Evaluation-Harness (Offline)","Perplexity Evaluations","Rouge &amp; Meteor Evaluations","Pruning","Language Model Post Training Quantization (PTQ) Using Quark","Language Model QAT Using Quark and Trainer","Integration with AMD Pytorch-light (APL)","Vision Model Quantization Using Quark FX Graph Mode","Bridge from Quark to llama.cpp","Exporting Quantized Models","GGUF Exporting","Hugging Face format (safetensors format)","ONNX Exporting","Quark Format","Extensions for PyTorch","LLM Pruning","Language Model Optimization","Accessing PyTorch Examples","Frequently Asked Questions (FAQ)","Quantization Schemes","Quantization Strategies","Quantization Symmetry","Save &amp; Load Quantized Models","Best Practices for Post-Training Quantization (PTQ)","YOLO-NAS FX graph Quantization","YOLO-X Tiny FX Graph Quantization","Activation/weight smoothing (SmoothQuant)","BFP16 (Block floating point) Quantization","Rotation-based quantization with QuaRot","Quantizing with Rotation and SmoothQuant","Configuring PyTorch Quantization","Configuring PyTorch Quantization for Large Language Models","Release Notes","Quark for AMD Instinct Accelerators","Quark for Ryzen AI NPU","Best Practice for Ryzen AI in AMD Quark ONNX","Float Scales (A8W8 and A16W8) Quantization","FP32/FP16 to BF16 Model Conversion","Quick Start for Ryzen AI","Quantizing LLMs for ONNX Runtime GenAI","Power-of-Two Scales (Xint8) Quantization","Introduction to Auto-SmoothQuant Algorithm","LLM Model Depth-Wise Pruning (beta)","Quantizing a Diffusion Model using Quark","AWQ end-to-end example","FP4 Quantization for LLM models","FP8 Quantization for LLM models","Quantizing a Large Language Model with Quark","AMD Quark Tutorial: PyTorch Quickstart","AMD Quark release history"],"titleterms":{"":[16,20],"0":124,"1":[28,35,36,37,38,39,40,79,80,82,83,90,92,95,96,97,98,100,116,119,122,123,124,130,133],"10":124,"12":[47,51],"125m":[49,52],"2":[28,48,60,79,80,82,83,90,92,95,96,97,98,100,116,119,122,123,124,130,133],"3":[28,79,80,82,83,90,92,96,97,98,100,116,119,122,123,130,133],"4":[28,79,80,82,83,90,92,96,116,119,122,123,130,133],"4k":97,"5":[79,80,82,83,90,92,96,116,124,130],"6":[92,96,116,124,130],"6b":97,"7":[96,116,124],"7b":[48,60],"8":[96,116,124],"9":[96,124],"A":[71,133],"For":[20,29,34,82],"It":100,"Not":96,"Of":92,"The":97,"Their":19,"These":81,"Will":[135,139,140],"With":[46,50,53,54,59],"a16w8":[71,128],"a8w8":[71,128],"a_float16":96,"about":[87,99],"acceler":[64,125],"access":[68,109],"accuraci":[26,68,71,72,73,74,75,128,129,132,140],"activ":118,"actual":19,"ad":[29,84],"adaqu":[22,41,43],"adaround":[22,44],"advanc":[18,123,130],"advantag":99,"ae":135,"ai":[56,57,58,63,66,67,68,126,127,130,131],"algoconfig":122,"algorithm":[26,82,115,133],"all":[71,83],"alreadi":102,"amd":[0,16,17,18,19,22,28,29,63,68,69,72,73,74,75,76,80,83,86,98,110,116,119,125,127,140,141],"an":[47,52,92],"analysi":76,"api":[0,1,87,107],"apl":98,"appli":[80,115],"ar":[19,80,81],"architectur":139,"area":20,"argument":[22,23,24,25,91,93,94],"articl":139,"ask":[69,110],"assign":71,"asymmetr":96,"attent":139,"attribut":[35,36,37,38,39,40],"auto":[45,56,57,58,63,77,133,135],"auto_search":45,"automat":[76,77,96],"awq":[82,96,131,136],"backward":135,"base":[76,120],"baselin":[71,92],"basic":[28,83],"befor":116,"benchmark":89,"benefit":[22,73,76],"best":[66,67,115,127],"beta":134,"between":[71,128,129,132],"bf16":[72,129],"bfloat16":[71,79],"bfp":41,"bfp16":[41,71,73,79,96,119],"bfpquantizedequant":35,"bia":71,"block":[41,73,80,119],"brevita":88,"bridg":100,"brief":99,"bug":124,"builder":131,"built":123,"c":[18,110],"cach":96,"calcul":80,"calibr":[2,28,29,30,63,64,65,66,67,80,83,84,85,89,107,116,127,130,140],"call":[56,57,58,82],"capabl":16,"chatglm":97,"chatglm3":97,"check":140,"chunk":139,"cl":140,"class":29,"classif":[68,87,99],"cle":[23,46],"cli":139,"cmake":18,"code":[29,34,82,107,135],"compar":[16,128,129,132],"compil":[18,110,116],"compon":[77,135],"concept":73,"conclus":[77,80,88],"config":[56,57,58,69,82,107,116,122,128,132,133,134],"configur":[8,10,12,14,27,28,78,80,83,96,97,119,122,123,130,140],"consider":19,"constraint":[35,36,37,38,39,40],"content":87,"context":81,"contrib":20,"contribut":20,"contributor":20,"controlnet":89,"conv":71,"convers":129,"convert":[19,71,129],"correspond":100,"cpp":100,"cpu":[71,96],"creat":[123,140],"crosslayerequ":[23,46],"crypto":[47,68],"custom":[18,58,65,71,78,123],"data":[19,28,29,34,41,42,43,44,45,46,47,51,53,54,62,63,65,66,67,71,79,80,81,83,116,127,130,140],"dataload":84,"dataread":29,"dataset":[29,84,89,92,107,134],"debug":86,"declar":87,"default":78,"defin":[83,140],"degrad":86,"denois":135,"depend":[89,140],"deploi":116,"deploy":83,"deprec":71,"depth":[107,134],"descript":82,"design":88,"detail":[34,90,99],"detect":99,"determin":97,"develop":126,"devic":116,"diagram":77,"dict":84,"differ":[115,128,129,131,132],"diffus":[89,135],"directori":140,"do":[100,119],"document":[17,20],"doe":[19,100,118],"download":[18,139],"drawn":140,"dtype":100,"dump":70,"dynam":[48,49,68,80],"eager":114,"effici":17,"enabl":[73,74,75,76],"encod":[135,139],"end":[96,133,136],"enhanc":124,"entir":89,"entropi":30,"environ":[64,110,134],"error":140,"establish":122,"evalu":[41,42,43,44,46,47,48,49,50,51,52,53,54,55,58,59,60,61,65,70,71,90,91,92,93,94,95,96,97,107,130,134,139],"exampl":[18,22,23,24,25,28,29,41,42,43,44,46,47,53,55,61,68,73,74,75,82,83,96,98,102,104,105,107,109,114,133,136],"exclud":115,"expand":121,"experi":[87,99,100,134],"experiment":96,"explan":134,"export":[9,10,70,83,89,90,92,96,97,100,101,102,103,104,105,116,131,135],"extend":71,"extendeddequantizelinear":36,"extendedinstancenorm":37,"extendedlstm":38,"extendedquantizelinear":39,"extens":[88,106],"face":[65,68,103],"fact":134,"factor":97,"fake":19,"faq":[69,77,110],"fashion":140,"fast":[18,22,64],"featur":[17,27,77,88,90,99,107,124,130],"field":82,"file":89,"finetun":[22,64,97],"first":18,"fix":124,"flexibl":17,"float":[28,41,62,65,70,71,73,83,119,128,130,132],"float16":[71,79,95,96],"float32":[71,79],"flow":[77,99,126],"folder":71,"format":[34,42,79,81,83,103,105],"forward":135,"found":140,"fp16":129,"fp32":[128,129,132],"fp4":137,"fp8":[96,138],"fp8_e4m3":96,"frequent":[69,110],"from":[18,67,92,100],"frozen":97,"fsdp":97,"full":27,"fundament":[135,139],"further":[28,72,73,74,75,83,135,139,140],"fx":[87,99,114,116,117],"gen":131,"genai":131,"gener":[45,83,96],"get":[16,90,92],"gguf":[100,102],"gguf_export":96,"given":71,"gptq":50,"gpu":[18,64],"graph":[87,99,114,116,117],"group":131,"guid":[18,90],"guidelin":55,"hand":140,"happen":19,"har":[90,91,92],"hardwar":81,"highlight":[87,116,117],"histori":141,"how":[20,72,73,74,75,76,80,81,82,100,118,119,128,129,132,133],"hqq":60,"hug":[65,68,103],"i":[19,47,74,75,76,80,100],"imag":[68,87,99,140],"implement":135,"import":[90,96,105,117,134],"improv":[26,68,72,73,74,75,128,129,132],"inf":71,"infer":[34,62,64,65,67],"inform":[116,117],"init":[107,134],"inp":82,"input":[29,34,35,36,37,38,39,40,71],"instal":[18,80,96,119,131,135,139,140],"instanc":134,"instinct":125,"instruct":[97,99],"int":96,"int16":[71,79],"int32":[71,79],"integ":[19,81],"integr":[88,98],"interest":92,"intern":19,"introduct":[55,72,74,80,82,98,100,119,121,128,129,132,133],"issu":[69,110],"json_safetensors_export":96,"jupyt":140,"keep":97,"kei":[17,73,99],"kernel":[18,140],"knowledg":116,"kv":96,"languag":[68,83,90,96,97,108,123,139],"larg":[83,123,139],"latent":139,"layer":[82,115,131],"layerwisepercentil":53,"learn":[135,139,140],"level":[79,81],"librari":18,"licens":[21,45,52,55],"light":98,"linux":18,"list":[27,84,96],"llama":[48,60,96,100],"llama2":95,"llama3":[82,133],"llm":[15,83,107,131,134,137,138],"llm_eval_haness_offlin":90,"llm_eval_har":90,"llmtemplat":123,"lm":[90,91,92],"load":[83,89,103,114],"loader":83,"main":87,"mainstream":107,"make":97,"map":81,"matmulnbit":60,"mean":19,"measur":[128,129,132],"mention":140,"meteor":94,"method":[30,85,107],"metric":107,"microexpon":[74,81],"microsc":[42,75,80],"mini":97,"minmax":[30,53],"mix":[54,71,76,79],"mnist":140,"mode":[47,68,87,92,99,114],"model":[2,4,7,9,10,17,19,28,29,34,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,73,74,75,77,79,80,83,87,89,90,91,92,93,94,95,96,97,99,100,101,102,103,107,108,114,116,119,121,122,123,127,128,129,130,131,132,134,135,137,138,139,140],"model_decoder_lay":82,"modelquant":88,"modul":122,"module2inspect":82,"more":[78,96,121],"mse":30,"multi":[29,34],"mx":[42,75,80,96],"mx4":81,"mx6":[81,96],"mx9":[74,81],"mxint8":79,"mxquantizedequant":40,"na":[57,116],"name":71,"nchw":71,"necessari":134,"net":135,"network":116,"new":[123,124],"next":[16,82,135,140],"nhwc":71,"nn":122,"nois":135,"non":97,"nonoverflow":30,"note":[81,124],"notebook":140,"npu":[71,116,126],"npy":34,"object":99,"obtain":81,"ocp":[80,96],"offlin":92,"oga":92,"onli":[68,80,89,96,97],"only_train_scaling_factor":97,"onnx":[0,2,3,4,6,7,8,16,17,22,28,34,43,44,45,46,53,55,56,57,58,61,63,66,67,68,69,70,71,72,73,74,75,76,78,89,90,91,92,93,94,104,116,127,131,135],"op":[71,79],"oper":18,"opt":[49,52],"optim":[4,92,108],"option":[18,62,65,67,70,83,116,122,123,131],"origin":[28,83,97,130],"osscar":107,"other":[79,83,91,93,94,97,107,134],"our":140,"outlier":115,"output":[35,36,37,38,39,40,116],"overal":[116,122],"overview":[27,77,82,88,107,116,117,133],"own":[82,133],"packag":134,"page":87,"paper":[135,139],"param":134,"paramet":97,"parti":89,"partli":134,"path":[29,134,140],"per":131,"per_group":96,"percentil":[30,53],"perform":[107,116,134],"perplex":93,"phi":97,"pip":[18,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,59,60,61,62,63,65,66,67,127],"pipelin":89,"point":[41,73,83,87,119],"post":[96,115,139],"power":132,"ppl":[90,93],"practic":[66,67,115,127],"pre":[70,92,139],"precis":[54,71,76,79],"premium":77,"prepar":[28,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,95,96,97,107,116,117,127,130,131,134],"prerequisit":[116,134],"pretrain":92,"prev_op":82,"previou":18,"principl":20,"print":71,"process":[56,57,58,70,92,134,135],"processs":135,"prompt":89,"provid":65,"prune":[11,12,95,107,134],"pruner":[107,134],"ptq":[96,115,116],"pypi":18,"python":18,"pytorch":[1,9,10,13,16,17,18,70,83,98,99,106,109,110,116,122,123,140],"qat":[97,115,116],"qdq":5,"quant":[59,100],"quantiti":71,"quantiz":[3,5,6,7,8,13,14,15,17,18,19,22,23,27,28,29,31,32,33,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,83,86,87,89,96,97,99,100,101,102,103,111,112,113,114,115,116,117,119,120,121,122,123,127,128,130,131,132,135,137,138,139,140],"quantizationconfig":[88,122],"quantizationspec":122,"quark":[0,1,16,17,18,19,20,21,22,28,29,43,44,46,53,55,61,66,67,68,69,71,72,73,74,75,76,80,82,83,86,89,90,96,97,99,100,105,107,109,110,118,119,125,126,127,131,133,135,139,140,141],"quarot":[24,55,120],"question":[69,110],"quick":[116,117,130],"quickstart":140,"random":[29,71],"read":[28,83,135,139,140],"recap":140,"recip":[91,93,94,95,96,97],"recommend":18,"refer":92,"regist":123,"releas":[68,109,124,141],"reload":[9,97],"replac":71,"requir":[41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,59,60,61,62,63,65,66,67,80,127],"resnet50":[47,51,63],"resourc":[125,126],"result":[41,62,65,70,71,87,90,97,100,107,116,117,121,130,134],"retriev":92,"reus":140,"rotat":[120,121],"roug":94,"run":[89,96,100],"runtim":131,"ryzen":[56,57,58,63,66,67,68,126,127,130],"safetensor":[89,95,97,103],"save":[34,95,103,107,114,134],"scale":[80,81,97,128,132],"scaling_lay":82,"schema":133,"scheme":[31,100,111,115,123],"score":92,"script":[89,95,96,97,99,139],"search":[45,56,57,58,63,77],"sensit":76,"set":[28,56,57,58,80,83,116,119,122,130,135,140],"setup":[64,92,139],"shape":71,"share":81,"simul":[70,140],"singl":[29,34],"size":131,"smooth":[59,118],"smoothquant":[25,55,59,118,121,133],"some":[99,100,134],"someth":19,"space":139,"specifi":134,"sq":25,"start":[16,90,116,117,130],"static":96,"step":[16,82,88,92,100,122,126,135,140],"str":84,"strategi":[32,112],"streamlin":17,"structur":116,"summari":[35,36,37,38,39,40,79,116],"support":[18,79,90,92,95,96,97,107,123],"symmetri":[33,113],"tabl":[79,90],"task":[92,99],"tech":99,"templat":[15,83,123],"tensor":[71,80,84,122],"test":[20,89,107,140],"testdata":134,"text":[135,139],"thi":[19,68,80,87,109],"third":89,"time":18,"timm":[65,68],"tini":117,"tip":70,"token":[107,139],"tool":[71,99,107],"torch":[67,84,91,93,94,118,122],"train":[92,96,115,116],"trainabl":97,"trainer":97,"transform":139,"troubleshoot":140,"try":115,"turn":80,"tutori":[17,96,135,139,140],"two":[81,132],"type":[19,35,36,37,38,39,40,79,81],"u":135,"u16u8":71,"u8u8":71,"uint4":131,"understand":[20,116],"unet":89,"uniform":81,"up":[80,122,135,140],"upgrad":22,"us":[22,23,29,34,54,59,60,80,89,96,97,99,100,118,119,123,131,135],"usag":[77,96,99,107],"user":[18,20,90],"util":[6,70],"v":90,"v1":[47,51],"valu":[19,71],"variabl":97,"verif":18,"verifi":92,"version":[18,35,36,37,38,39,40],"vision":99,"visual":116,"viti":71,"vlm":90,"w_uint4":96,"we":19,"weight":[68,71,80,96,118],"welcom":17,"well":80,"what":[19,47,74,75,76,87,100,135,139,140],"when":19,"whether":97,"while":97,"window":18,"wise":[107,134],"without":[43,44,46,50,54,55,59,89,95,96,130],"work":[47,99,100,118,119],"workflow":[82,117,133],"write":[82,133],"x":117,"xint8":132,"yolo":[57,116,117],"yolo_na":[62,68],"yolov3":58,"yolov8":45,"yolox":[62,68],"you":[135,139,140],"your":[20,82,100,133]}})