{
  "name": "smooth",
  "alpha": 0.8,
  "scale_clamp_min": 0.001,
  "scaling_layers": [
    {
      "prev_op": "input_layernorm",
      "layers": [
        "self_attn.q_a_proj",
        "self_attn.kv_a_proj_with_mqa"
      ],
      "inp": "self_attn.q_a_proj",
      "module2inspect": "self_attn"
    },
    {
      "prev_op": "self_attn.q_a_layernorm",
      "layers": [
        "self_attn.q_b_proj"
      ],
      "inp": "self_attn.q_b_proj"
    },
    {
      "prev_op": "self_attn.kv_a_layernorm",
      "layers": [
        "self_attn.kv_b_proj"
      ],
      "inp": "self_attn.kv_b_proj"
    },
    {
      "prev_op": "post_attention_layernorm",
      "layers": [
        "mlp.gate_proj",
        "mlp.up_proj"
      ],
      "inp": "mlp.gate_proj",
      "module2inspect": "mlp"
    },
    {
      "prev_op": "mlp.up_proj",
      "layers": [
        "mlp.down_proj"
      ],
      "inp": "mlp.down_proj"
    },
    {
      "prev_op": "up_proj",
      "layers": [
        "down_proj"
      ],
      "inp": "down_proj"
    }
  ],
  "model_decoder_layers": "model.layers"
}
