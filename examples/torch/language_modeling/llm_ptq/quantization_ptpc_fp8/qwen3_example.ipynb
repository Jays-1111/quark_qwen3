{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# FP8 Quantization with Per-Channel Static Weights and Per-Token Dynamic Activations\n",
    "\n",
    "## Installation\n",
    "\n",
    "To get started, install:\n",
    "\n",
    " `pip install amd-quark transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "The example includes an end-to-end script for applying the weight_static_fp8_activation_dynamic_fp8 quantization algorithm.\n",
    "\n",
    "`python3 qwen3_example.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "The resulting model Qwen3-8B-FP8-ptpc is ready to be loaded into vLLM.\n",
    "\n",
    "## Code Overview\n",
    "\n",
    "Typically, quantizing a floating-point model with AMD Quark involves the following steps:\n",
    "\n",
    "### 1) Load the original floating-point model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ckpt_path = \"Qwen/Qwen3-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(ckpt_path)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 2) Set the quantization configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quark.torch.quantization import FP8E4M3PerChannelSpec\n",
    "from quark.torch.quantization.config.config import Config, QuantizationConfig\n",
    "\n",
    "FP8_PER_CHANNEL_SPEC = FP8E4M3PerChannelSpec(is_dynamic=False, ch_axis=0).to_quantization_spec()\n",
    "FP8_PER_TOKEN_DYNAMIC_SPEC = FP8E4M3PerChannelSpec(is_dynamic=True, ch_axis=1).to_quantization_spec()\n",
    "W_FP8_PER_CHANNEL_STATIC_A_FP8_PER_TOKEN_DYNAMIC_CONFIG = QuantizationConfig(\n",
    "    input_tensors=FP8_PER_TOKEN_DYNAMIC_SPEC, weight=FP8_PER_CHANNEL_SPEC\n",
    ")\n",
    "quant_config = Config(global_quant_config=W_FP8_PER_CHANNEL_STATIC_A_FP8_PER_TOKEN_DYNAMIC_CONFIG, exclude=[\"lm_head\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 3) Use the AMD Quark API to perform an in-place replacement of the model's modules with quantized modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quark.torch import ModelQuantizer\n",
    "\n",
    "quantizer = ModelQuantizer(quant_config)\n",
    "model = quantizer.quantize_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 4) (Optional) Export the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quark.torch import export_safetensors\n",
    "\n",
    "output_dir = ckpt_path.rstrip(\"/\").split(\"/\")[-1] + \"-FP8-ptpc\"\n",
    "model = quantizer.freeze(model)\n",
    "export_safetensors(model, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 5) (Optional) Evaluate Accuracy\n",
    "\n",
    "Install `vllm` and `lm-evaluation-harness`:\n",
    "\n",
    "`pip install vllm lm_eval`\n",
    "\n",
    "Evaluate accuracy with `lm_eval` (for example on 200 samples of `gsm8k`):\n",
    "\n",
    "```\n",
    "lm_eval \\\n",
    "  --model vllm \\\n",
    "  --model_args pretrained=./Qwen3-8B-FP8-ptpc,add_bos_token=True \\\n",
    "  --tasks gsm8k  --num_fewshot 5 --batch_size auto --limit 200\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "license": "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
